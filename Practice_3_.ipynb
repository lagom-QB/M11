{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 3.",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b0b35767c3143d18689a7b02d134b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0411b3d0546f4927869ad37ca4b86279",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4dba3a1c0f6d41e9a34ad128c1a12236",
              "IPY_MODEL_7bf1c612646d4802bcd2f0eba29bacff"
            ]
          }
        },
        "c45203464bec49d2b9de4f4540a362cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_871f36f21b0c44d896c7e43a6cf25f21",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86dc053ebc1148c2b8f89af04654048e",
              "IPY_MODEL_549d2556597144ecb6ecaf5d01e1ab80"
            ]
          }
        },
        "5b462a18eeef4584b12ddddc1e8c528c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9663c3175a544fd2bfbd168f5e491889",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a418a48879aa4fe4a271d60df88cecb2",
              "IPY_MODEL_72cc7d4438074fada3551005b07385a7"
            ]
          }
        },
        "67136c51f1d64bcea7093ad5ff516b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3609edc864df43f7bbd69c6895e94a5b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_00df78adde834995bd10696b7e7d0cde",
              "IPY_MODEL_742d79fe8ce24770a317a6f38e4a6e72"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lagom-QB/M11/blob/master/Practice_3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UinBL84o1sml",
        "colab_type": "text"
      },
      "source": [
        "# Optimization in Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbZUDB9339wg",
        "colab_type": "text"
      },
      "source": [
        "# keywords: stochastic gradient decent, momentum, adagrad, adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wu66Y_K4X5B",
        "colab_type": "text"
      },
      "source": [
        "# SGD optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUJSwWnu6W0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAq-Jn03_wwB",
        "colab_type": "text"
      },
      "source": [
        "This is a sample implementation of SGD optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8M4v1-p4a2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MySGD(torch.optim.Optimizer):  \n",
        "  def __init__(self, params, lr):\n",
        "    self._lr = lr\n",
        "    defaults = {}\n",
        "    super().__init__(params, defaults)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def step(self):\n",
        "    for group in self.param_groups:\n",
        "      for p in group['params']:\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        d_p = p.grad\n",
        "        p.add_(d_p, alpha=-self._lr)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtQ6maX2_85V",
        "colab_type": "text"
      },
      "source": [
        "Let's test that it works correctly (the code below is copied from Practice 2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN6Uk4bp7bUW",
        "colab_type": "code",
        "outputId": "fadc6d8d-40f2-46dc-bee5-aecc244a79e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228,
          "referenced_widgets": [
            "3b0b35767c3143d18689a7b02d134b32",
            "c45203464bec49d2b9de4f4540a362cd",
            "5b462a18eeef4584b12ddddc1e8c528c",
            "67136c51f1d64bcea7093ad5ff516b90"
          ]
        }
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "train_dataset = datasets.MNIST('/data', train=True, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                ]))\n",
        "test_dataset = datasets.MNIST('../data', train=False, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                ]))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b0b35767c3143d18689a7b02d134b32",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/train-images-idx3-ubyte.gz to /data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c45203464bec49d2b9de4f4540a362cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/train-labels-idx1-ubyte.gz to /data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b462a18eeef4584b12ddddc1e8c528c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/t10k-images-idx3-ubyte.gz to /data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67136c51f1d64bcea7093ad5ff516b90",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rJnxiov7w8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn.modules import loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoQRSrH46aQ0",
        "colab_type": "code",
        "outputId": "ab862c25-fcf8-45f6-d6c3-1fc126a0bb41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "  def forward(self, x):\n",
        "    batch_size = x.shape[0]\n",
        "    return x.view(batch_size, -1)\n",
        "\n",
        "def get_model():\n",
        "  return nn.Sequential(Flatten(), \n",
        "                       nn.Linear(784, 512), \n",
        "                       nn.Tanh(),\n",
        "                       nn.Linear(512, 64), \n",
        "                       nn.Tanh(),\n",
        "                       nn.Linear(64, 10))\n",
        "\n",
        "loss_function = loss.CrossEntropyLoss()\n",
        "\n",
        "def train(model, train_loader, optimizer, loss_function, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_function(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 200 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "def test(model, test_loader, loss_function):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            test_loss += loss_function(output, target).sum().item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tzmJt_Q7XQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model()\n",
        "optim = MySGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUHv-0EZ6wr4",
        "colab_type": "code",
        "outputId": "7089e378-cae4-407c-bddc-d1e8538bf0cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "for epoch in range(1, 5):\n",
        "  train(model, train_loader, optim, loss_function, epoch)\n",
        "  test(model, test_loader, loss_function)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.339847\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.268448\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.319674\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.252545\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.214682\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9493/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.213813\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.185647\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.087889\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.195175\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.213207\n",
            "\n",
            "Test set: Average loss: 0.0019, Accuracy: 9632/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.088355\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.079265\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.046103\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.037328\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.077569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVdf57GZBiW3",
        "colab_type": "text"
      },
      "source": [
        "Why do we need defaults?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOsyWcIa8xT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MySGD(torch.optim.Optimizer):  \n",
        "  def __init__(self, params, lr):\n",
        "    defaults = {\"lr\": lr}\n",
        "    super().__init__(params, defaults)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def step(self):\n",
        "    for group in self.param_groups:\n",
        "      for p in group['params']:\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        d_p = p.grad\n",
        "        p.add_(d_p, alpha=-group[\"lr\"])\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzJp5vWi_pNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model()\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdgt_Zd-ANXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim = MySGD([{'params': model[:2].parameters(), 'lr': 0.01}, \n",
        "               {'params': model[2:].parameters()}], lr = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8CZF5wKBKT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, 5):\n",
        "  train(model, train_loader, optim, loss_function, epoch)\n",
        "  test(model, test_loader, loss_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_Gtk50FbUq",
        "colab_type": "text"
      },
      "source": [
        "Let's modify our SGD class to introduce an exponential momentum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-qUSRv6BtzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ExpMomentumSGD(torch.optim.Optimizer):  \n",
        "  def __init__(self, params, lr, momentum):\n",
        "    defaults = {\"lr\": lr, \"momentum\": momentum}\n",
        "    super().__init__(params, defaults)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def step(self):\n",
        "    for group in self.param_groups:\n",
        "      momentum = group['momentum']\n",
        "\n",
        "      for p in group['params']:\n",
        "        param_state = self.state[p]\n",
        "\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        d_p = p.grad\n",
        "        if 'momentum_buffer' not in param_state:\n",
        "          buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
        "        else:\n",
        "          buf = param_state['momentum_buffer']\n",
        "          buf.mul_(momentum).add_(d_p)\n",
        "        d_p = buf\n",
        "        p.add_(d_p, alpha=-group[\"lr\"])\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9mEdkhSCDw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model()\n",
        "optim = ExpMomentumSGD(model.parameters(), lr=0.1, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5byvU9tiEgnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, 5):\n",
        "  train(model, train_loader, optim, loss_function, epoch)\n",
        "  test(model, test_loader, loss_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-mXQwr4Fkcr",
        "colab_type": "text"
      },
      "source": [
        "Linear momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzUSZp9SEpNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearMomentumSGD(torch.optim.Optimizer):  \n",
        "  def __init__(self, params, lr, momentum):\n",
        "    defaults = {\"lr\": lr, \"momentum\": momentum}\n",
        "    super().__init__(params, defaults)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def step(self):\n",
        "    for group in self.param_groups:\n",
        "      momentum = group['momentum']\n",
        "\n",
        "      for p in group['params']:\n",
        "        param_state = self.state[p]\n",
        "\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        d_p = p.grad\n",
        "        if 'momentum_buffer' not in param_state:\n",
        "          ...\n",
        "        d_p = buf\n",
        "        p.add_(d_p, alpha=-group[\"lr\"])\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPbI2UPyFpKV",
        "colab_type": "text"
      },
      "source": [
        "Nesterov momentum\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n7sciz1KcS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SGD(Optimizer):\n",
        "    r\"\"\"Implements stochastic gradient descent (optionally with momentum).\n",
        "    Nesterov momentum is based on the formula from\n",
        "    `On the importance of initialization and momentum in deep learning`__.\n",
        "    Args:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float): learning rate\n",
        "        momentum (float, optional): momentum factor (default: 0)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        dampening (float, optional): dampening for momentum (default: 0)\n",
        "        nesterov (bool, optional): enables Nesterov momentum (default: False)\n",
        "    Example:\n",
        "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "        >>> optimizer.zero_grad()\n",
        "        >>> loss_fn(model(input), target).backward()\n",
        "        >>> optimizer.step()\n",
        "    __ http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf\n",
        "    .. note::\n",
        "        The implementation of SGD with Momentum/Nesterov subtly differs from\n",
        "        Sutskever et. al. and implementations in some other frameworks.\n",
        "        Considering the specific case of Momentum, the update can be written as\n",
        "        .. math::\n",
        "            \\begin{aligned}\n",
        "                v_{t+1} & = \\mu * v_{t} + g_{t+1}, \\\\\n",
        "                p_{t+1} & = p_{t} - \\text{lr} * v_{t+1},\n",
        "            \\end{aligned}\n",
        "        where :math:`p`, :math:`g`, :math:`v` and :math:`\\mu` denote the \n",
        "        parameters, gradient, velocity, and momentum respectively.\n",
        "        This is in contrast to Sutskever et. al. and\n",
        "        other frameworks which employ an update of the form\n",
        "        .. math::\n",
        "            \\begin{aligned}\n",
        "                v_{t+1} & = \\mu * v_{t} + \\text{lr} * g_{t+1}, \\\\\n",
        "                p_{t+1} & = p_{t} - v_{t+1}.\n",
        "            \\end{aligned}\n",
        "        The Nesterov version is analogously modified.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=required, momentum=0, dampening=0,\n",
        "                 weight_decay=0, nesterov=False):\n",
        "        if lr is not required and lr < 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if momentum < 0.0:\n",
        "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
        "        if weight_decay < 0.0:\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
        "\n",
        "        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n",
        "                        weight_decay=weight_decay, nesterov=nesterov)\n",
        "        if nesterov and (momentum <= 0 or dampening != 0):\n",
        "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
        "        super(SGD, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(SGD, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('nesterov', False)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            weight_decay = group['weight_decay']\n",
        "            momentum = group['momentum']\n",
        "            dampening = group['dampening']\n",
        "            nesterov = group['nesterov']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                d_p = p.grad\n",
        "                if weight_decay != 0:\n",
        "                    d_p = d_p.add(p, alpha=weight_decay)\n",
        "                if momentum != 0:\n",
        "                    param_state = self.state[p]\n",
        "                    if 'momentum_buffer' not in param_state:\n",
        "                        buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
        "                    else:\n",
        "                        buf = param_state['momentum_buffer']\n",
        "                        buf.mul_(momentum).add_(d_p, alpha=1 - dampening)\n",
        "                    if nesterov:\n",
        "                        d_p = d_p.add(buf, alpha=momentum)\n",
        "                    else:\n",
        "                        d_p = buf\n",
        "\n",
        "                p.add_(d_p, alpha=-group['lr'])\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnFzHrRGFuvw",
        "colab_type": "text"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arE2rw7-HbQD",
        "colab_type": "text"
      },
      "source": [
        "The easiest way to compare different models/optimizers/initialization is to plot loss after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9wzi2AoFwVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEifAT0SGfqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -r logs logs2 logs3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__nMZ6nNF625",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter(log_dir=\"logs\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNpwBljjGId5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer.add_scalar(\"plot1\", torch.tensor(1.0), global_step = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5-lBuByGXt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer.add_scalar(\"plot1\", torch.tensor(3.0), global_step = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHr1jrrVGZn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer.add_scalar(\"plot1\", torch.tensor(2.0), global_step = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnKwN-cGGbdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRw9ag4LGipk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-YBmAKmGsrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhZd6YfkG1Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter(log_dir=\"logs\")\n",
        "writer.add_scalar(\"plot2\", torch.tensor(1.0), global_step = 1)\n",
        "writer.add_scalar(\"plot2\", torch.tensor(4.0), global_step = 2)\n",
        "writer.add_scalar(\"plot2\", torch.tensor(5.0), global_step = 3)\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQi8nXgkHYZo",
        "colab_type": "text"
      },
      "source": [
        "How to draw multiple line on the same plot?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr0JBeVGHYEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter(log_dir=\"logs2/experiment1\")\n",
        "writer.add_scalar(\"plot2\", torch.tensor(1.0), global_step = 1)\n",
        "writer.add_scalar(\"plot2\", torch.tensor(3.0), global_step = 2)\n",
        "writer.add_scalar(\"plot2\", torch.tensor(2.0), global_step = 3)\n",
        "writer.close()\n",
        "writer = SummaryWriter(log_dir=\"logs2/experiment2\")\n",
        "writer.add_scalar(\"plot2\", torch.tensor(1.0), global_step = 1)\n",
        "writer.add_scalar(\"plot2\", torch.tensor(4.0), global_step = 2)\n",
        "writer.add_scalar(\"plot2\", torch.tensor(5.0), global_step = 3)\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5Gw5qkGIEXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iMZFl-qIQDN",
        "colab_type": "text"
      },
      "source": [
        "What else can we plot?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kox4vh8QIGhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter(log_dir=\"logs3\")\n",
        "writer.add_image(\"mnist_sample\", train_dataset[0][0], global_step=1)\n",
        "writer.add_image(\"mnist_sample\", train_dataset[1][0], global_step=2)\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH2mAoAMI7F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_wxgHm2I9gG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter(log_dir=\"logs4\")\n",
        "writer.add_graph(model, train_loader.__iter__().__next__()[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e0nckoIJtkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW7ZNAh9Ju0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8ab9wFnJw80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SmsS6FOJ8VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter(log_dir=\"logs5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKS527b3KXUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U-GKltNKP_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(10):\n",
        "  time.sleep(15)\n",
        "  writer.add_scalar(\"linear\", torch.tensor(epoch * 2), global_step=epoch)\n",
        "  writer.add_scalar(\"parabolic\", torch.tensor(epoch ** 2), global_step=epoch)\n",
        "  if epoch % 2 == 0:\n",
        "    writer.add_image(\"mnist\", train_dataset[epoch][0], global_step=epoch)\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8IPaAcWLfx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiE_SEQTL3_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(100):\n",
        "  writer = SummaryWriter(log_dir=\"logs6\")\n",
        "  time.sleep(5)\n",
        "  writer.add_scalar(\"linear\", torch.tensor(epoch * 2), global_step=epoch)\n",
        "  writer.add_scalar(\"parabolic\", torch.tensor(epoch ** 2), global_step=epoch)\n",
        "  if epoch % 2 == 0:\n",
        "    writer.add_image(\"mnist\", train_dataset[epoch][0], global_step=epoch)\n",
        "  writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeVhHIT_Mc-q",
        "colab_type": "text"
      },
      "source": [
        "# Assignment [10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77WpHOmbMj_m",
        "colab_type": "text"
      },
      "source": [
        "1. Update training and test function in such a way that train loss is ploted on \"train_loss\" graph, test loss on \"test_loss\" graph and accuracy on the test set on \"test_accuracy\" graph. [2]\n",
        "2. Every 5 epochs choose 9 images from test_set which are missclassified and display them in tensorboard (use add_images function of writer https://pytorch.org/docs/stable/tensorboard.html).[2]\n",
        "3. Choose 5 different gradient-decent optimizers (do not choose SGD) https://pytorch.org/docs/stable/optim.html, train model with given optimizer and with default parameters. Plot train losses on \"train_loss\" graph, test losses on \"test_loss\" graph, accuracy on \"test_accuracy\" graph. Train at least for 50 epochs. [2]\n",
        "4. In PyTorch implementation of nesterov momentum differs from one you saw at lecture. Show that it still works in the same way up to one step. [2]\n",
        "5. Train your model with LBFGS optimizer https://pytorch.org/docs/stable/optim.html. Choose history size as large as you can fit in the memory. **Impotant** you'll need to call `step` with clojure parameter. Find how to use it at https://pytorch.org/docs/stable/optim.html[2]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPZAWAVoMijM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}