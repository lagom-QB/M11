{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Practice 2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lagom-QB/M11/blob/master/Copy_of_Practice_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY2P_K6PbR4U",
        "colab_type": "text"
      },
      "source": [
        "# Keywords: modules, optimizers, dense layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UwJ0fPUb24R",
        "colab_type": "text"
      },
      "source": [
        "# High level concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A339bun3b6LD",
        "colab_type": "text"
      },
      "source": [
        "## Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrNck7Vsb-gK",
        "colab_type": "text"
      },
      "source": [
        "Modules helps organizing and composing functions and inputs (weights) together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHh0RNT6bQa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from torch.nn.modules import loss\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6xmxvkJcTRA",
        "colab_type": "text"
      },
      "source": [
        "Some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbIVrzkecL3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e61ad52c-7b75-44ce-bdc5-4ce801a9c00d"
      },
      "source": [
        "linear = nn.Linear(10, 10)\n",
        "linear"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=10, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqASjjZQckL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3dedb571-9a13-4f71-a945-19edb51ef1c1"
      },
      "source": [
        "linear(torch.tensor([1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,0.0]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.2866, -6.1020,  3.7358,  1.5607, -1.5761, -1.2221, -5.1340,  1.0736,\n",
              "        -0.8882,  3.5746], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJcHLHt6cXAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a031aff-7939-49d3-bb85-43e4dec8358a"
      },
      "source": [
        "relu = nn.ReLU()\n",
        "relu\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ReLU()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzrQBmD6cfr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73c7e027-50bb-482b-f0bf-e0230ff8433a"
      },
      "source": [
        "x = torch.tensor([-1.0])\n",
        "relu(x)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4CehSLxcjyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eba268e6-5eee-48d3-acdf-2e039d9b93ad"
      },
      "source": [
        "tanh = nn.Tanh()\n",
        "tanh"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tanh()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfNrJGRnc1po",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06304903-475e-444f-de6a-8873f3e866a1"
      },
      "source": [
        "dropout = nn.Dropout(0.45, inplace=True)\n",
        "dropout"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dropout(p=0.45, inplace=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RFklgV1c3Lp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9eae77ec-6a6f-43a0-8318-cd22bb06884f"
      },
      "source": [
        "sequential = nn.Sequential(nn.Linear(10, 100), nn.Tanh(), nn.Linear(100,100), nn.Dropout(0.4, inplace = True), nn.Linear(100,10))\n",
        "sequential"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=100, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (3): Dropout(p=0.4, inplace=True)\n",
              "  (4): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH30QbbVc41R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "8df2e39c-5660-4206-d931-f48184ff1f15"
      },
      "source": [
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lin1 = nn.Linear(10,100)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.lin2 = nn.Linear(100,100)\n",
        "        self.lin3 = nn.Linear(100,100)\n",
        "        self.lin4 = nn.Linear(100,10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin3(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin4(x)\n",
        "        return x\n",
        "net = Net()\n",
        "net\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (lin1): Linear(in_features=10, out_features=100, bias=True)\n",
              "  (act1): Tanh()\n",
              "  (lin2): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (lin3): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (lin4): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hJXnvzvc677",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1319ed60-69c7-473f-ac1b-2864d8f44600"
      },
      "source": [
        "cross_entropy = loss.CrossEntropyLoss()\n",
        "cross_entropy\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PakWOAlNHa8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import Module"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZaSSef3Hc7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import Parameter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhScgmbhF-rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Power(Module):\n",
        "\n",
        "    __constants__ = ['exponent']\n",
        "\n",
        "    def __init__(self, exponent=3):\n",
        "        super().__init__()\n",
        "        self.exponent = exponent\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.pow(input, self.exponent)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return f'exponent={self.exponent}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z_jvFGhOt18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "947a10dd-8bf9-44d3-9e12-43cf0268e91d"
      },
      "source": [
        "Power(exponent = 4)\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Power(exponent=4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1uAg4zzGrWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WPower(Module):    \n",
        "    def __init__(self, ):\n",
        "        super().__init__()\n",
        "        self.exponent = Parameter(torch.Tensor(1))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init.uniform_(self.exponent, a=math.sqrt(5))\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.pow(input, self.exponent)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YemfgVcdIFB",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeszfvqidJ_o",
        "colab_type": "text"
      },
      "source": [
        "Some models are not just functions, but they also have internal parameters (weights/graph inputs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbYduaVOdDID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "8580b4e2-b2ed-460f-eba9-1911f7ef65a3"
      },
      "source": [
        "list(linear.parameters())\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.1841, -0.2706, -0.0248, -0.0374, -0.2025, -0.2800,  0.1331, -0.1579,\n",
              "           0.2137, -0.0756],\n",
              "         [ 0.3044, -0.1330, -0.3043, -0.2973, -0.0440, -0.3158,  0.2321, -0.1708,\n",
              "          -0.2097, -0.0177],\n",
              "         [ 0.0073, -0.1068, -0.0715,  0.2875, -0.2889,  0.2396, -0.2814,  0.3076,\n",
              "           0.2679,  0.1112],\n",
              "         [ 0.1610,  0.2035, -0.0718,  0.2903,  0.2890,  0.2556,  0.2927, -0.3029,\n",
              "          -0.2906, -0.0708],\n",
              "         [ 0.2511,  0.1973, -0.1474,  0.1887, -0.1552, -0.3096,  0.2602, -0.1486,\n",
              "          -0.0490, -0.2428],\n",
              "         [ 0.2463, -0.0933,  0.2715,  0.0695, -0.1928, -0.0424, -0.0567,  0.1480,\n",
              "          -0.2343,  0.0064],\n",
              "         [-0.2895, -0.1613,  0.2282, -0.2646, -0.1181,  0.0240, -0.0506, -0.1239,\n",
              "          -0.2742, -0.3085],\n",
              "         [-0.2798, -0.2613, -0.1899, -0.1370, -0.0795,  0.2287,  0.2967,  0.0120,\n",
              "          -0.0344,  0.0325],\n",
              "         [-0.2263, -0.0347, -0.2762,  0.1199, -0.0095, -0.0934, -0.0084, -0.0961,\n",
              "           0.0980, -0.2143],\n",
              "         [ 0.1156,  0.2085,  0.0201, -0.1232,  0.1090,  0.0463, -0.2182,  0.2428,\n",
              "           0.2814, -0.1617]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.2370, -0.2952,  0.1115,  0.0576, -0.0920,  0.1653,  0.1114,  0.1556,\n",
              "          0.3099, -0.2964], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmgsM_OedbPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "79f89eb2-1624-4e89-b1d9-e1855f1c6d12"
      },
      "source": [
        "linear.weight\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.1841, -0.2706, -0.0248, -0.0374, -0.2025, -0.2800,  0.1331, -0.1579,\n",
              "          0.2137, -0.0756],\n",
              "        [ 0.3044, -0.1330, -0.3043, -0.2973, -0.0440, -0.3158,  0.2321, -0.1708,\n",
              "         -0.2097, -0.0177],\n",
              "        [ 0.0073, -0.1068, -0.0715,  0.2875, -0.2889,  0.2396, -0.2814,  0.3076,\n",
              "          0.2679,  0.1112],\n",
              "        [ 0.1610,  0.2035, -0.0718,  0.2903,  0.2890,  0.2556,  0.2927, -0.3029,\n",
              "         -0.2906, -0.0708],\n",
              "        [ 0.2511,  0.1973, -0.1474,  0.1887, -0.1552, -0.3096,  0.2602, -0.1486,\n",
              "         -0.0490, -0.2428],\n",
              "        [ 0.2463, -0.0933,  0.2715,  0.0695, -0.1928, -0.0424, -0.0567,  0.1480,\n",
              "         -0.2343,  0.0064],\n",
              "        [-0.2895, -0.1613,  0.2282, -0.2646, -0.1181,  0.0240, -0.0506, -0.1239,\n",
              "         -0.2742, -0.3085],\n",
              "        [-0.2798, -0.2613, -0.1899, -0.1370, -0.0795,  0.2287,  0.2967,  0.0120,\n",
              "         -0.0344,  0.0325],\n",
              "        [-0.2263, -0.0347, -0.2762,  0.1199, -0.0095, -0.0934, -0.0084, -0.0961,\n",
              "          0.0980, -0.2143],\n",
              "        [ 0.1156,  0.2085,  0.0201, -0.1232,  0.1090,  0.0463, -0.2182,  0.2428,\n",
              "          0.2814, -0.1617]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5f0Q3GCdeHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "753c01ae-087f-47e8-f40e-d2a4112d186c"
      },
      "source": [
        "linear.bias\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.2370, -0.2952,  0.1115,  0.0576, -0.0920,  0.1653,  0.1114,  0.1556,\n",
              "         0.3099, -0.2964], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoSzZUpfdgDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eabd512f-c0ab-415b-eba1-bbca09ce96b4"
      },
      "source": [
        "list(tanh.parameters())\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-sapuItdiYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5444953-fe2c-4684-d09d-cf78ca3047c2"
      },
      "source": [
        "list(dropout.parameters())\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aet5UQbydkp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76fbe1a1-f9bb-46f6-979d-ba256085bd5f"
      },
      "source": [
        "dropout.p "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsdfce82dtQl",
        "colab_type": "code",
        "outputId": "1b7f952a-afb1-4560-817d-d3e88bab0a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(cross_entropy.parameters())\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQT6wYz8dpPH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "8f91bd1e-16af-4cb1-cb79-a14ce2c96f39"
      },
      "source": [
        "list(map(lambda x: x.shape, list(sequential.parameters())))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([100, 10]),\n",
              " torch.Size([100]),\n",
              " torch.Size([100, 100]),\n",
              " torch.Size([100]),\n",
              " torch.Size([10, 100]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtxKoxdfdmsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "944c1905-03ec-44ec-8618-d0af25d7bcfe"
      },
      "source": [
        "list(map(lambda x: x.shape, list(net.parameters())))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([100, 10]),\n",
              " torch.Size([100]),\n",
              " torch.Size([100, 100]),\n",
              " torch.Size([100]),\n",
              " torch.Size([100, 100]),\n",
              " torch.Size([100]),\n",
              " torch.Size([10, 100]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3SN19HOdrow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40fe2307-50a0-4222-a4fd-ff8ea904c22e"
      },
      "source": [
        "list(map(lambda x: x.requires_grad, list(net.parameters())))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True, True, True, True, True, True, True, True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8zULEKKd37v",
        "colab_type": "text"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqPenEPGd7U5",
        "colab_type": "text"
      },
      "source": [
        "Each module can be in either `eval` or `train` state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFPY0TRNd6Kn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2877cfa-6ff3-492e-be93-3ac77bcec4bf"
      },
      "source": [
        "dropout.train()\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dropout(p=0.45, inplace=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPk0cHNqdw51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6dc5393a-8dc8-47f4-a577-c54b902241f5"
      },
      "source": [
        "dropout(torch.ones(10))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 1.8182, 1.8182, 0.0000, 0.0000, 1.8182, 0.0000, 0.0000,\n",
              "        1.8182])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1JnLrcLeFYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a2acb6d-39c2-4671-9e72-d8e38cc848d6"
      },
      "source": [
        "dropout.eval()\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dropout(p=0.45, inplace=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT0hgQ5PeG_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4dd148e-5b45-4c56-f708-9827f6e33155"
      },
      "source": [
        "newseq = nn.Sequential(nn.Dropout(), nn.Dropout())\n",
        "newseq(torch.ones(10))\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 4., 0., 0., 4., 0., 0., 4., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kETqU1poeKMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6a20853-d52e-4f20-c245-2e16b44bee90"
      },
      "source": [
        "newseq.eval()\n",
        "newseq(torch.ones(10))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxeKQ3r0eP9a",
        "colab_type": "text"
      },
      "source": [
        "**Important**! Train / eval mode has nothing to do with weight training. It just changes behaviour of some modules (i.e. `dropout`, `batchnorm`). For composite modules `.eval()`/`.train()` sets corresponding mode for each of its components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7rIS3A3etBO",
        "colab_type": "text"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyKkp9pcewGR",
        "colab_type": "text"
      },
      "source": [
        "Most of module have default way of parameter initialization, but sometimes we might want to init them explicitly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKX8XpoPer3N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "9aded9a6-f393-4d31-b999-ffc68d09baa7"
      },
      "source": [
        "linear.weight"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.1841, -0.2706, -0.0248, -0.0374, -0.2025, -0.2800,  0.1331, -0.1579,\n",
              "          0.2137, -0.0756],\n",
              "        [ 0.3044, -0.1330, -0.3043, -0.2973, -0.0440, -0.3158,  0.2321, -0.1708,\n",
              "         -0.2097, -0.0177],\n",
              "        [ 0.0073, -0.1068, -0.0715,  0.2875, -0.2889,  0.2396, -0.2814,  0.3076,\n",
              "          0.2679,  0.1112],\n",
              "        [ 0.1610,  0.2035, -0.0718,  0.2903,  0.2890,  0.2556,  0.2927, -0.3029,\n",
              "         -0.2906, -0.0708],\n",
              "        [ 0.2511,  0.1973, -0.1474,  0.1887, -0.1552, -0.3096,  0.2602, -0.1486,\n",
              "         -0.0490, -0.2428],\n",
              "        [ 0.2463, -0.0933,  0.2715,  0.0695, -0.1928, -0.0424, -0.0567,  0.1480,\n",
              "         -0.2343,  0.0064],\n",
              "        [-0.2895, -0.1613,  0.2282, -0.2646, -0.1181,  0.0240, -0.0506, -0.1239,\n",
              "         -0.2742, -0.3085],\n",
              "        [-0.2798, -0.2613, -0.1899, -0.1370, -0.0795,  0.2287,  0.2967,  0.0120,\n",
              "         -0.0344,  0.0325],\n",
              "        [-0.2263, -0.0347, -0.2762,  0.1199, -0.0095, -0.0934, -0.0084, -0.0961,\n",
              "          0.0980, -0.2143],\n",
              "        [ 0.1156,  0.2085,  0.0201, -0.1232,  0.1090,  0.0463, -0.2182,  0.2428,\n",
              "          0.2814, -0.1617]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8LyFiCweOYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "3f5632e8-ccf2-4f20-a691-9c265b849536"
      },
      "source": [
        "init.xavier_uniform_(linear.weight)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.3964, -0.3738, -0.1707,  0.2043, -0.5209, -0.3062,  0.2264,  0.0719,\n",
              "         -0.3809, -0.2267],\n",
              "        [ 0.4128, -0.5404, -0.4449,  0.3523, -0.3056,  0.5182,  0.3036, -0.4446,\n",
              "          0.3724,  0.1884],\n",
              "        [ 0.5032, -0.1352,  0.5015, -0.1440,  0.2471,  0.2670, -0.0344,  0.5327,\n",
              "         -0.0842, -0.0143],\n",
              "        [-0.0517, -0.3589,  0.4782,  0.1596,  0.1457, -0.2698,  0.4296,  0.0849,\n",
              "         -0.4978,  0.0292],\n",
              "        [-0.2763,  0.0665, -0.4960,  0.3620, -0.2832,  0.0552, -0.0335,  0.4341,\n",
              "          0.2753, -0.2730],\n",
              "        [-0.0840,  0.5242,  0.1976,  0.1535, -0.4351,  0.3219,  0.2517, -0.0349,\n",
              "         -0.4192, -0.1800],\n",
              "        [ 0.0278,  0.4917, -0.4840,  0.1552, -0.1271, -0.1368, -0.2442, -0.4015,\n",
              "         -0.4935,  0.3335],\n",
              "        [ 0.4641, -0.0811, -0.3439, -0.4597, -0.4653,  0.4271, -0.1744,  0.2252,\n",
              "          0.4277, -0.0655],\n",
              "        [-0.2928, -0.5395,  0.0479, -0.0527, -0.0259,  0.1733,  0.0995, -0.1139,\n",
              "         -0.4507, -0.0180],\n",
              "        [-0.4996,  0.4933,  0.0880, -0.4892, -0.2833,  0.4554,  0.3995, -0.0531,\n",
              "         -0.3586,  0.4772]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og6vAbZvfHRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "3f57a86d-c57c-4c0a-c35d-eae237205eef"
      },
      "source": [
        "init.constant_(linear.weight, 1.0)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6X6oRr2fJ6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "af981bdd-9f81-493d-8071-380677211d1c"
      },
      "source": [
        "list(linear.parameters())\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.2370, -0.2952,  0.1115,  0.0576, -0.0920,  0.1653,  0.1114,  0.1556,\n",
              "          0.3099, -0.2964], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NcEej-6fL5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "a6d39abb-6b54-4dfd-8655-ca24aeaf338e"
      },
      "source": [
        "for param in linear.parameters():\n",
        "    init.uniform_(param, -12, 12)\n",
        "list(linear.parameters())"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ -0.8955,  -7.3200,  11.8042,   2.3805,  -1.9371,   6.2361,  -6.1504,\n",
              "            5.4821,  -0.7473, -11.7750],\n",
              "         [ -9.6005,   7.2515,  -8.3429,   9.0277,  -2.2263,  -8.1955,   2.4189,\n",
              "           -6.3216,   1.6924,   3.3800],\n",
              "         [ 11.7391,  -1.9932,   2.2595,  -5.4431,  11.7544,  -8.7856,   3.1187,\n",
              "           -9.1097,   2.9110,   4.6401],\n",
              "         [  9.0106, -10.9753,  -6.4513,   7.0419,  -6.4194,   5.6170,  10.9282,\n",
              "           -1.9731,   4.2670,  -0.5721],\n",
              "         [  7.6583,   1.2211,  -1.7389,   8.4438,  -0.2160,  -6.3735,   9.8945,\n",
              "           11.5802,  -6.2088,  -5.4466],\n",
              "         [  4.3059,   4.8857,  -1.2377,  -4.9239,  -2.7792,  -1.2092,  -1.7010,\n",
              "           11.1698,  -4.5067,  11.0237],\n",
              "         [  0.0683,   8.7704,   3.3154, -10.8260,  -6.4225,  -9.1574,  -8.4022,\n",
              "          -11.4604,  -6.0724,   0.9404],\n",
              "         [  2.0001,  10.5815,   9.3413,  -4.2864,  -2.3873,  -7.0063,   4.8950,\n",
              "           11.0870,  -1.1142,   2.8749],\n",
              "         [  6.9599,  -3.8676,   2.1985,   7.9798,   7.4785,  -0.7311,  -7.9347,\n",
              "          -11.0931,   6.4995,   6.7677],\n",
              "         [  3.2517,   6.6997,  -0.5090,  10.0660,  -4.8954,   7.5512,  -8.4817,\n",
              "          -11.5429,  -7.7635,  -1.3982]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 4.4159,  4.9748, 10.0845,  3.2926, 11.7183, 10.5313,  0.3938, -3.0098,\n",
              "          5.8538,  4.6145], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bczsQJD_fXJF",
        "colab_type": "text"
      },
      "source": [
        "You can find more initialization functions here: https://pytorch.org/docs/master/nn.html#torch-nn-init."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-HlBUMMfooa",
        "colab_type": "text"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QcAvjRJfvsT",
        "colab_type": "text"
      },
      "source": [
        "Torch has a reach collection of optimizers built-in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D4SLAamfONk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_zpzWMggMHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([1.0], requires_grad = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfWQxhE3gOC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = optim.SGD([x], lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80K1tz4ugP_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x * 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS49qBGzgTEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0nHcNqVgWRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71a08f5f-adad-408a-a57d-e5057243cd48"
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuVGUuqPgYTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr-tEtKEgaIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e42df5b-6e8b-456b-cfb6-2dbb034d043a"
      },
      "source": [
        "x"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.8000], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0dKVjoYgb_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c9a1c6b-be14-4f26-dfed-5ac556a77b22"
      },
      "source": [
        "x.grad\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HkkGT9igdst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd.zero_grad()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8eRwxRQgfNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84c07726-1d2d-4997-f887-176f4d69bab3"
      },
      "source": [
        "x.grad\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bbVM2MHgiWQ",
        "colab_type": "text"
      },
      "source": [
        "# First Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIFr-KUjgmR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKSiYasbgrQ3",
        "colab_type": "text"
      },
      "source": [
        "Let's downlad MNIST --- dataset of handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CaQGiyMgrnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = datasets.MNIST('/data', train=True, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                ]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3h5RcNngxnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = datasets.MNIST('../data', train=False, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VreNjs_ghAEI",
        "colab_type": "text"
      },
      "source": [
        "Dataloaders are responsible for data loading. They help us to split dataset in batches and shuffles the dataset(otherwise each buch will have only variants of a single digit). We will look inside them later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isUaEilOg79-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JwLAUASg-3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "toPIL = transforms.ToPILImage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNt3vzcWheef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def example(i):\n",
        "    print(train_dataset[i][1])\n",
        "    return toPIL(train_dataset[i][0]).resize((256, 256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS0IXIAOk_8K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "8ad03bad-228c-4523-c1db-0f73f4d3324b"
      },
      "source": [
        "example(9)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F2993E68F60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT3VcfTNhg9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "3a55d9ee-c1ab-48b6-8da0-4d1a623ab877"
      },
      "source": [
        "example(10)\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F2993FC2080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukAEeDcShinq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "dfd7addb-c813-4f88-c31b-aa583e6a2e2a"
      },
      "source": [
        "train_loader.__iter__().__next__()[1]\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 9, 7, 0, 1, 4, 9, 7, 7, 7, 3, 0, 5, 3, 1, 9, 8, 7, 5, 6, 6, 8, 3,\n",
              "        2, 6, 6, 5, 9, 0, 2, 8, 7, 6, 0, 9, 9, 9, 1, 2, 7, 7, 2, 0, 6, 9, 1, 4,\n",
              "        6, 3, 7, 7, 2, 5, 1, 2, 3, 2, 8, 2, 8, 3, 8, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2xbqs4CiAxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b76b04ac-016d-4f53-97db-70053fbb6189"
      },
      "source": [
        "train_loader.__iter__().__next__()[0].shape\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBOrXp1ZiDQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "f872d931-1b1b-4f64-9298-6da87e23e9f9"
      },
      "source": [
        "toPIL(train_loader.__iter__().__next__()[0][0]).resize((256,256))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F2994020B70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU728eD_iVwF",
        "colab_type": "text"
      },
      "source": [
        "Let's write a simple helper module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drFE7ng0iaY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        return x.view(batch_size, -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyfJfxlYiGY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "for param in model.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar9AwM6aFVxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8q6alogikey",
        "colab_type": "text"
      },
      "source": [
        "Why do we need `Flatten` module?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1ioiHwWiriu",
        "colab_type": "text"
      },
      "source": [
        "Setup an optimizer:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_ZaRtLhiQpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuGF-VaJixR-",
        "colab_type": "text"
      },
      "source": [
        "Choose a loss function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97rK7imziwi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = loss.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY1JXkwsi4B7",
        "colab_type": "text"
      },
      "source": [
        "And start training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTGlEEUsi21g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, optimizer, loss_function, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_function(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 200 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJZcV3I1it47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, test_loader, loss_function):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "\n",
        "    y_prediction = []\n",
        "    \n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            test_loss += loss_function(output, target).sum().item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            y_prediction.append(output)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    #     test_loss, correct, len(test_loader.dataset),\n",
        "    #     100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    flat_list = [item for sublist in y_prediction for item in sublist]\n",
        "\n",
        "    print(len(flat_list))\n",
        "    return flat_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMHY4BfdjJFr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "579f607c-96c8-49f0-fb79-8449c7f84c2a"
      },
      "source": [
        " %%time\n",
        "\n",
        "#  for epoch in range(1, 10):\n",
        "#         train(model, train_loader, optimizer, loss_function, epoch)\n",
        "#         test(model, test_loader, loss_function)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15 s, sys: 4 s, total: 19 s\n",
            "Wall time: 23.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v18YmlwUoxY8",
        "colab_type": "text"
      },
      "source": [
        "# Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W20EUe7AxioK",
        "colab_type": "text"
      },
      "source": [
        "## Due to 10AM, 20.05.2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO6zst4UpcMR",
        "colab_type": "text"
      },
      "source": [
        "## 1. MNIST playground [10]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et-qYR-M9PIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------------- 1. ----------------------------------- \n",
        "# For the test set; it has a constant percentage loss of 98% from the get go, \n",
        "#     Lying between Accuracy: 9821/10000 and Accuracy: 9819/10000\n",
        "#     So i'll say the test accuracy is somewhat comstant\n",
        "\n",
        "# -------------------- 2. ----------------------------------- \n",
        "# example(4321) #The 0 looks like a 6 to me\n",
        "# example(600) #The nine looks like a 1 to me\n",
        "# example(4542) #Is that a 2?\n",
        "# example(56742) #This 9 is a joke"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLi6gyxB9V1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ass_test(model, test_loader, loss_function):\n",
        "    y_predictions = []\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            \n",
        "            output = model(data)\n",
        "            \n",
        "            test_loss += loss_function(output, target).sum().item()\n",
        "            \n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            \n",
        "            y_predictions.append(pred)\n",
        "            \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    return [item for sublist in y_predictions for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjSuqqK1jN9j",
        "colab_type": "code",
        "outputId": "974166d7-f74a-4be9-e933-7d053139276a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#---------------------------------------------3 ----------------------------------------------\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(0, 105):\n",
        "      train(model, train_loader, optimizer, loss_function, epoch)\n",
        "      ass_test(model1, test_loader, loss_function)\n",
        "\n",
        "labels = test_dataset.targets\n",
        "y_pred = ass_test(model, test_loader, loss_function)\n",
        "\n",
        "confusion_matrix(labels, y_pred)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.289697\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.225070\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.311553\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.179538\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.158620\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.514318\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.148604\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.182951\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.158368\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.138909\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.113120\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.121859\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.040371\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.146750\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.039738\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.136310\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.009897\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.045270\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.133308\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.040677\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.041161\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.012629\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.064380\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.019058\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.070971\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.071081\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.052861\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.016140\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.050335\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.032305\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.050954\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.006945\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.048213\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.023941\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.051400\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.015212\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.003921\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.026524\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.002569\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.023646\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.030038\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.014519\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.004588\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.045450\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.007640\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.003715\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.006346\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.005235\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.065409\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.008133\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.012104\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.001759\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.002389\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.002145\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.001547\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.003561\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.001541\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.008623\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.004179\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.006313\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.001420\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.004974\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.004769\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.000813\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.007458\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.004249\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.002527\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.001276\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.002630\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.001904\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.004076\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.002806\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.001376\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.002202\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.001067\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.003093\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.024301\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.004020\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.000910\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.001516\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000678\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.002199\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.000689\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.000590\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.003562\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.000876\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.000259\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.004121\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.001766\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.001527\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.001318\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.000879\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.000690\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.001819\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.001682\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.000571\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.001048\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.000881\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.001501\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.000788\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.000572\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.001428\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.000554\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.001231\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.001325\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.000339\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.001581\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.000365\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.001524\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.000581\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.000926\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.000805\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.000920\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.000520\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.000594\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.001914\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.001590\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.001617\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.002114\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.001273\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000305\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.000545\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.000577\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.000883\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.000396\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.000450\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.001106\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.000968\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.000801\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.001305\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.000706\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.000802\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.000568\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.000753\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000201\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000825\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.000449\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.000713\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.000354\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.000482\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.000565\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.000411\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.000413\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.000906\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.000528\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000986\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.000304\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.000512\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.001076\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.000768\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.001027\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.000612\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.000582\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.000539\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.000449\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.000355\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.000337\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.000563\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.000382\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.000264\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.000477\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.000637\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.000273\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.000438\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.000534\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000292\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.000716\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.000278\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.000639\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.000525\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.000261\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.000181\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.000238\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.000158\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000462\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.000683\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.000195\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.000172\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.000297\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.000334\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000215\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.000238\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.000724\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.000364\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.000834\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000186\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.000235\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.000506\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.000095\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.000447\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.000057\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.000287\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.000942\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.000270\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.000586\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.000600\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.000302\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.000505\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.000122\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.000204\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000227\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.000146\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.000235\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.000514\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.000362\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.000597\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.000403\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.000524\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.000181\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.000560\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000590\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.000470\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.000309\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.000830\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.000109\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.000214\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.000049\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.000213\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.000164\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.000559\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.000430\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.000410\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.000520\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.000219\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.000174\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000719\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.000063\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.000097\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.000215\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000429\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000243\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.000267\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.000300\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.000257\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.000452\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000255\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.000094\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.000156\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.000107\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.000267\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000144\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.000193\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.000101\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.000138\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.000122\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000224\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.000434\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.000114\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.000226\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.000379\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.000631\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.000133\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.000220\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.000297\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.000226\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.000139\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.000260\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.000089\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.000254\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.000309\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.000274\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.000221\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.000417\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.000121\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.000022\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.000338\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.000270\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.000125\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.000388\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.000120\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.000072\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.000550\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.000255\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.000580\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.000254\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.000282\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.000181\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.000057\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.000302\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.000190\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.000134\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.000155\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.000147\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.000307\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.000135\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000270\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.000491\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.000331\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.000107\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.000630\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.000119\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.000279\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.000250\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.000467\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.000187\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.000466\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.000439\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.000187\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.000211\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.000074\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.000225\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.000365\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.000076\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.000170\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.000244\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.000113\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.000211\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.000482\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.000237\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.000465\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.000292\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.000354\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.000185\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.000139\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.000379\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.000086\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.000158\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.000016\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.000118\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.000078\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.000110\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.000400\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.000049\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.000201\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.000092\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.000053\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.000224\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.000099\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.000213\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.000118\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.000115\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.000103\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.000114\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.000157\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.000159\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.000327\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.000105\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.000509\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.000118\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.000171\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.000177\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.000076\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.000175\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.000247\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.000448\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.000122\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.000333\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.000124\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.000112\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.000102\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.000146\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.000181\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.000037\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.000070\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.000071\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.000149\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 0.000392\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.000362\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.000127\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.000171\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000158\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.000080\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.000290\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.000099\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.000251\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.000192\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.000131\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.000073\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.000232\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.000033\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.000181\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.000356\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.000145\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.000041\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.000317\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.000201\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.000159\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.000127\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.000080\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.000099\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.000191\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.000331\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.000475\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.000177\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.000111\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.000117\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.000089\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.000172\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 0.000073\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.000071\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.000201\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.000172\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.000124\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.000107\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.000061\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.000309\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.000272\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.000138\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.000140\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.000256\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.000076\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.000151\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.000284\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.000113\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.000069\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.000074\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.000040\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.000080\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.000078\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.000157\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.000254\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.000268\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.000201\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.000140\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.000144\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.000316\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.000086\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.000223\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.000238\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.000105\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.000135\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.000187\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.000083\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.000110\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.000068\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000178\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.000212\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.000079\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.000170\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.000157\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.000084\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.000090\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.000096\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.000104\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.000103\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.000045\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.000034\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.000121\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.000117\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.000032\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.000076\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.000204\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.000108\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.000010\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.000029\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000151\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.000115\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.000163\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.000067\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.000117\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.000105\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.000152\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.000127\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.000112\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.000287\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.000150\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.000116\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.000123\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.000324\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.000114\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000079\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.000094\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.000191\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.000130\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.000187\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.000026\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.000087\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.000041\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.000235\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.000138\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.000141\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.000180\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.000074\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.000083\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.000135\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.000074\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.000056\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.000057\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.000054\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.000094\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000076\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.000142\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.000072\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.000047\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.000107\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.000323\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.000109\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.000062\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.000158\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.000119\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.000275\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.000113\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.000082\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.000087\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.000158\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.000082\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.000071\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.000088\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.000121\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.000094\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.000127\n",
            "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 0.000051\n",
            "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 0.000053\n",
            "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 0.000079\n",
            "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 0.000110\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 101 [0/60000 (0%)]\tLoss: 0.000094\n",
            "Train Epoch: 101 [12800/60000 (21%)]\tLoss: 0.000193\n",
            "Train Epoch: 101 [25600/60000 (43%)]\tLoss: 0.000129\n",
            "Train Epoch: 101 [38400/60000 (64%)]\tLoss: 0.000086\n",
            "Train Epoch: 101 [51200/60000 (85%)]\tLoss: 0.000078\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 102 [0/60000 (0%)]\tLoss: 0.000097\n",
            "Train Epoch: 102 [12800/60000 (21%)]\tLoss: 0.000085\n",
            "Train Epoch: 102 [25600/60000 (43%)]\tLoss: 0.000088\n",
            "Train Epoch: 102 [38400/60000 (64%)]\tLoss: 0.000096\n",
            "Train Epoch: 102 [51200/60000 (85%)]\tLoss: 0.000082\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 103 [0/60000 (0%)]\tLoss: 0.000084\n",
            "Train Epoch: 103 [12800/60000 (21%)]\tLoss: 0.000051\n",
            "Train Epoch: 103 [25600/60000 (43%)]\tLoss: 0.000149\n",
            "Train Epoch: 103 [38400/60000 (64%)]\tLoss: 0.000160\n",
            "Train Epoch: 103 [51200/60000 (85%)]\tLoss: 0.000122\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 104 [0/60000 (0%)]\tLoss: 0.000097\n",
            "Train Epoch: 104 [12800/60000 (21%)]\tLoss: 0.000085\n",
            "Train Epoch: 104 [25600/60000 (43%)]\tLoss: 0.000037\n",
            "Train Epoch: 104 [38400/60000 (64%)]\tLoss: 0.000130\n",
            "Train Epoch: 104 [51200/60000 (85%)]\tLoss: 0.000151\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9835/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 96, 107,  97, 107, 102,  90,  94, 104,  88,  95],\n",
              "       [118, 113, 123, 119, 122, 103, 103, 118,  99, 117],\n",
              "       [105, 128, 104, 103, 100,  91, 107,  99, 100,  95],\n",
              "       [ 96, 133,  96,  83,  91,  86, 101, 112, 108, 104],\n",
              "       [ 76, 111, 102, 104, 106,  90,  93,  95, 108,  97],\n",
              "       [ 94, 100,  98,  96,  85,  71,  82,  92,  79,  95],\n",
              "       [ 98, 113, 100,  84, 100,  79,  95,  89,  87, 113],\n",
              "       [ 98, 110, 107, 110,  99,  89, 105, 105,  99, 106],\n",
              "       [109, 111,  93,  99,  94,  86,  83, 114,  96,  89],\n",
              "       [ 94, 107, 115, 107,  81, 104,  97, 100, 110,  94]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4lJfekJBvv1",
        "colab_type": "code",
        "outputId": "6f9c71f4-501f-4d4c-8469-16835253ae1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "#  -----------------------------------------4 -----------------------------------------------\n",
        "model1 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer1 = optim.SGD(model1.parameters(), lr=0.1)\n",
        "for param in model1.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)\n",
        "for epoch in range(0, 105):\n",
        "      train(model1, train_loader, optimizer1, loss_function, epoch)\n",
        "      ass_test(model1, test_loader, loss_function)\n",
        "\n",
        "# This takes about 2mins (probably bc i did just 5 iterations) and has test accuracy of 95%-97%"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.327614\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.322788\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.180111\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.170397\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.106102\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9525/10000 (95%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.165890\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.222739\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.179312\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.132613\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.065397\n",
            "\n",
            "Test set: Average loss: 0.0018, Accuracy: 9613/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.076624\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.103470\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.184033\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.074030\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.047837\n",
            "\n",
            "Test set: Average loss: 0.0015, Accuracy: 9687/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.113985\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.071044\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.050360\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.009479\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.013190\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9699/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.015062\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.024323\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.042041\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.015052\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.011494\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9762/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.007203\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.012336\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.028468\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.004611\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.018395\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9758/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.006198\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.017516\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.006494\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.037455\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.022166\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9754/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.012296\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.007218\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.006419\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.001539\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.004429\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9782/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.005652\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.003033\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.007109\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.002373\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.002317\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9788/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.002724\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.002174\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.006261\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.004501\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.005089\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9793/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.002131\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.001259\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.004971\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.004251\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.002366\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9794/10000 (98%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.001600\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.002583\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.006733\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.017719\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.001976\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9800/10000 (98%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.002405\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.002149\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.003182\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.001240\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.001207\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9795/10000 (98%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.001825\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.002954\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.002220\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.001770\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.001096\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9794/10000 (98%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.000258\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.001499\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.004014\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.001386\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.001706\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.001547\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.001371\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.001380\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.001196\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.002765\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.001133\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.001880\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.000472\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.000914\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.002049\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.001691\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.002410\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.001057\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.000304\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.000410\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000617\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.001628\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.004315\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.002029\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.001112\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.000736\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.000629\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.000786\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.000709\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.000809\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.002353\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.000473\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.000156\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.000413\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.000769\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.001015\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.001134\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.001048\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.000454\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.000538\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9800/10000 (98%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.000375\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.000800\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.000664\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.000490\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.001005\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9799/10000 (98%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000445\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.000717\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.001327\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.000475\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.000990\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000382\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.000828\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.000777\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.000364\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.000451\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.000851\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.002080\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.000518\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.000531\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.000177\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.000779\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.000873\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.000415\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.000977\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000194\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000627\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.000828\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.000554\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.000186\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.000268\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.000418\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.000548\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.000716\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.000825\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.000362\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9808/10000 (98%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000427\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.000741\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.001048\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.000959\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.000822\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.000669\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.000279\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.000365\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.000586\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.000932\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.000374\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.000878\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.000474\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.000232\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.000696\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.000558\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.000370\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.000295\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.000900\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.000635\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000798\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.000281\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.000470\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.000660\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.000461\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.000325\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.000787\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.000702\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.000374\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000183\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9809/10000 (98%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.000332\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.000503\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.001217\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.000527\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.000174\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000174\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.000542\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.000325\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.000653\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.000133\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9800/10000 (98%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000813\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.000405\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.000435\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.000510\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.000382\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.000261\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.000259\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.000694\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.000594\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.000350\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.000889\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.000667\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.000323\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.000392\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.000249\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9800/10000 (98%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000292\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.000334\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.000623\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.000344\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.000128\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.000333\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.000439\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.000275\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.000124\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.000514\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000447\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.000248\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.000281\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.000154\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.000501\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9799/10000 (98%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.000555\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.000939\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.000328\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.000158\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.000397\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9809/10000 (98%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.000637\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.000285\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.000224\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.000569\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.000263\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000487\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.000642\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.000127\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.000153\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000254\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000354\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.000252\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.000290\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.000618\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.000179\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000468\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.000460\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.000311\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.000431\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.000675\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000162\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.000322\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.000260\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.000403\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.000193\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000184\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.000193\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.000231\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.000258\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.000191\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.000326\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.000196\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.000209\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.000213\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.000393\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.000558\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.000334\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.000145\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.000320\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.000089\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9800/10000 (98%)\n",
            "\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.000342\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.000168\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.000542\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.000293\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.000243\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.000233\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.000165\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.000306\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.000401\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.000188\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.000297\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.000260\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.000211\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.000095\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.000164\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.000173\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.000151\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.000095\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.000269\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.000130\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.000324\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.000086\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.000463\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.000185\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.000097\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000176\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.000280\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.000188\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.000215\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.000150\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.000216\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.000345\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.000353\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.000153\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.000087\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.000163\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.000210\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.000241\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.000268\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.000145\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.000412\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.000202\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.000150\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.000218\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.000416\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.000142\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.000136\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.000266\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.000449\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.000315\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.000135\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.000349\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.000067\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.000179\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.000168\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.000157\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.000090\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.000242\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.000241\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.000187\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.000190\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.000225\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.000261\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.000252\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.000268\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.000166\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.000140\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.000137\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.000434\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.000131\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.000168\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.000056\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.000295\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.000165\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.000188\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.000081\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.000168\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.000166\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.000240\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.000161\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.000135\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.000308\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.000177\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.000125\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.000240\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.000155\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.000342\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.000190\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.000138\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.000150\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.000164\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.000209\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.000138\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.000152\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.000284\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.000268\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 0.000295\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.000210\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.000039\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.000175\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000267\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.000179\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.000214\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.000066\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.000137\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.000113\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.000175\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.000252\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.000130\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.000260\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.000227\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.000091\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.000144\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.000262\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.000106\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.000135\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.000323\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.000205\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.000246\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.000244\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.000239\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.000229\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.000273\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.000162\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.000067\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.000085\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.000137\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.000125\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 0.000304\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.000143\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.000150\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.000115\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.000155\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.000052\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.000244\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.000171\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.000181\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.000083\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.000126\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.000177\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.000169\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.000185\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.000097\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.000308\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.000245\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9808/10000 (98%)\n",
            "\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.000196\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.000174\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.000106\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.000252\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.000373\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.000085\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.000131\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.000074\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.000098\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.000166\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.000152\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.000217\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.000086\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.000255\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.000129\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.000170\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.000056\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.000202\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.000146\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.000163\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000049\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.000191\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.000137\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.000109\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.000118\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.000110\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.000133\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.000271\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.000130\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.000189\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.000101\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.000191\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.000057\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.000115\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.000135\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.000202\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.000143\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.000164\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.000080\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.000151\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000125\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.000134\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.000098\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.000184\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.000090\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.000364\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.000195\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.000166\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.000188\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.000061\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.000113\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.000197\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.000184\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.000192\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.000038\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000132\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.000248\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.000174\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.000147\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.000122\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.000156\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.000154\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.000059\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.000059\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.000136\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.000216\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.000076\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.000107\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.000103\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.000168\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.000042\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.000189\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.000091\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.000080\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.000166\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000145\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.000208\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.000158\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.000097\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.000327\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.000184\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.000098\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.000215\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.000186\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.000182\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.000091\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.000082\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.000138\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.000186\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.000191\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9807/10000 (98%)\n",
            "\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.000078\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.000039\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.000094\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.000220\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.000061\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.000083\n",
            "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 0.000079\n",
            "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 0.000147\n",
            "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 0.000074\n",
            "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 0.000032\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Train Epoch: 101 [0/60000 (0%)]\tLoss: 0.000072\n",
            "Train Epoch: 101 [12800/60000 (21%)]\tLoss: 0.000095\n",
            "Train Epoch: 101 [25600/60000 (43%)]\tLoss: 0.000189\n",
            "Train Epoch: 101 [38400/60000 (64%)]\tLoss: 0.000150\n",
            "Train Epoch: 101 [51200/60000 (85%)]\tLoss: 0.000232\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9807/10000 (98%)\n",
            "\n",
            "Train Epoch: 102 [0/60000 (0%)]\tLoss: 0.000145\n",
            "Train Epoch: 102 [12800/60000 (21%)]\tLoss: 0.000088\n",
            "Train Epoch: 102 [25600/60000 (43%)]\tLoss: 0.000096\n",
            "Train Epoch: 102 [38400/60000 (64%)]\tLoss: 0.000115\n",
            "Train Epoch: 102 [51200/60000 (85%)]\tLoss: 0.000129\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 103 [0/60000 (0%)]\tLoss: 0.000040\n",
            "Train Epoch: 103 [12800/60000 (21%)]\tLoss: 0.000118\n",
            "Train Epoch: 103 [25600/60000 (43%)]\tLoss: 0.000104\n",
            "Train Epoch: 103 [38400/60000 (64%)]\tLoss: 0.000092\n",
            "Train Epoch: 103 [51200/60000 (85%)]\tLoss: 0.000136\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Train Epoch: 104 [0/60000 (0%)]\tLoss: 0.000147\n",
            "Train Epoch: 104 [12800/60000 (21%)]\tLoss: 0.000131\n",
            "Train Epoch: 104 [25600/60000 (43%)]\tLoss: 0.000105\n",
            "Train Epoch: 104 [38400/60000 (64%)]\tLoss: 0.000192\n",
            "Train Epoch: 104 [51200/60000 (85%)]\tLoss: 0.000213\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "CPU times: user 31min 50s, sys: 10.7 s, total: 32min 1s\n",
            "Wall time: 32min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT4ISfEWHRNd",
        "colab_type": "code",
        "outputId": "e198cb83-6968-4539-be35-d246dde5f958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "model2 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer2 = optim.SGD(model2.parameters(), lr=0.1)\n",
        "for param in model2.parameters():\n",
        "    init.uniform_(param, -1, 1)\n",
        "for epoch in range(0, 105):\n",
        "      train(model2, train_loader, optimizer2, loss_function, epoch)\n",
        "      ass_test(model2, test_loader, loss_function)\n",
        "\n",
        "#  --> Gives a test accuracy of 83% - 87%.\n",
        "#  --> Takes approximately 2 minutes ; almost same time as the previous one"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 7.337266\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.305615\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.800558\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.583531\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.582974\n",
            "\n",
            "Test set: Average loss: 0.0083, Accuracy: 8365/10000 (84%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.384020\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.282239\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.574333\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.441757\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.259030\n",
            "\n",
            "Test set: Average loss: 0.0067, Accuracy: 8667/10000 (87%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.211873\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.364755\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.449424\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.282921\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.189589\n",
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 8844/10000 (88%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.259836\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.214727\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.431771\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.214271\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.300416\n",
            "\n",
            "Test set: Average loss: 0.0057, Accuracy: 8892/10000 (89%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.215499\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.200086\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.282542\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.282340\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.411390\n",
            "\n",
            "Test set: Average loss: 0.0055, Accuracy: 8941/10000 (89%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.140695\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.148101\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.111644\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.164312\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.189320\n",
            "\n",
            "Test set: Average loss: 0.0054, Accuracy: 8996/10000 (90%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.124963\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.207980\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.106895\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.110545\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.126238\n",
            "\n",
            "Test set: Average loss: 0.0053, Accuracy: 9019/10000 (90%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.303986\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.169183\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.140463\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.097038\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.071862\n",
            "\n",
            "Test set: Average loss: 0.0053, Accuracy: 9039/10000 (90%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.125142\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.065002\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.078746\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.189282\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.183951\n",
            "\n",
            "Test set: Average loss: 0.0053, Accuracy: 9055/10000 (91%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.039801\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.088169\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.064559\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.183196\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.036076\n",
            "\n",
            "Test set: Average loss: 0.0054, Accuracy: 9064/10000 (91%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.056712\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.109167\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.027950\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.036132\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.047122\n",
            "\n",
            "Test set: Average loss: 0.0055, Accuracy: 9056/10000 (91%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.064226\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.061442\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.102848\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.161752\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.029568\n",
            "\n",
            "Test set: Average loss: 0.0055, Accuracy: 9081/10000 (91%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.038357\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.083618\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.057882\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.067598\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.180168\n",
            "\n",
            "Test set: Average loss: 0.0055, Accuracy: 9078/10000 (91%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.030292\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.035340\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.052724\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.079623\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.035368\n",
            "\n",
            "Test set: Average loss: 0.0056, Accuracy: 9073/10000 (91%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.163585\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.144022\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.061821\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.046934\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.022568\n",
            "\n",
            "Test set: Average loss: 0.0057, Accuracy: 9094/10000 (91%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.010305\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.086347\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.009819\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.078033\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.064402\n",
            "\n",
            "Test set: Average loss: 0.0058, Accuracy: 9083/10000 (91%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.055925\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.055660\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.018769\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.026367\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.043870\n",
            "\n",
            "Test set: Average loss: 0.0058, Accuracy: 9081/10000 (91%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.112687\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.016002\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.027082\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.052204\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.049509\n",
            "\n",
            "Test set: Average loss: 0.0058, Accuracy: 9075/10000 (91%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.033924\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.078202\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.054734\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.049211\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.037230\n",
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 9067/10000 (91%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.083060\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.028591\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.038671\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.039187\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.026277\n",
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 9070/10000 (91%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.019335\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.022447\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.032436\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.350679\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.072107\n",
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 9078/10000 (91%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.017210\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.088170\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.047515\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.018179\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.028223\n",
            "\n",
            "Test set: Average loss: 0.0060, Accuracy: 9079/10000 (91%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.020984\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.078075\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.016974\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.045446\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.104022\n",
            "\n",
            "Test set: Average loss: 0.0060, Accuracy: 9066/10000 (91%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.005498\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.020723\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.091512\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.075818\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.066103\n",
            "\n",
            "Test set: Average loss: 0.0061, Accuracy: 9058/10000 (91%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.129838\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.018122\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.020818\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.038976\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.028447\n",
            "\n",
            "Test set: Average loss: 0.0062, Accuracy: 9058/10000 (91%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.165865\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.032052\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.035473\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.105991\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.017241\n",
            "\n",
            "Test set: Average loss: 0.0062, Accuracy: 9058/10000 (91%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.033774\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.004250\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.027987\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.048754\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.012479\n",
            "\n",
            "Test set: Average loss: 0.0062, Accuracy: 9066/10000 (91%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.033499\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.010933\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.031050\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.083178\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.106332\n",
            "\n",
            "Test set: Average loss: 0.0062, Accuracy: 9065/10000 (91%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.012400\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.109022\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.023368\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.031432\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.041506\n",
            "\n",
            "Test set: Average loss: 0.0063, Accuracy: 9048/10000 (90%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.068556\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.008791\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.097095\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.011741\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.010391\n",
            "\n",
            "Test set: Average loss: 0.0063, Accuracy: 9049/10000 (90%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.006449\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.092534\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.070690\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.012397\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.066994\n",
            "\n",
            "Test set: Average loss: 0.0063, Accuracy: 9045/10000 (90%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.007320\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.020569\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.014172\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.024480\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.005397\n",
            "\n",
            "Test set: Average loss: 0.0064, Accuracy: 9045/10000 (90%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.007937\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.107097\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.015180\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.018430\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.010565\n",
            "\n",
            "Test set: Average loss: 0.0064, Accuracy: 9049/10000 (90%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.011092\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.129732\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.089052\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.014175\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.018718\n",
            "\n",
            "Test set: Average loss: 0.0064, Accuracy: 9047/10000 (90%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.268165\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.061533\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.058387\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.008968\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.005227\n",
            "\n",
            "Test set: Average loss: 0.0064, Accuracy: 9047/10000 (90%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.015928\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.007260\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.004389\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.018708\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.032619\n",
            "\n",
            "Test set: Average loss: 0.0065, Accuracy: 9033/10000 (90%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.118309\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.018496\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.008345\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.046472\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.015402\n",
            "\n",
            "Test set: Average loss: 0.0065, Accuracy: 9041/10000 (90%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.015350\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.003576\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.021834\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.022810\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.008011\n",
            "\n",
            "Test set: Average loss: 0.0065, Accuracy: 9049/10000 (90%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.005029\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.102226\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.022217\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.026305\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.014194\n",
            "\n",
            "Test set: Average loss: 0.0066, Accuracy: 9034/10000 (90%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.038878\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.131775\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.018181\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.072003\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.014110\n",
            "\n",
            "Test set: Average loss: 0.0065, Accuracy: 9055/10000 (91%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.005243\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.014010\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.063934\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.010168\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.008023\n",
            "\n",
            "Test set: Average loss: 0.0066, Accuracy: 9044/10000 (90%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.020796\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.084042\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.021274\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.034449\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.011813\n",
            "\n",
            "Test set: Average loss: 0.0066, Accuracy: 9050/10000 (90%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.173082\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.019887\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.008700\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.005405\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.019116\n",
            "\n",
            "Test set: Average loss: 0.0066, Accuracy: 9044/10000 (90%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.049759\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.008511\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.014820\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.005603\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.008624\n",
            "\n",
            "Test set: Average loss: 0.0067, Accuracy: 9053/10000 (91%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.104653\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.021666\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.010419\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.003352\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.106829\n",
            "\n",
            "Test set: Average loss: 0.0067, Accuracy: 9046/10000 (90%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.018933\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.053030\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.045031\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.005037\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.004127\n",
            "\n",
            "Test set: Average loss: 0.0067, Accuracy: 9054/10000 (91%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.012408\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.006992\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.006231\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.021131\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.012368\n",
            "\n",
            "Test set: Average loss: 0.0067, Accuracy: 9054/10000 (91%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.019406\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.024089\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.022381\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.018378\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.005312\n",
            "\n",
            "Test set: Average loss: 0.0067, Accuracy: 9052/10000 (91%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.032649\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.012928\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.013257\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.003367\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.011595\n",
            "\n",
            "Test set: Average loss: 0.0067, Accuracy: 9041/10000 (90%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.019802\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.006112\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.014681\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.014996\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.008348\n",
            "\n",
            "Test set: Average loss: 0.0067, Accuracy: 9042/10000 (90%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.088675\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.086041\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.007310\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.055657\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.022274\n",
            "\n",
            "Test set: Average loss: 0.0068, Accuracy: 9053/10000 (91%)\n",
            "\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.046585\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.006257\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.004209\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.011742\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.009340\n",
            "\n",
            "Test set: Average loss: 0.0068, Accuracy: 9050/10000 (90%)\n",
            "\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.004081\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.007786\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.067558\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.176500\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.010202\n",
            "\n",
            "Test set: Average loss: 0.0069, Accuracy: 9049/10000 (90%)\n",
            "\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.054687\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.004969\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.036374\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.022870\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.003976\n",
            "\n",
            "Test set: Average loss: 0.0069, Accuracy: 9047/10000 (90%)\n",
            "\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.008456\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.031444\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.003837\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.005509\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.039313\n",
            "\n",
            "Test set: Average loss: 0.0069, Accuracy: 9054/10000 (91%)\n",
            "\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.006442\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.009964\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.009473\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.013100\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.143827\n",
            "\n",
            "Test set: Average loss: 0.0069, Accuracy: 9052/10000 (91%)\n",
            "\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.007083\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.023747\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.008740\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.126851\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.081906\n",
            "\n",
            "Test set: Average loss: 0.0069, Accuracy: 9050/10000 (90%)\n",
            "\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.005873\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.016433\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.006510\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.070705\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.003258\n",
            "\n",
            "Test set: Average loss: 0.0069, Accuracy: 9049/10000 (90%)\n",
            "\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.010606\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.004817\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.034708\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.005358\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.014458\n",
            "\n",
            "Test set: Average loss: 0.0069, Accuracy: 9053/10000 (91%)\n",
            "\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.003328\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.003593\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.093891\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.011502\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.011996\n",
            "\n",
            "Test set: Average loss: 0.0070, Accuracy: 9056/10000 (91%)\n",
            "\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.159767\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.019746\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.013043\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.051745\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.003808\n",
            "\n",
            "Test set: Average loss: 0.0070, Accuracy: 9043/10000 (90%)\n",
            "\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.002766\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.008999\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.032992\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.006714\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.004482\n",
            "\n",
            "Test set: Average loss: 0.0070, Accuracy: 9056/10000 (91%)\n",
            "\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.008119\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.031217\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.003466\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.009406\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.005203\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 9047/10000 (90%)\n",
            "\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.022867\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.005953\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.007962\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.009366\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.040811\n",
            "\n",
            "Test set: Average loss: 0.0070, Accuracy: 9048/10000 (90%)\n",
            "\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.014397\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.003323\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.001933\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.007623\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.020012\n",
            "\n",
            "Test set: Average loss: 0.0070, Accuracy: 9055/10000 (91%)\n",
            "\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.022406\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.040914\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.006488\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.031629\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.008413\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 9047/10000 (90%)\n",
            "\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.001823\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.008437\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.011669\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.008782\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.012994\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 9048/10000 (90%)\n",
            "\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.014587\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.074796\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.048922\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.006755\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.008463\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 9049/10000 (90%)\n",
            "\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.024453\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.006075\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.009217\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.003832\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.005500\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 9049/10000 (90%)\n",
            "\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.001612\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.018363\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.019867\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.022093\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.212327\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 9046/10000 (90%)\n",
            "\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.021266\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.003503\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.083750\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.003962\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.004649\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 9046/10000 (90%)\n",
            "\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.008065\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 0.001555\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.003890\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.011541\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.005744\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 9038/10000 (90%)\n",
            "\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.002923\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.008184\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.002527\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.007746\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.013016\n",
            "\n",
            "Test set: Average loss: 0.0073, Accuracy: 9042/10000 (90%)\n",
            "\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.056925\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.003626\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.013937\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.002574\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.007289\n",
            "\n",
            "Test set: Average loss: 0.0073, Accuracy: 9048/10000 (90%)\n",
            "\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.001511\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.006001\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.006788\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.002707\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.029656\n",
            "\n",
            "Test set: Average loss: 0.0072, Accuracy: 9035/10000 (90%)\n",
            "\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.069097\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.029148\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.015106\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.027564\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.002402\n",
            "\n",
            "Test set: Average loss: 0.0073, Accuracy: 9036/10000 (90%)\n",
            "\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.023822\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.030452\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.008151\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.012212\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.004155\n",
            "\n",
            "Test set: Average loss: 0.0073, Accuracy: 9037/10000 (90%)\n",
            "\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.002948\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.025509\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.002339\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 0.008526\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.003605\n",
            "\n",
            "Test set: Average loss: 0.0073, Accuracy: 9041/10000 (90%)\n",
            "\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.004067\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.005033\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.002062\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.003582\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.002485\n",
            "\n",
            "Test set: Average loss: 0.0073, Accuracy: 9042/10000 (90%)\n",
            "\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.007081\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.007109\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.057419\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.011467\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.007328\n",
            "\n",
            "Test set: Average loss: 0.0073, Accuracy: 9036/10000 (90%)\n",
            "\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.004898\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.003555\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.017722\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.004819\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.026224\n",
            "\n",
            "Test set: Average loss: 0.0073, Accuracy: 9029/10000 (90%)\n",
            "\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.002658\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.004198\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.016440\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.003427\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.011487\n",
            "\n",
            "Test set: Average loss: 0.0074, Accuracy: 9031/10000 (90%)\n",
            "\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.002838\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.009689\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.003575\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.004177\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.054397\n",
            "\n",
            "Test set: Average loss: 0.0074, Accuracy: 9034/10000 (90%)\n",
            "\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.058652\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.008611\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.026500\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.002417\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.004670\n",
            "\n",
            "Test set: Average loss: 0.0074, Accuracy: 9034/10000 (90%)\n",
            "\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.001323\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.002647\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.040474\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.077747\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.007615\n",
            "\n",
            "Test set: Average loss: 0.0074, Accuracy: 9033/10000 (90%)\n",
            "\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.007515\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.166593\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.018779\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.012465\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.017696\n",
            "\n",
            "Test set: Average loss: 0.0075, Accuracy: 9029/10000 (90%)\n",
            "\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.001563\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.069902\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.010525\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.004336\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.003572\n",
            "\n",
            "Test set: Average loss: 0.0074, Accuracy: 9037/10000 (90%)\n",
            "\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.010974\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.001159\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.004079\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.002647\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.022287\n",
            "\n",
            "Test set: Average loss: 0.0075, Accuracy: 9030/10000 (90%)\n",
            "\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.001712\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.037021\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.002483\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.034149\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.003608\n",
            "\n",
            "Test set: Average loss: 0.0075, Accuracy: 9036/10000 (90%)\n",
            "\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.005166\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.002945\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.022740\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.008697\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.001046\n",
            "\n",
            "Test set: Average loss: 0.0075, Accuracy: 9034/10000 (90%)\n",
            "\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.027555\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.005525\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.009728\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.004288\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.007848\n",
            "\n",
            "Test set: Average loss: 0.0075, Accuracy: 9035/10000 (90%)\n",
            "\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.003954\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.020955\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.003695\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.017102\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.012018\n",
            "\n",
            "Test set: Average loss: 0.0076, Accuracy: 9038/10000 (90%)\n",
            "\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.003827\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.006091\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.004885\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.013456\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.004267\n",
            "\n",
            "Test set: Average loss: 0.0076, Accuracy: 9034/10000 (90%)\n",
            "\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.175154\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.003808\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.002226\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.013070\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.015585\n",
            "\n",
            "Test set: Average loss: 0.0076, Accuracy: 9039/10000 (90%)\n",
            "\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.005080\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.005233\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.004927\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.002834\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.002460\n",
            "\n",
            "Test set: Average loss: 0.0076, Accuracy: 9037/10000 (90%)\n",
            "\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.012475\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.007040\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.018444\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.008387\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.004210\n",
            "\n",
            "Test set: Average loss: 0.0076, Accuracy: 9046/10000 (90%)\n",
            "\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000867\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.008087\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.007364\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.006043\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.003366\n",
            "\n",
            "Test set: Average loss: 0.0076, Accuracy: 9044/10000 (90%)\n",
            "\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.003172\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.000986\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.112223\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.005747\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.004210\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 9041/10000 (90%)\n",
            "\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.118307\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.003761\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.017830\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.028622\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.054874\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 9041/10000 (90%)\n",
            "\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.004337\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.003643\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.002859\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.001330\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.004128\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 9043/10000 (90%)\n",
            "\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.041646\n",
            "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 0.028399\n",
            "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 0.002114\n",
            "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 0.004278\n",
            "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 0.006897\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 9044/10000 (90%)\n",
            "\n",
            "Train Epoch: 101 [0/60000 (0%)]\tLoss: 0.003095\n",
            "Train Epoch: 101 [12800/60000 (21%)]\tLoss: 0.072612\n",
            "Train Epoch: 101 [25600/60000 (43%)]\tLoss: 0.002224\n",
            "Train Epoch: 101 [38400/60000 (64%)]\tLoss: 0.034440\n",
            "Train Epoch: 101 [51200/60000 (85%)]\tLoss: 0.003392\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 9040/10000 (90%)\n",
            "\n",
            "Train Epoch: 102 [0/60000 (0%)]\tLoss: 0.002904\n",
            "Train Epoch: 102 [12800/60000 (21%)]\tLoss: 0.006507\n",
            "Train Epoch: 102 [25600/60000 (43%)]\tLoss: 0.002586\n",
            "Train Epoch: 102 [38400/60000 (64%)]\tLoss: 0.002525\n",
            "Train Epoch: 102 [51200/60000 (85%)]\tLoss: 0.002273\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 9037/10000 (90%)\n",
            "\n",
            "Train Epoch: 103 [0/60000 (0%)]\tLoss: 0.003966\n",
            "Train Epoch: 103 [12800/60000 (21%)]\tLoss: 0.002441\n",
            "Train Epoch: 103 [25600/60000 (43%)]\tLoss: 0.001106\n",
            "Train Epoch: 103 [38400/60000 (64%)]\tLoss: 0.004469\n",
            "Train Epoch: 103 [51200/60000 (85%)]\tLoss: 0.003458\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 9036/10000 (90%)\n",
            "\n",
            "Train Epoch: 104 [0/60000 (0%)]\tLoss: 0.004016\n",
            "Train Epoch: 104 [12800/60000 (21%)]\tLoss: 0.220983\n",
            "Train Epoch: 104 [25600/60000 (43%)]\tLoss: 0.005723\n",
            "Train Epoch: 104 [38400/60000 (64%)]\tLoss: 0.003780\n",
            "Train Epoch: 104 [51200/60000 (85%)]\tLoss: 0.004831\n",
            "\n",
            "Test set: Average loss: 0.0077, Accuracy: 9041/10000 (90%)\n",
            "\n",
            "CPU times: user 32min, sys: 9.24 s, total: 32min 9s\n",
            "Wall time: 32min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gbto4UPJlh9",
        "colab_type": "code",
        "outputId": "0484e03f-b479-467f-e7c3-ea93f9e826bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "model3 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer3 = optim.SGD(model3.parameters(), lr=0.1)\n",
        "for param in model3.parameters():\n",
        "    init.uniform_(param, 0)\n",
        "for epoch in range(1, 105):\n",
        "      train(model3, train_loader, optimizer3, loss_function, epoch)\n",
        "      ass_test(model3, test_loader, loss_function)\n",
        "\n",
        "#  --> Poorest model with a Test Accuracy of 11%\n",
        "#  --> Takes the same amount of time as the previous 2"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 3.368242\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.259674\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.340664\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.090500\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.203761\n",
            "\n",
            "Test set: Average loss: 0.0357, Accuracy: 1962/10000 (20%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.318826\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.227855\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.134995\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.138198\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.255779\n",
            "\n",
            "Test set: Average loss: 0.0351, Accuracy: 1441/10000 (14%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.218840\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.129416\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.217857\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.240223\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.277918\n",
            "\n",
            "Test set: Average loss: 0.0351, Accuracy: 1809/10000 (18%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.124435\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.255437\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 2.146461\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 2.090305\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.272723\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 1803/10000 (18%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.273700\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 2.311260\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 2.220935\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 2.313039\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 2.150527\n",
            "\n",
            "Test set: Average loss: 0.0356, Accuracy: 1445/10000 (14%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.295889\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 2.326560\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 2.237426\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 2.301445\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 2.182386\n",
            "\n",
            "Test set: Average loss: 0.0356, Accuracy: 1605/10000 (16%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.297463\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 2.324178\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 2.158436\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 2.208186\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 2.217838\n",
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 1604/10000 (16%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.121362\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 2.174802\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 2.307838\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 2.094351\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 2.189517\n",
            "\n",
            "Test set: Average loss: 0.0352, Accuracy: 1519/10000 (15%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.223423\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 2.103269\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 2.228113\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 2.203470\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 2.257329\n",
            "\n",
            "Test set: Average loss: 0.0349, Accuracy: 1971/10000 (20%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.301090\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 2.084890\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 2.159060\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 2.175087\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 2.171875\n",
            "\n",
            "Test set: Average loss: 0.0353, Accuracy: 1451/10000 (15%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 2.432083\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 2.306059\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 2.204789\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 2.080269\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 2.164486\n",
            "\n",
            "Test set: Average loss: 0.0352, Accuracy: 1603/10000 (16%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 2.262435\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 2.133280\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 2.228842\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 2.171575\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 2.346900\n",
            "\n",
            "Test set: Average loss: 0.0344, Accuracy: 1980/10000 (20%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 2.176541\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 2.205176\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 2.312140\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 2.196620\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 2.212753\n",
            "\n",
            "Test set: Average loss: 0.0354, Accuracy: 1980/10000 (20%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 2.240685\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 2.117821\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 2.261644\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 2.197302\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 2.201845\n",
            "\n",
            "Test set: Average loss: 0.0357, Accuracy: 1982/10000 (20%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 2.202698\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 2.279801\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 2.241711\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 2.100927\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 2.193126\n",
            "\n",
            "Test set: Average loss: 0.0344, Accuracy: 1984/10000 (20%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 2.240177\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 2.223675\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 2.207053\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 2.272019\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 2.264358\n",
            "\n",
            "Test set: Average loss: 0.0350, Accuracy: 1830/10000 (18%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 2.241328\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 2.075210\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 2.275384\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 2.248235\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 2.176723\n",
            "\n",
            "Test set: Average loss: 0.0351, Accuracy: 1340/10000 (13%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 2.157575\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 2.278880\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 2.224851\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 2.116045\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 2.155658\n",
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 1836/10000 (18%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 2.182412\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 2.332150\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 2.109740\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 2.258266\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 2.200166\n",
            "\n",
            "Test set: Average loss: 0.0352, Accuracy: 1463/10000 (15%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 2.127856\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 2.209476\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 2.119594\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 2.220858\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 2.186939\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 1500/10000 (15%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 2.173584\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 2.182234\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 2.309904\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 2.155226\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 2.118264\n",
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 1830/10000 (18%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 2.096045\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 2.272145\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 2.123369\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 2.205865\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 2.080814\n",
            "\n",
            "Test set: Average loss: 0.0349, Accuracy: 1502/10000 (15%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 2.105149\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 2.209609\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 2.263124\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 2.182389\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 2.221273\n",
            "\n",
            "Test set: Average loss: 0.0352, Accuracy: 1352/10000 (14%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 2.243101\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 2.148610\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 2.206857\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 2.266677\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 2.115594\n",
            "\n",
            "Test set: Average loss: 0.0355, Accuracy: 1109/10000 (11%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 2.402877\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 2.202418\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 2.227490\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 2.119584\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 2.339607\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1232/10000 (12%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 2.166620\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 2.180749\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 2.165589\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 2.076073\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 2.152392\n",
            "\n",
            "Test set: Average loss: 0.0353, Accuracy: 1429/10000 (14%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 2.205497\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 2.116028\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 2.236343\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 2.128935\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 2.198705\n",
            "\n",
            "Test set: Average loss: 0.0350, Accuracy: 1619/10000 (16%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 2.265670\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 2.321548\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 2.060734\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 2.138453\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 2.219806\n",
            "\n",
            "Test set: Average loss: 0.0344, Accuracy: 1744/10000 (17%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 2.225668\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 2.065403\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 2.335234\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 2.120187\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 2.185987\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1984/10000 (20%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 2.217990\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 2.194443\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 2.190319\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 2.286694\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 2.110327\n",
            "\n",
            "Test set: Average loss: 0.0349, Accuracy: 1341/10000 (13%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 2.248191\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 2.159026\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 2.074748\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 2.209295\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 2.234124\n",
            "\n",
            "Test set: Average loss: 0.0349, Accuracy: 1352/10000 (14%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 2.278101\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 2.172179\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 2.203654\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 2.154127\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 2.077711\n",
            "\n",
            "Test set: Average loss: 0.0344, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 2.143493\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 2.123364\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 2.119082\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 2.149894\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 2.170601\n",
            "\n",
            "Test set: Average loss: 0.0355, Accuracy: 1352/10000 (14%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 2.216216\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 2.178806\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 2.224013\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 2.175626\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 2.210572\n",
            "\n",
            "Test set: Average loss: 0.0344, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 2.189009\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 2.133741\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 2.031528\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 2.256500\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 2.232013\n",
            "\n",
            "Test set: Average loss: 0.0344, Accuracy: 1826/10000 (18%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 2.127213\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 2.178738\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 2.162559\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 2.076111\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 2.228764\n",
            "\n",
            "Test set: Average loss: 0.0353, Accuracy: 1504/10000 (15%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 2.356359\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 2.133940\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 2.117819\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 2.203417\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 2.140084\n",
            "\n",
            "Test set: Average loss: 0.0355, Accuracy: 1831/10000 (18%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 2.293763\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 2.249012\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 2.193513\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 2.288975\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 2.204986\n",
            "\n",
            "Test set: Average loss: 0.0351, Accuracy: 1616/10000 (16%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 2.230491\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 2.020048\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 2.260911\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 2.146524\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 2.203982\n",
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 1989/10000 (20%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 2.040385\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 2.238551\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 2.103205\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 2.154305\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 2.039417\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1989/10000 (20%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 2.202719\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 2.195078\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 2.187232\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 2.305515\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 2.116352\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 1835/10000 (18%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 2.140059\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 2.149457\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 2.166726\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 2.147920\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 2.130182\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1625/10000 (16%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 2.258150\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 2.141333\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 2.208975\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 2.274119\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 2.072215\n",
            "\n",
            "Test set: Average loss: 0.0352, Accuracy: 1990/10000 (20%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 2.222624\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 2.210160\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 2.183806\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 2.192118\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 2.194798\n",
            "\n",
            "Test set: Average loss: 0.0345, Accuracy: 1620/10000 (16%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 2.198391\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 2.201011\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 2.290545\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 2.226362\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 2.228544\n",
            "\n",
            "Test set: Average loss: 0.0352, Accuracy: 1116/10000 (11%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 2.138971\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 2.180643\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 2.075298\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 2.295001\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 2.145847\n",
            "\n",
            "Test set: Average loss: 0.0349, Accuracy: 1274/10000 (13%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 2.259074\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 2.197971\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 2.225118\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 2.121229\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 2.163569\n",
            "\n",
            "Test set: Average loss: 0.0352, Accuracy: 1193/10000 (12%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 2.289276\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 2.113089\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 2.035242\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 2.167912\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 2.182416\n",
            "\n",
            "Test set: Average loss: 0.0349, Accuracy: 1749/10000 (17%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 2.179546\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 2.058602\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 2.149459\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 2.240708\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 2.193215\n",
            "\n",
            "Test set: Average loss: 0.0354, Accuracy: 1352/10000 (14%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 2.116579\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 2.060902\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 2.137122\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 2.200077\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 2.195612\n",
            "\n",
            "Test set: Average loss: 0.0358, Accuracy: 1516/10000 (15%)\n",
            "\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 2.279491\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 2.237904\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 2.231306\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 2.072360\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 2.163880\n",
            "\n",
            "Test set: Average loss: 0.0349, Accuracy: 1494/10000 (15%)\n",
            "\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 2.272992\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 2.210146\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 2.212866\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 2.218162\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 2.326882\n",
            "\n",
            "Test set: Average loss: 0.0343, Accuracy: 1838/10000 (18%)\n",
            "\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 2.198884\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 2.149757\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 2.077228\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 2.081574\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 2.153201\n",
            "\n",
            "Test set: Average loss: 0.0351, Accuracy: 1992/10000 (20%)\n",
            "\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 2.242449\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 2.216622\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 2.188873\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 2.229492\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 2.175753\n",
            "\n",
            "Test set: Average loss: 0.0349, Accuracy: 1629/10000 (16%)\n",
            "\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 2.102282\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 2.217679\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 2.115822\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 2.166181\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 2.085575\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1837/10000 (18%)\n",
            "\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 2.188821\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 2.068105\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 2.071431\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 2.184464\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 2.146729\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1844/10000 (18%)\n",
            "\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 1.959903\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 2.159947\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 2.263595\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 2.104145\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 2.305150\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 1351/10000 (14%)\n",
            "\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 2.244203\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 2.216233\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 2.127194\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 2.123660\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 2.178151\n",
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 1630/10000 (16%)\n",
            "\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 2.138116\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 2.200903\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 2.229326\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 2.127750\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 2.105848\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 1628/10000 (16%)\n",
            "\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 2.103715\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 2.202371\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 2.189819\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 2.283520\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 2.325425\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 1753/10000 (18%)\n",
            "\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 2.101360\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 2.047615\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 2.195722\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 2.294757\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 2.065655\n",
            "\n",
            "Test set: Average loss: 0.0368, Accuracy: 1349/10000 (13%)\n",
            "\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 2.385743\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 2.212388\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 2.215981\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 2.165715\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 2.165143\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1994/10000 (20%)\n",
            "\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 2.174648\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 2.160960\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 2.182618\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 2.107009\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 2.142492\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1840/10000 (18%)\n",
            "\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 2.188357\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 2.183738\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 2.150016\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 2.237125\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 2.242001\n",
            "\n",
            "Test set: Average loss: 0.0344, Accuracy: 1626/10000 (16%)\n",
            "\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 2.036198\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 2.241394\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 2.188681\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 2.268855\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 2.309668\n",
            "\n",
            "Test set: Average loss: 0.0343, Accuracy: 1837/10000 (18%)\n",
            "\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 2.187671\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 2.168480\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 2.187966\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 2.232933\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 2.190583\n",
            "\n",
            "Test set: Average loss: 0.0358, Accuracy: 1836/10000 (18%)\n",
            "\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 2.194410\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 2.142869\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 2.119134\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 2.162344\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 2.187563\n",
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 1999/10000 (20%)\n",
            "\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 2.120003\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 2.282525\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 2.266990\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 2.195607\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 2.100656\n",
            "\n",
            "Test set: Average loss: 0.0345, Accuracy: 1997/10000 (20%)\n",
            "\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 2.124813\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 2.250410\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 2.315441\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 2.191379\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 2.076228\n",
            "\n",
            "Test set: Average loss: 0.0361, Accuracy: 1994/10000 (20%)\n",
            "\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 2.200666\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 2.208876\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 2.348890\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 2.230188\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 2.165763\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 1848/10000 (18%)\n",
            "\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 2.278587\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 2.016019\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 2.198112\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 2.165495\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 2.227166\n",
            "\n",
            "Test set: Average loss: 0.0345, Accuracy: 1726/10000 (17%)\n",
            "\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 2.130991\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 2.050515\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 2.145116\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 2.143256\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 2.208815\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 1629/10000 (16%)\n",
            "\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 2.237500\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 2.150248\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 2.179864\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 2.166094\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 2.168468\n",
            "\n",
            "Test set: Average loss: 0.0350, Accuracy: 1838/10000 (18%)\n",
            "\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 2.206461\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 2.222652\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 2.030514\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 2.140080\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 2.061286\n",
            "\n",
            "Test set: Average loss: 0.0350, Accuracy: 1363/10000 (14%)\n",
            "\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 2.263324\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 2.250381\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 2.188627\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 2.113682\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 2.098634\n",
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 1846/10000 (18%)\n",
            "\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 2.156706\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 2.185180\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 2.388026\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 2.209568\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 2.091962\n",
            "\n",
            "Test set: Average loss: 0.0344, Accuracy: 1727/10000 (17%)\n",
            "\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 2.269948\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 2.173730\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 2.155895\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 2.227896\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 2.189308\n",
            "\n",
            "Test set: Average loss: 0.0349, Accuracy: 1995/10000 (20%)\n",
            "\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 2.233655\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 2.055471\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 2.224411\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 2.202801\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 2.222569\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 1726/10000 (17%)\n",
            "\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 2.125668\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 2.167218\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 2.120518\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 2.133799\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 2.165225\n",
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 1994/10000 (20%)\n",
            "\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 2.181845\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 2.063185\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 2.183659\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 2.105942\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 2.208702\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1750/10000 (18%)\n",
            "\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 2.175232\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 2.135174\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 2.246287\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 2.094083\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 2.225590\n",
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 1999/10000 (20%)\n",
            "\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 2.192499\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 2.160486\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 2.207675\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 2.228741\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 2.124712\n",
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 1845/10000 (18%)\n",
            "\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 2.227559\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 2.145102\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 2.190327\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 2.236736\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 2.087965\n",
            "\n",
            "Test set: Average loss: 0.0344, Accuracy: 1996/10000 (20%)\n",
            "\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 2.199986\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 2.213686\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 2.104414\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 2.118410\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 2.193126\n",
            "\n",
            "Test set: Average loss: 0.0356, Accuracy: 1996/10000 (20%)\n",
            "\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 2.299398\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 2.181178\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 2.270357\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 2.287822\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 2.216150\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1301/10000 (13%)\n",
            "\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 2.206736\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 2.242691\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 2.177202\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 2.168517\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 2.130286\n",
            "\n",
            "Test set: Average loss: 0.0350, Accuracy: 1481/10000 (15%)\n",
            "\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 2.366314\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 2.184872\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 2.131420\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 2.106764\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 2.209941\n",
            "\n",
            "Test set: Average loss: 0.0352, Accuracy: 1841/10000 (18%)\n",
            "\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 2.317380\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 2.128767\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 2.208092\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 2.117169\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 2.263030\n",
            "\n",
            "Test set: Average loss: 0.0342, Accuracy: 1850/10000 (18%)\n",
            "\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 2.115384\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 2.300519\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 2.264999\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 2.207415\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 2.102834\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 1842/10000 (18%)\n",
            "\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 2.165790\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 2.194281\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 2.132277\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 2.217870\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 2.299722\n",
            "\n",
            "Test set: Average loss: 0.0345, Accuracy: 1999/10000 (20%)\n",
            "\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 2.165156\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 2.158742\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 2.145278\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 2.247001\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 2.198143\n",
            "\n",
            "Test set: Average loss: 0.0351, Accuracy: 1757/10000 (18%)\n",
            "\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 2.217856\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 2.298598\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 2.138623\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 2.089431\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 2.204281\n",
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 1731/10000 (17%)\n",
            "\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 2.174390\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 2.114931\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 2.103891\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 2.059570\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 2.178619\n",
            "\n",
            "Test set: Average loss: 0.0351, Accuracy: 2000/10000 (20%)\n",
            "\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 2.133171\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 2.198470\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 2.042603\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 2.229062\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 2.142154\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1999/10000 (20%)\n",
            "\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 2.213514\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 2.102895\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 2.217804\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 2.199455\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 2.157781\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 1758/10000 (18%)\n",
            "\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 2.236472\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 2.256297\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 2.259814\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 2.198690\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 2.226202\n",
            "\n",
            "Test set: Average loss: 0.0352, Accuracy: 1482/10000 (15%)\n",
            "\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 2.290370\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 2.106532\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 2.193297\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 2.104527\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 2.116232\n",
            "\n",
            "Test set: Average loss: 0.0351, Accuracy: 1245/10000 (12%)\n",
            "\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 2.286923\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 2.223853\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 2.131126\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 2.132510\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 2.105031\n",
            "\n",
            "Test set: Average loss: 0.0353, Accuracy: 1525/10000 (15%)\n",
            "\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 2.205997\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 2.065597\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 2.147830\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 2.213801\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 2.091023\n",
            "\n",
            "Test set: Average loss: 0.0357, Accuracy: 1366/10000 (14%)\n",
            "\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 2.263850\n",
            "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 2.297706\n",
            "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 2.134760\n",
            "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 2.115937\n",
            "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 2.204541\n",
            "\n",
            "Test set: Average loss: 0.0342, Accuracy: 1998/10000 (20%)\n",
            "\n",
            "Train Epoch: 101 [0/60000 (0%)]\tLoss: 2.180776\n",
            "Train Epoch: 101 [12800/60000 (21%)]\tLoss: 2.119098\n",
            "Train Epoch: 101 [25600/60000 (43%)]\tLoss: 2.201076\n",
            "Train Epoch: 101 [38400/60000 (64%)]\tLoss: 2.129765\n",
            "Train Epoch: 101 [51200/60000 (85%)]\tLoss: 2.200427\n",
            "\n",
            "Test set: Average loss: 0.0361, Accuracy: 1482/10000 (15%)\n",
            "\n",
            "Train Epoch: 102 [0/60000 (0%)]\tLoss: 2.262235\n",
            "Train Epoch: 102 [12800/60000 (21%)]\tLoss: 2.146605\n",
            "Train Epoch: 102 [25600/60000 (43%)]\tLoss: 2.168224\n",
            "Train Epoch: 102 [38400/60000 (64%)]\tLoss: 2.211791\n",
            "Train Epoch: 102 [51200/60000 (85%)]\tLoss: 2.172497\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 1851/10000 (19%)\n",
            "\n",
            "Train Epoch: 103 [0/60000 (0%)]\tLoss: 2.138582\n",
            "Train Epoch: 103 [12800/60000 (21%)]\tLoss: 2.218475\n",
            "Train Epoch: 103 [25600/60000 (43%)]\tLoss: 2.301980\n",
            "Train Epoch: 103 [38400/60000 (64%)]\tLoss: 2.213908\n",
            "Train Epoch: 103 [51200/60000 (85%)]\tLoss: 2.169023\n",
            "\n",
            "Test set: Average loss: 0.0361, Accuracy: 1999/10000 (20%)\n",
            "\n",
            "Train Epoch: 104 [0/60000 (0%)]\tLoss: 2.274886\n",
            "Train Epoch: 104 [12800/60000 (21%)]\tLoss: 2.212799\n",
            "Train Epoch: 104 [25600/60000 (43%)]\tLoss: 2.185363\n",
            "Train Epoch: 104 [38400/60000 (64%)]\tLoss: 2.177246\n",
            "Train Epoch: 104 [51200/60000 (85%)]\tLoss: 2.268499\n",
            "\n",
            "Test set: Average loss: 0.0344, Accuracy: 1849/10000 (18%)\n",
            "\n",
            "CPU times: user 31min 40s, sys: 8.1 s, total: 31min 48s\n",
            "Wall time: 31min 56s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVgzcmOQNN-G",
        "colab_type": "code",
        "outputId": "9f60ec73-83ce-4e42-9a18-555982166899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "#  ----------------------------------------------- 5 --------------------------------------------------\n",
        "model4 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Sigmoid(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Sigmoid(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer4 = optim.SGD(model4.parameters(), lr=0.1)\n",
        "for epoch in range(1, 105):\n",
        "      train(model4, train_loader, optimizer4, loss_function, epoch)\n",
        "      ass_test(model4, test_loader, loss_function)\n",
        "\n",
        "#  --> This runs for about 2 minutes and has a test accuracy in the range 88% - 94% "
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.359387\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.789837\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.919109\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.673962\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.468177\n",
            "\n",
            "Test set: Average loss: 0.0067, Accuracy: 8793/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.484025\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.410158\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.236222\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.372621\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.247581\n",
            "\n",
            "Test set: Average loss: 0.0047, Accuracy: 9145/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.292524\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.272689\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.181045\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.350339\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.336032\n",
            "\n",
            "Test set: Average loss: 0.0039, Accuracy: 9283/10000 (93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.482143\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.485170\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.472487\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.145014\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.297265\n",
            "\n",
            "Test set: Average loss: 0.0034, Accuracy: 9375/10000 (94%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.221929\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.199290\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.165194\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.133368\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.189582\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9420/10000 (94%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.306544\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.235279\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.077333\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.094527\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.125996\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9509/10000 (95%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.229878\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.232901\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.101235\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.067629\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.123255\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9560/10000 (96%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.156806\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.200970\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.093861\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.085527\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.197464\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 9610/10000 (96%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.089423\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.059045\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.118271\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.177986\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.055712\n",
            "\n",
            "Test set: Average loss: 0.0019, Accuracy: 9632/10000 (96%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.058991\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.099273\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.068652\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.050038\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.049689\n",
            "\n",
            "Test set: Average loss: 0.0018, Accuracy: 9652/10000 (97%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.070398\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.088435\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.065184\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.042544\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.055287\n",
            "\n",
            "Test set: Average loss: 0.0017, Accuracy: 9685/10000 (97%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.106236\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.050956\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.080108\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.053504\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.028541\n",
            "\n",
            "Test set: Average loss: 0.0015, Accuracy: 9699/10000 (97%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.051074\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.018659\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.074474\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.127711\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.071554\n",
            "\n",
            "Test set: Average loss: 0.0015, Accuracy: 9707/10000 (97%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.055413\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.047910\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.067574\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.060068\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.069025\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9727/10000 (97%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.024689\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.069773\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.029464\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.036116\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.071639\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9735/10000 (97%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.166590\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.068013\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.109852\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.044200\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.063236\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9742/10000 (97%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.028943\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.201539\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.072773\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.038951\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.070398\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9734/10000 (97%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.034055\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.032598\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.044836\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.028588\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.068745\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9765/10000 (98%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.020243\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.023541\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.023766\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.021548\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.022399\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9756/10000 (98%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.013636\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.021876\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.066590\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.044575\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.050684\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9780/10000 (98%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.037342\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.053335\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.071677\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.011327\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.023821\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9774/10000 (98%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.018411\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.049873\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.014688\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.023991\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.009524\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9798/10000 (98%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.023725\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.026139\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.132999\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.009253\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.032224\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9783/10000 (98%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.027977\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.020161\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.015917\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.068098\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.010583\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.022490\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.036877\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.006376\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.019922\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.024705\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9791/10000 (98%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.007687\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.017789\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.013728\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.018919\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.032101\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9793/10000 (98%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.038793\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.006491\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.036088\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.019331\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.026174\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.018507\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.025348\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.006404\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.013889\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.049506\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9807/10000 (98%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.007522\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.002501\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.005750\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.024588\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.022326\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.019966\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.008826\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.012993\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.005138\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.004868\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9800/10000 (98%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.012872\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.006088\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.021796\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.012374\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.010010\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9813/10000 (98%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.020319\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.005379\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.006816\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.013846\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.011122\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9808/10000 (98%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.018065\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.012571\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.006666\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.004789\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.007955\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9813/10000 (98%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.015521\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.012619\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.017356\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.012069\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.015655\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.010443\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.008764\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.008589\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.004562\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.011858\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.006153\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.008793\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.004029\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.011242\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.007720\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9815/10000 (98%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.003994\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.007020\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.007873\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.016152\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.001208\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9817/10000 (98%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.012670\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.003246\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.012644\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.009126\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.008019\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9818/10000 (98%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.003061\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.009996\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.005451\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.003528\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.015074\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9812/10000 (98%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.013790\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.010236\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.004078\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.001452\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.012323\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9817/10000 (98%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.005545\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.026933\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.011091\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.015192\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.012683\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.002808\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.006650\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.006314\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.004104\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.014369\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.005399\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.006781\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.010146\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.003789\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.010025\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.008311\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.016717\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.005029\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.002624\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.006798\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9813/10000 (98%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.006455\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.009674\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.007027\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.002952\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.007474\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.007044\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.008620\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.002300\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.005387\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.002155\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.007355\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.009511\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.015323\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.003068\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.002461\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.010608\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.008264\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.008916\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.004634\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.011843\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.003826\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.003699\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.001060\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.009851\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.003244\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.004321\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.005678\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.005759\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.005506\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.003123\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9813/10000 (98%)\n",
            "\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.000306\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.005717\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.001623\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.002608\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.002975\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.007754\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.001314\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.004703\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.003217\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.008226\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.008432\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.003049\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.006306\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.010110\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.007518\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9827/10000 (98%)\n",
            "\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.006164\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.004256\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.004081\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.005497\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.001244\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.005303\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.002400\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.002510\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.000687\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.013600\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9829/10000 (98%)\n",
            "\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.001048\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.004575\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.005693\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.008727\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.002662\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9827/10000 (98%)\n",
            "\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.002888\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.005770\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.001010\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.002206\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.001950\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9827/10000 (98%)\n",
            "\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.004930\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.001736\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.002466\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.005778\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.002648\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9827/10000 (98%)\n",
            "\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.002815\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.001097\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.004470\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.002550\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.001641\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9827/10000 (98%)\n",
            "\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.004524\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.002193\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.000916\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.003468\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.002680\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.007715\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.000872\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.005979\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.005391\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.004835\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9828/10000 (98%)\n",
            "\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.002235\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.001772\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.003185\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.002811\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.002892\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9832/10000 (98%)\n",
            "\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.002417\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.001503\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.003657\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.002435\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.001209\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9829/10000 (98%)\n",
            "\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.001043\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.002727\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.006663\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.002088\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.000551\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9831/10000 (98%)\n",
            "\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.005455\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.001829\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.016706\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.000441\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.000738\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9832/10000 (98%)\n",
            "\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.001110\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.003993\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.001980\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.001148\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.001276\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9829/10000 (98%)\n",
            "\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.003022\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.002868\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.000904\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.003323\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.001674\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9828/10000 (98%)\n",
            "\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.005296\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.002297\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.002074\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.000439\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.002465\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9827/10000 (98%)\n",
            "\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.000737\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.002197\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.004129\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.002673\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.001780\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9830/10000 (98%)\n",
            "\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.000285\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.001998\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.000885\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.002345\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.001205\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9831/10000 (98%)\n",
            "\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.000954\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 0.003873\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.002122\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.003599\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.002784\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9829/10000 (98%)\n",
            "\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000928\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.003872\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.001727\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.002498\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.003531\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9833/10000 (98%)\n",
            "\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.003781\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.003542\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.000934\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.002059\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.002640\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9831/10000 (98%)\n",
            "\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.003603\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.001311\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.002835\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.001081\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.002789\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9830/10000 (98%)\n",
            "\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.003039\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.003739\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.002166\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.001183\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.001206\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9833/10000 (98%)\n",
            "\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.001188\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.001794\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.001882\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.001915\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.003181\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9830/10000 (98%)\n",
            "\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.001410\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.001977\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.000760\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 0.001369\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.003709\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9831/10000 (98%)\n",
            "\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.000890\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.000533\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.002680\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.000389\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.001662\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9833/10000 (98%)\n",
            "\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.002807\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.001182\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.001301\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.003305\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.002060\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9831/10000 (98%)\n",
            "\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.001072\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.003570\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.000630\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.002121\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.002294\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9831/10000 (98%)\n",
            "\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.001868\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.000640\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.002802\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.002408\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.000863\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9831/10000 (98%)\n",
            "\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.009538\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.000815\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.001871\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.002176\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.000622\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9835/10000 (98%)\n",
            "\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.001887\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.001865\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.000258\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.002057\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.002004\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9833/10000 (98%)\n",
            "\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.000492\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.002967\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.000693\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.000566\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.002321\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9835/10000 (98%)\n",
            "\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000833\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.001541\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.002774\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.000988\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.001459\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9834/10000 (98%)\n",
            "\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.003457\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.000839\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.001036\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.002870\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.003867\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9834/10000 (98%)\n",
            "\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.001037\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.002452\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.003107\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.002341\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.000660\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9833/10000 (98%)\n",
            "\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.001805\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.000859\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.001163\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.002998\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.002627\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9831/10000 (98%)\n",
            "\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.002553\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.002084\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.001551\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.002556\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.000510\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9834/10000 (98%)\n",
            "\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.001033\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.001518\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.000204\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.001059\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.001448\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9833/10000 (98%)\n",
            "\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.000913\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.000936\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.000451\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.004634\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.001035\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9833/10000 (98%)\n",
            "\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000645\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.001849\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.000757\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.000877\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.000880\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9835/10000 (98%)\n",
            "\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.001834\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.000455\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.003233\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.001182\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.001676\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9835/10000 (98%)\n",
            "\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.003370\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.000496\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.001432\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.000794\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.001457\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9835/10000 (98%)\n",
            "\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.001407\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.000680\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.002176\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.000613\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.001600\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9833/10000 (98%)\n",
            "\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000475\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.001810\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.000720\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.003023\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.000641\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9834/10000 (98%)\n",
            "\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.002614\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.001248\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.002709\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.001282\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.000739\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9835/10000 (98%)\n",
            "\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.001310\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.004109\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.001214\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.001617\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.002742\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9835/10000 (98%)\n",
            "\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.001342\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.002041\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.000385\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.001344\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.000440\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9835/10000 (98%)\n",
            "\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.000560\n",
            "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 0.001190\n",
            "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 0.001178\n",
            "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 0.000296\n",
            "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 0.001407\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9834/10000 (98%)\n",
            "\n",
            "Train Epoch: 101 [0/60000 (0%)]\tLoss: 0.001149\n",
            "Train Epoch: 101 [12800/60000 (21%)]\tLoss: 0.001481\n",
            "Train Epoch: 101 [25600/60000 (43%)]\tLoss: 0.000384\n",
            "Train Epoch: 101 [38400/60000 (64%)]\tLoss: 0.000493\n",
            "Train Epoch: 101 [51200/60000 (85%)]\tLoss: 0.001612\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9836/10000 (98%)\n",
            "\n",
            "Train Epoch: 102 [0/60000 (0%)]\tLoss: 0.000945\n",
            "Train Epoch: 102 [12800/60000 (21%)]\tLoss: 0.000815\n",
            "Train Epoch: 102 [25600/60000 (43%)]\tLoss: 0.001086\n",
            "Train Epoch: 102 [38400/60000 (64%)]\tLoss: 0.001501\n",
            "Train Epoch: 102 [51200/60000 (85%)]\tLoss: 0.002503\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9833/10000 (98%)\n",
            "\n",
            "Train Epoch: 103 [0/60000 (0%)]\tLoss: 0.001603\n",
            "Train Epoch: 103 [12800/60000 (21%)]\tLoss: 0.000771\n",
            "Train Epoch: 103 [25600/60000 (43%)]\tLoss: 0.000923\n",
            "Train Epoch: 103 [38400/60000 (64%)]\tLoss: 0.000500\n",
            "Train Epoch: 103 [51200/60000 (85%)]\tLoss: 0.001655\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9833/10000 (98%)\n",
            "\n",
            "Train Epoch: 104 [0/60000 (0%)]\tLoss: 0.000667\n",
            "Train Epoch: 104 [12800/60000 (21%)]\tLoss: 0.001476\n",
            "Train Epoch: 104 [25600/60000 (43%)]\tLoss: 0.001032\n",
            "Train Epoch: 104 [38400/60000 (64%)]\tLoss: 0.001753\n",
            "Train Epoch: 104 [51200/60000 (85%)]\tLoss: 0.003146\n",
            "\n",
            "Test set: Average loss: 0.0009, Accuracy: 9834/10000 (98%)\n",
            "\n",
            "CPU times: user 31min 36s, sys: 21.2 s, total: 31min 57s\n",
            "Wall time: 32min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loiRdOBhPiyK",
        "colab_type": "code",
        "outputId": "0e7aa48c-971c-46b6-d5b2-8ae900b68409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "# ------------------------------------------------ 6 -------------------------------------------------------------\n",
        "\n",
        "model5 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 256), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(256, 1024), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(1024, 10))\n",
        "optimizer5 = optim.SGD(model5.parameters(), lr=0.1)\n",
        "\n",
        "print(len(model5.parameters()))\n",
        "\n",
        "for epoch in range(0, 105):\n",
        "      train(model5, train_loader, optimizer5, loss_function, epoch)\n",
        "      ass_test(model5, test_loader, loss_function)\n",
        "\n",
        "# --> This cell takes about 2minutes and has a range accuracy of 94% - 98%\n",
        "# --> Here we have 6 parameters\n",
        "# --> Because we are building 1024 ouputs from 256inputs, we should have more weights \n",
        "#       to enable those transformations from few inputs to so many"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.308177\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.165606\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.259422\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.170130\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.138069\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9529/10000 (95%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.080634\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.158119\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.194048\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.109059\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.102879\n",
            "\n",
            "Test set: Average loss: 0.0015, Accuracy: 9690/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.097351\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.018245\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.083821\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.129758\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.032937\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9755/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.067308\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.054000\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.023622\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.039188\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.086888\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9743/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.064914\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.040581\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.030013\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.068438\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.044550\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9772/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001866\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.100073\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.032924\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.015414\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.151083\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9792/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.007464\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.036111\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.010193\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.066012\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.015036\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9785/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.005812\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.039004\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.025568\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.004738\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.008779\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9798/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.007659\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.003655\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.002344\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.005357\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.009607\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.001150\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.002979\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.001644\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.003678\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.005645\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9810/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.007907\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.000398\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.001031\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.004029\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000867\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9815/10000 (98%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.003092\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.002816\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.002828\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.001700\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.002511\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.001925\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.001473\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.001122\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.001373\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.001096\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.001913\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.001207\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.003586\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.002268\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.000850\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.001008\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.000586\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.000777\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.004577\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.002264\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.001224\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.000434\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.001084\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.000413\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.000390\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000954\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.000906\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.002786\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.002289\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.000872\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9826/10000 (98%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.000614\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.000403\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.000496\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.000259\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.000528\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.001481\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.001097\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.001238\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.000832\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.000401\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.000477\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.000699\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.000250\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.000548\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.000511\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.000409\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.000282\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.000404\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.000821\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.000930\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.001218\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.001139\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.000819\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.000626\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.000318\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.000162\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.000193\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.000490\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.000980\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.000532\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9827/10000 (98%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000470\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.000818\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.000759\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.000580\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.000255\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9828/10000 (98%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000505\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.000718\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.000425\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.000542\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.000260\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.000148\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.000297\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.000478\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.000460\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.000183\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.000227\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.000518\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.000731\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.000431\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000477\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000446\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.000174\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.000905\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.000199\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.000863\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.000759\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.000293\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.000281\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.000173\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.000514\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000333\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.000393\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.000151\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.000562\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.000719\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9826/10000 (98%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.000318\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.000292\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.000237\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.000383\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.000204\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.000469\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.000170\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.000329\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.000502\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.000201\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.000437\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.000378\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.000415\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.000397\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.000168\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000423\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.000265\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.000156\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.000145\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.000250\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.000415\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.000505\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.000176\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.000798\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000345\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.000307\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.000116\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.000098\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.000216\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.000252\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000309\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.000345\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.000256\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.000343\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.000512\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000108\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.000087\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.000127\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.000343\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.000603\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.000931\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.000062\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.000401\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.000068\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.000586\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.000167\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.000374\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.000349\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.000125\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.000121\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000113\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.000102\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.000138\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.000232\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.000200\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.000239\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.000028\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.000349\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.000291\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.000137\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000204\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.000151\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.000123\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.000383\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.000125\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.000253\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.000235\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.000558\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.000673\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.000471\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.000287\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.000032\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.000025\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.000182\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.000093\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000200\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.000198\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.000538\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.000180\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000182\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000225\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.000182\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.000173\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.000274\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.000133\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000164\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.000295\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.000103\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.000247\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.000060\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000149\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.000089\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.000069\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.000159\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.000136\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000156\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.000370\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.000276\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.000308\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.000029\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.000249\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.000304\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.000049\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.000290\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.000166\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.000187\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.000137\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.000204\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.000144\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.000095\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.000143\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.000033\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.000145\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.000170\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.000087\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.000156\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.000152\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.000180\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.000217\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.000103\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.000258\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.000368\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.000081\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.000343\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.000151\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.000186\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.000252\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.000189\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.000242\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.000222\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.000370\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.000041\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.000411\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.000114\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.000083\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000200\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.000322\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.000209\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.000138\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.000309\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.000034\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.000159\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.000099\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.000035\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.000206\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.000029\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.000110\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.000197\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.000196\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.000075\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.000139\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.000112\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.000077\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.000068\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.000100\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.000201\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.000034\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.000114\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.000058\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.000032\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.000518\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.000236\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.000068\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.000144\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.000085\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.000192\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.000117\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.000068\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.000140\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.000111\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.000124\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.000041\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.000259\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.000136\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.000217\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.000088\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.000073\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.000079\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.000143\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.000196\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.000058\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.000133\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.000047\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.000132\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.000108\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.000283\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.000102\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.000080\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.000233\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.000256\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.000054\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.000145\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.000142\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.000259\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.000108\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.000119\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.000194\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.000145\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.000049\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.000120\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.000216\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.000104\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.000102\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.000081\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.000198\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.000115\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 0.000071\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.000049\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.000113\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.000265\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000047\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.000027\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.000175\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.000109\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.000055\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.000219\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.000214\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.000085\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.000148\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.000020\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.000167\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.000055\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.000145\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.000121\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.000166\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.000137\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.000118\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.000056\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.000043\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.000101\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.000097\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.000193\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.000119\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.000107\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.000111\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.000159\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.000024\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.000026\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 0.000026\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.000029\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.000063\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.000060\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.000097\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.000084\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.000228\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.000141\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.000148\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.000125\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.000076\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.000104\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.000178\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.000068\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.000170\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.000045\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.000068\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.000111\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.000340\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.000193\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.000017\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.000064\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.000099\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.000022\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.000053\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.000183\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.000045\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.000105\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.000025\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.000017\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.000067\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.000117\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.000084\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.000031\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.000099\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.000131\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.000170\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000279\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.000029\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.000154\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.000122\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.000086\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.000087\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.000096\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.000137\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.000098\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.000162\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.000107\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.000055\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.000015\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.000128\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.000095\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.000028\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.000087\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.000181\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.000046\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.000098\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000213\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.000043\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.000096\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.000025\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.000050\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.000123\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.000191\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.000038\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.000038\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.000066\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.000046\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.000039\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.000118\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.000014\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.000031\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000022\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.000224\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.000002\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.000063\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.000192\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.000148\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.000075\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.000022\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.000041\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.000037\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.000110\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.000081\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.000072\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.000100\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.000043\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.000034\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.000058\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.000032\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.000092\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.000115\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000086\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.000108\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.000023\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.000086\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.000032\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.000087\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.000056\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.000028\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.000122\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.000047\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.000162\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.000108\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.000092\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.000059\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.000066\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.000079\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.000069\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.000058\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.000042\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.000120\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.000125\n",
            "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 0.000031\n",
            "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 0.000105\n",
            "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 0.000128\n",
            "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 0.000045\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 101 [0/60000 (0%)]\tLoss: 0.000031\n",
            "Train Epoch: 101 [12800/60000 (21%)]\tLoss: 0.000105\n",
            "Train Epoch: 101 [25600/60000 (43%)]\tLoss: 0.000076\n",
            "Train Epoch: 101 [38400/60000 (64%)]\tLoss: 0.000017\n",
            "Train Epoch: 101 [51200/60000 (85%)]\tLoss: 0.000116\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 102 [0/60000 (0%)]\tLoss: 0.000046\n",
            "Train Epoch: 102 [12800/60000 (21%)]\tLoss: 0.000049\n",
            "Train Epoch: 102 [25600/60000 (43%)]\tLoss: 0.000107\n",
            "Train Epoch: 102 [38400/60000 (64%)]\tLoss: 0.000071\n",
            "Train Epoch: 102 [51200/60000 (85%)]\tLoss: 0.000187\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 103 [0/60000 (0%)]\tLoss: 0.000064\n",
            "Train Epoch: 103 [12800/60000 (21%)]\tLoss: 0.000078\n",
            "Train Epoch: 103 [25600/60000 (43%)]\tLoss: 0.000122\n",
            "Train Epoch: 103 [38400/60000 (64%)]\tLoss: 0.000116\n",
            "Train Epoch: 103 [51200/60000 (85%)]\tLoss: 0.000137\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 104 [0/60000 (0%)]\tLoss: 0.000113\n",
            "Train Epoch: 104 [12800/60000 (21%)]\tLoss: 0.000032\n",
            "Train Epoch: 104 [25600/60000 (43%)]\tLoss: 0.000083\n",
            "Train Epoch: 104 [38400/60000 (64%)]\tLoss: 0.000074\n",
            "Train Epoch: 104 [51200/60000 (85%)]\tLoss: 0.000118\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "CPU times: user 32min 30s, sys: 26.1 s, total: 32min 56s\n",
            "Wall time: 33min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1feGFZR28_",
        "colab_type": "code",
        "outputId": "b53bea01-0d0b-4297-d792-c929fe0bab89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "# ------------------------------------------------ 7 -------------------------------------------------------------\n",
        "model6 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 256), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(256, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer6 = optim.SGD(model6.parameters(), lr=0.1)\n",
        "for epoch in range(0, 105):\n",
        "      train(model6, train_loader, optimizer6, loss_function, epoch)\n",
        "      # ass_test(model6, test_loader, loss_function)\n",
        "\n",
        "print(len(list(model6.parameters())))\n",
        "\n",
        "# --> Test accuracy lies bwtween 95% and 97%. \n",
        "# --> Because there is a layer more than the previous cells, it should take more time to complete and have more parameters\n",
        "# --> This cell has 8 parameters"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.307003\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.226137\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.141190\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.230117\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.152591\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.086357\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.075259\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.139744\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.145347\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.100430\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.143588\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.099064\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.187879\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.121555\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.081323\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.074681\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.008886\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.012741\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.060795\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.011299\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.027040\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.018516\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.018562\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.074786\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.028181\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.029243\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.094352\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.011177\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.045337\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.006929\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.010334\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.008527\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.060357\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.003935\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.025964\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.013930\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.020948\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.007510\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.017460\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.004235\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.002805\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.005538\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.001345\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.008608\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.004368\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.001709\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.002720\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.005287\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.001235\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000967\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.003716\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.006392\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.003457\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.001879\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000721\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.002010\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.000609\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.000431\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.000110\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.001282\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000567\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.002082\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.000419\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.000531\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.000306\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.000457\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.000811\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.000488\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.000870\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.001488\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.000542\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.000527\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.000620\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.000893\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.000780\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.000250\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.001145\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.000310\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.000338\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.000698\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.009051\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.000897\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.001401\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.000425\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.000211\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.000599\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.000610\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.000510\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.000280\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.000312\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000702\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.000932\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.000489\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.000268\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.000618\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.000613\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.000951\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.000171\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.000551\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.000289\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.000338\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.000160\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.001275\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.000206\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.000788\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.000506\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.000388\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.000633\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.000549\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.000104\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.001032\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.000493\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.000323\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.000382\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.000849\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000182\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.002090\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.000521\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.000340\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.000219\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000267\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.000160\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.000147\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.000693\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.000563\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.000453\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.000313\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.000329\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.000189\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.000285\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.000250\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.000340\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.000470\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.000676\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000284\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000188\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.000298\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.000055\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.000311\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.000233\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.001149\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.000213\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.000094\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.000138\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.000227\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000158\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.000113\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.000216\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.000238\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.000036\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.000061\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.000470\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.000837\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.000308\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.000121\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.000209\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.000271\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.000136\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.000142\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.000340\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.000322\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.000195\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.000613\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.000335\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.000113\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000306\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.000184\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.000230\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.000150\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.000326\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.000343\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.000487\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.000232\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.000239\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000177\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.000307\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.000229\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.000291\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.000385\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.000130\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000147\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.000231\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.000100\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.000111\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.000363\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000295\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.000066\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.000087\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.000111\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.000152\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.000180\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.000219\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.000160\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.000143\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.000132\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.000330\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.000131\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.000188\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.000304\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.000252\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000088\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.000068\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.000224\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.000152\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.000178\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.000069\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.000382\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.000150\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.000227\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.000500\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000132\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.000329\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.000055\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.000121\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.000095\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.000067\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.000206\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.000278\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.000137\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.000163\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.000152\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.000303\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.000022\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.000200\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.000416\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000100\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.000159\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.000076\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.000134\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000501\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000073\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.000128\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.000113\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.000218\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.000259\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000069\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.000097\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.000082\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.000051\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.000063\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000150\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.000154\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.000100\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.000072\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.000249\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000098\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.000110\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.000260\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.000046\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.000048\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.000075\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.000052\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.000240\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.000078\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.000153\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.000133\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.000031\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.000127\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.000088\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.000039\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.000169\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.000102\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.000097\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.000191\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.000061\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.000148\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.000056\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.000086\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.000100\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.000085\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.000136\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.000185\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.000303\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.000042\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.000191\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.000128\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.000039\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.000086\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.000143\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.000124\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.000066\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.000040\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.000104\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.000119\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.000235\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000053\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.000252\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.000093\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.000124\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.000840\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.000113\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.000170\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.000151\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.000202\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.000050\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.000050\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.000067\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.000046\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.000080\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.000132\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.000118\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.000075\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.000034\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.000072\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.000165\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.000075\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.000091\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.000096\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.000096\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.000089\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.000090\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.000084\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.000095\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.000044\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.000076\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.000085\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.000079\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.000181\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.000140\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.000156\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.000167\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.000149\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.000138\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.000076\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.000098\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.000074\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.000186\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.000038\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.000151\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.000062\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.000061\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.000129\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.000020\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.000091\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.000124\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.000139\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.000073\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.000082\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.000081\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.000063\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.000031\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.000097\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.000102\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.000051\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.000191\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.000064\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.000125\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.000054\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.000061\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.000117\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.000046\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.000139\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.000144\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.000065\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.000057\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.000049\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 0.000037\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.000109\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.000036\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.000041\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000042\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.000032\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.000048\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.000121\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.000100\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.000063\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.000139\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.000072\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.000070\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.000134\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.000054\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.000129\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.000105\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.000067\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.000037\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.000041\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.000101\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.000113\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.000072\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.000145\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.000142\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.000164\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.000065\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.000095\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.000048\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.000036\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.000035\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.000039\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 0.000027\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.000047\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.000047\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.000074\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.000087\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.000066\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.000133\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.000120\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.000052\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.000115\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.000019\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.000052\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.000065\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.000079\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.000209\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.000109\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.000082\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.000060\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.000110\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.000096\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.000027\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.000035\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.000024\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.000031\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.000074\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.000101\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.000131\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.000040\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.000033\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.000050\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.000047\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.000124\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.000063\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.000035\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.000053\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.000022\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.000034\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000074\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.000031\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.000068\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.000024\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.000062\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.000056\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.000088\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.000112\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.000060\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.000046\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.000039\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.000084\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.000032\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.000139\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.000060\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.000048\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.000111\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.000101\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.000023\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.000130\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000032\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.000059\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.000052\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.000042\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.000065\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.000085\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.000031\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.000042\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.000061\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.000108\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.000044\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.000044\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.000046\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.000055\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.000032\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000046\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.000053\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.000157\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.000082\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.000092\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.000057\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.000054\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.000105\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.000109\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.000047\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.000058\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.000021\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.000107\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.000033\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.000099\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.000069\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.000030\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.000086\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.000151\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.000049\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000034\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.000019\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.000065\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.000066\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.000024\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.000032\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.000061\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.000054\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.000045\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.000027\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.000025\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.000128\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.000025\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.000103\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.000077\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.000038\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.000074\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.000023\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.000107\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.000032\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.000054\n",
            "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 0.000014\n",
            "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 0.000101\n",
            "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 0.000030\n",
            "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 0.000059\n",
            "Train Epoch: 101 [0/60000 (0%)]\tLoss: 0.000029\n",
            "Train Epoch: 101 [12800/60000 (21%)]\tLoss: 0.000038\n",
            "Train Epoch: 101 [25600/60000 (43%)]\tLoss: 0.000041\n",
            "Train Epoch: 101 [38400/60000 (64%)]\tLoss: 0.000027\n",
            "Train Epoch: 101 [51200/60000 (85%)]\tLoss: 0.000061\n",
            "Train Epoch: 102 [0/60000 (0%)]\tLoss: 0.000054\n",
            "Train Epoch: 102 [12800/60000 (21%)]\tLoss: 0.000018\n",
            "Train Epoch: 102 [25600/60000 (43%)]\tLoss: 0.000034\n",
            "Train Epoch: 102 [38400/60000 (64%)]\tLoss: 0.000067\n",
            "Train Epoch: 102 [51200/60000 (85%)]\tLoss: 0.000044\n",
            "Train Epoch: 103 [0/60000 (0%)]\tLoss: 0.000017\n",
            "Train Epoch: 103 [12800/60000 (21%)]\tLoss: 0.000024\n",
            "Train Epoch: 103 [25600/60000 (43%)]\tLoss: 0.000102\n",
            "Train Epoch: 103 [38400/60000 (64%)]\tLoss: 0.000109\n",
            "Train Epoch: 103 [51200/60000 (85%)]\tLoss: 0.000076\n",
            "Train Epoch: 104 [0/60000 (0%)]\tLoss: 0.000015\n",
            "Train Epoch: 104 [12800/60000 (21%)]\tLoss: 0.000031\n",
            "Train Epoch: 104 [25600/60000 (43%)]\tLoss: 0.000060\n",
            "Train Epoch: 104 [38400/60000 (64%)]\tLoss: 0.000026\n",
            "Train Epoch: 104 [51200/60000 (85%)]\tLoss: 0.000043\n",
            "8\n",
            "CPU times: user 28min 18s, sys: 24.9 s, total: 28min 43s\n",
            "Wall time: 28min 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dvuMbGFV_34",
        "colab_type": "code",
        "outputId": "41d8d71a-2d13-4a6a-d668-4e3b5747a811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "model7 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(5, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer7 = optim.SGD(model7.parameters(), lr=0.1)\n",
        "for epoch in range(0, 105):\n",
        "      train(model7, train_loader, optimizer7, loss_function, epoch)\n",
        "      ass_test(model7, test_loader, loss_function)\n",
        "\n",
        "print(len(list(model7.parameters())))\n",
        "\n",
        "# --> It takes a few seconds more to complete compared to the q4 and q5 because of the extra layer\n",
        "# --> It should have 8 layers like in the other cell\n",
        "# --> The accuracy should pumelt because we are extracting 64 features from 5 \n",
        "#     features after loosing over half of our features from 512"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.303751\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.688768\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.238333\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.290020\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.254590\n",
            "\n",
            "Test set: Average loss: 0.0060, Accuracy: 8944/10000 (89%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.373551\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.165000\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.309689\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.179566\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.116013\n",
            "\n",
            "Test set: Average loss: 0.0032, Accuracy: 9477/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.122568\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.127964\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.194820\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.047592\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.162460\n",
            "\n",
            "Test set: Average loss: 0.0034, Accuracy: 9423/10000 (94%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.070868\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.088387\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.038042\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.220063\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.073734\n",
            "\n",
            "Test set: Average loss: 0.0034, Accuracy: 9427/10000 (94%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.074924\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.143093\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.022603\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.051233\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.063106\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9633/10000 (96%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.031093\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.072985\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.153799\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.083537\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.089328\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 9673/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.039003\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.034600\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.153832\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.047960\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.092619\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 9667/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.114009\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.045067\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.235105\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.062375\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.091305\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9649/10000 (96%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.016984\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.017570\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.007219\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.080507\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.126188\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 9676/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.056653\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.015817\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.006485\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.106000\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.254016\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 9690/10000 (97%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.021485\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.047445\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.011472\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.024314\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.010993\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 9695/10000 (97%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.097056\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.057385\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.044246\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.092929\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.097014\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 9683/10000 (97%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.007801\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.101071\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.011367\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.007021\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.016579\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9625/10000 (96%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.077675\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.013475\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.203419\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.181733\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.038996\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 9709/10000 (97%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.006999\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.015902\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.044803\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.040942\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.202900\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9609/10000 (96%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.168001\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.040969\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.003559\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.218951\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.022618\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 9704/10000 (97%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.039746\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.036593\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.203304\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.060722\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.057850\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9674/10000 (97%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.005960\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.011759\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.023690\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.006192\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.107827\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9677/10000 (97%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.013345\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.016720\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.080104\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.030116\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.172412\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 9715/10000 (97%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.003207\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.072095\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.011135\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.115406\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.002424\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 9728/10000 (97%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.008452\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.024009\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.001967\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.005306\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.143651\n",
            "\n",
            "Test set: Average loss: 0.0031, Accuracy: 9607/10000 (96%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.088043\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.001703\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.002166\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.053665\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.045962\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9676/10000 (97%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.083166\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.030534\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.003179\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.015993\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.016052\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9671/10000 (97%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.010230\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.005973\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.007574\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.003478\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.012002\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9704/10000 (97%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.010128\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.003376\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.004291\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.003152\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.005135\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 9729/10000 (97%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.017124\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.003511\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.016059\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.006392\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.002900\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9651/10000 (97%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.047922\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.014010\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.002195\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.010549\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.024662\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9736/10000 (97%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.001394\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.023443\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.001277\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.001779\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.001727\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9711/10000 (97%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.013954\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.203823\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.054669\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.108067\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.004620\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9683/10000 (97%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.005060\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.012926\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.003072\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.009323\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.035465\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9713/10000 (97%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.008187\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.002232\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.002574\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.006456\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.056425\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9716/10000 (97%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.040499\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.070004\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.003728\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.002394\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.023885\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9698/10000 (97%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.001079\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.014340\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.003434\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.115030\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.078523\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9695/10000 (97%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.001949\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.002669\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.062799\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.001469\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.003974\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9727/10000 (97%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.001959\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.002001\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.001740\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.013735\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.021032\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9713/10000 (97%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.016239\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.015738\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.004510\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.001383\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.003340\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9667/10000 (97%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.002821\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.007904\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.012107\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.018072\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.004221\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9712/10000 (97%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.040621\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.001327\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.005251\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.023093\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.050484\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9727/10000 (97%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.007419\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.008799\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.003268\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.063383\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.020982\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9670/10000 (97%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.137803\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.002452\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.005569\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.001305\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.006488\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9721/10000 (97%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.001635\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.001592\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.002204\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.001361\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.047032\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9707/10000 (97%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.037480\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.113940\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.003087\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.011751\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.068043\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9708/10000 (97%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.009355\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.016381\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.001267\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.003502\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.031821\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9672/10000 (97%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.070180\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.011358\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.058062\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.001493\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.062866\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9695/10000 (97%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.047579\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.033258\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.009145\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.029931\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.002788\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9721/10000 (97%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.007445\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.008735\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.001198\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.001006\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000928\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9741/10000 (97%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.003049\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.001065\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.029063\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.001017\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.046832\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9724/10000 (97%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.014946\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.004081\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.121104\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.001926\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.018643\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9734/10000 (97%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.007081\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.001730\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.122309\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.003652\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.001007\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9712/10000 (97%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.001206\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.010636\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.008753\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.005839\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.002490\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9733/10000 (97%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.004744\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.001163\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.000902\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.001543\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.002433\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9716/10000 (97%)\n",
            "\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.171445\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.022860\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.003831\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.003852\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.003587\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9674/10000 (97%)\n",
            "\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.001205\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.172777\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.002236\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.001463\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.004312\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9737/10000 (97%)\n",
            "\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.016924\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.000908\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.001323\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.000882\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.001102\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9706/10000 (97%)\n",
            "\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.001190\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.003092\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.005676\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.016610\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.002644\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 9689/10000 (97%)\n",
            "\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.060075\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.001234\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.147464\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.001932\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.000786\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9704/10000 (97%)\n",
            "\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.002845\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.015840\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.004063\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.001248\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.001468\n",
            "\n",
            "Test set: Average loss: 0.0049, Accuracy: 9448/10000 (94%)\n",
            "\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.121518\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.001293\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.002332\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.045873\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.021513\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9674/10000 (97%)\n",
            "\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.003317\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.045570\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.004871\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.034812\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.076166\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9705/10000 (97%)\n",
            "\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.084334\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.007011\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.001222\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.005987\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.020274\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9718/10000 (97%)\n",
            "\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.023932\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.001100\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.067352\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.005301\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.005743\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9728/10000 (97%)\n",
            "\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.001204\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.006936\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.014411\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.001532\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.032176\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9745/10000 (97%)\n",
            "\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.009344\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.003676\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.005056\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.001393\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.040797\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9707/10000 (97%)\n",
            "\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.033156\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.108934\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.004159\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.001529\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.004490\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9728/10000 (97%)\n",
            "\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.002891\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.003610\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.001217\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.011565\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.016102\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9700/10000 (97%)\n",
            "\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.000673\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.010734\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.001327\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.000958\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.009773\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9696/10000 (97%)\n",
            "\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.006116\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.032738\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.001150\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.014822\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.018262\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9711/10000 (97%)\n",
            "\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.002723\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.009298\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.001625\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.013818\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.001363\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9737/10000 (97%)\n",
            "\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.001569\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.001562\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.000499\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.001845\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.000875\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9729/10000 (97%)\n",
            "\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.000954\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.000557\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.015965\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.002430\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.000484\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9731/10000 (97%)\n",
            "\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.001523\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.001928\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.034515\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.001101\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.000678\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9730/10000 (97%)\n",
            "\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.000870\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 0.021629\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.000653\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.002967\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.005193\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 9689/10000 (97%)\n",
            "\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.087830\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.001053\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.033112\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.001078\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.001164\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9698/10000 (97%)\n",
            "\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.002040\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.001349\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.063601\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.059988\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.002406\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9715/10000 (97%)\n",
            "\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.002175\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.000934\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.003081\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.037945\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.001859\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9702/10000 (97%)\n",
            "\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.001189\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.004935\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.122463\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.002936\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.002842\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9675/10000 (97%)\n",
            "\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.001045\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.001013\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.002250\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.066487\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.005184\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9715/10000 (97%)\n",
            "\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.001653\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.163181\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.166085\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 0.019626\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.000728\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9721/10000 (97%)\n",
            "\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.003633\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.062928\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.001541\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.006856\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.000807\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9715/10000 (97%)\n",
            "\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.000573\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.002063\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.004054\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.000679\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.001345\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9730/10000 (97%)\n",
            "\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.001616\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.001478\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.004458\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.002515\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.130786\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9740/10000 (97%)\n",
            "\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.001180\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.006532\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.000611\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.000715\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.005144\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9729/10000 (97%)\n",
            "\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.001161\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.001018\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.000454\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.015947\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.002380\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9714/10000 (97%)\n",
            "\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.004540\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.011376\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.002488\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.001120\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.097163\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9716/10000 (97%)\n",
            "\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.002673\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.002189\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.000859\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.001426\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.124234\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9714/10000 (97%)\n",
            "\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000528\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.001313\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.001601\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.001728\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.001726\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9724/10000 (97%)\n",
            "\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.001362\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.000852\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.000761\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.001647\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.000612\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9716/10000 (97%)\n",
            "\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.002218\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.017050\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.001422\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.000582\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.001840\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9706/10000 (97%)\n",
            "\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.001265\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.002936\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.000532\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.000927\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.000726\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9724/10000 (97%)\n",
            "\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.001578\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.000660\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.047977\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.044475\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.000562\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 9704/10000 (97%)\n",
            "\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.008104\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.000933\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.000623\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.000573\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.001849\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9700/10000 (97%)\n",
            "\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.001117\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.002083\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.001236\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.006377\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.005254\n",
            "\n",
            "Test set: Average loss: 0.0036, Accuracy: 9638/10000 (96%)\n",
            "\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000751\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.005991\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.001768\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.000831\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.001373\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9700/10000 (97%)\n",
            "\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.004245\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.000768\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.000798\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.000568\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.086843\n",
            "\n",
            "Test set: Average loss: 0.0032, Accuracy: 9688/10000 (97%)\n",
            "\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.078732\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.004433\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.000661\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.042157\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.001430\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 9692/10000 (97%)\n",
            "\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.000503\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.005774\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.008121\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.002473\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.007065\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9732/10000 (97%)\n",
            "\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.047470\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.003651\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.007711\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.000921\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.001483\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9718/10000 (97%)\n",
            "\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.000932\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.065749\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.000605\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.003649\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.001731\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9728/10000 (97%)\n",
            "\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.001366\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.000487\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.000562\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.000842\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.004368\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9678/10000 (97%)\n",
            "\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.007462\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.001235\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.000617\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.008017\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.070545\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9743/10000 (97%)\n",
            "\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.002291\n",
            "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 0.002208\n",
            "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 0.000677\n",
            "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 0.001279\n",
            "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 0.002616\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9741/10000 (97%)\n",
            "\n",
            "Train Epoch: 101 [0/60000 (0%)]\tLoss: 0.001087\n",
            "Train Epoch: 101 [12800/60000 (21%)]\tLoss: 0.001629\n",
            "Train Epoch: 101 [25600/60000 (43%)]\tLoss: 0.000775\n",
            "Train Epoch: 101 [38400/60000 (64%)]\tLoss: 0.001453\n",
            "Train Epoch: 101 [51200/60000 (85%)]\tLoss: 0.000461\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 9702/10000 (97%)\n",
            "\n",
            "Train Epoch: 102 [0/60000 (0%)]\tLoss: 0.005074\n",
            "Train Epoch: 102 [12800/60000 (21%)]\tLoss: 0.001057\n",
            "Train Epoch: 102 [25600/60000 (43%)]\tLoss: 0.055221\n",
            "Train Epoch: 102 [38400/60000 (64%)]\tLoss: 0.001284\n",
            "Train Epoch: 102 [51200/60000 (85%)]\tLoss: 0.001779\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Train Epoch: 103 [0/60000 (0%)]\tLoss: 0.004203\n",
            "Train Epoch: 103 [12800/60000 (21%)]\tLoss: 0.019583\n",
            "Train Epoch: 103 [25600/60000 (43%)]\tLoss: 0.005346\n",
            "Train Epoch: 103 [38400/60000 (64%)]\tLoss: 0.001410\n",
            "Train Epoch: 103 [51200/60000 (85%)]\tLoss: 0.009093\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9681/10000 (97%)\n",
            "\n",
            "Train Epoch: 104 [0/60000 (0%)]\tLoss: 0.114484\n",
            "Train Epoch: 104 [12800/60000 (21%)]\tLoss: 0.019352\n",
            "Train Epoch: 104 [25600/60000 (43%)]\tLoss: 0.001698\n",
            "Train Epoch: 104 [38400/60000 (64%)]\tLoss: 0.009858\n",
            "Train Epoch: 104 [51200/60000 (85%)]\tLoss: 0.000608\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 9713/10000 (97%)\n",
            "\n",
            "8\n",
            "CPU times: user 29min 10s, sys: 13.6 s, total: 29min 24s\n",
            "Wall time: 29min 33s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ0Ia-O5ZSSa",
        "colab_type": "code",
        "outputId": "aecdfb9e-a605-4e25-f09f-ec0aa1f5e265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "source": [
        "%%time\n",
        "# ------------------------------------------- 8 -----------------------------------------------------\n",
        "model8 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5),\n",
        "                      nn.Dropout(0.35, inplace=True),\n",
        "                      nn.Linear(5, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "print(len(list(model8.parameters())))\n",
        "\n",
        "optimizer8 = optim.SGD(model8.parameters(), lr=0.1)\n",
        "for epoch in range(0, 5):\n",
        "      train(model8, train_loader, optimizer8, loss_function, epoch)\n",
        "      ass_test(model8, test_loader, loss_function)\n",
        "\n",
        "# --> Training using dropout ensures that some features aren't considered more important than others by randomly deselecting \n",
        "#     some nodes during the training process. I think a model which uses dropuout is barely biased on the training."
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.306140\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.974462\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.781608\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.683485\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.620702\n",
            "\n",
            "Test set: Average loss: 0.0039, Accuracy: 9302/10000 (93%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.622591\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.410312\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.567970\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.489436\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.552429\n",
            "\n",
            "Test set: Average loss: 0.0031, Accuracy: 9426/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.530663\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.337218\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.296914\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.627043\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.326032\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 9479/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.343894\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.381731\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.250320\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.236459\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.381331\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9559/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.385400\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.381864\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.207946\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.283939\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.329770\n",
            "\n",
            "Test set: Average loss: 0.0052, Accuracy: 8919/10000 (89%)\n",
            "\n",
            "CPU times: user 1min 22s, sys: 581 ms, total: 1min 23s\n",
            "Wall time: 1min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTE5DGkygbT8",
        "colab_type": "code",
        "outputId": "e6d68a7b-0f2f-4542-b674-970e57995c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "source": [
        "%%time\n",
        "# ----------------------------------------------- 9 ---------------------------------------------------------------------\n",
        "\n",
        "ass_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "model9 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(5, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "optimizer9 = optim.SGD(model9.parameters(), lr=0.1)\n",
        "\n",
        "for param in model9.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)\n",
        "    \n",
        "print(len(list(model9.parameters())))\n",
        "\n",
        "for epoch in range(0, 5):\n",
        "      train(model9, ass_train_loader, optimizer9, loss_function, epoch)\n",
        "      ass_test(model9, test_loader, loss_function)\n",
        "\n",
        "# --> When training, the loss reduces faster than in the shuffled model because the data is probably correlated"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.311835\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.377528\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.403388\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.170413\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.190133\n",
            "\n",
            "Test set: Average loss: 0.0034, Accuracy: 9354/10000 (94%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.199399\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.104464\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.161599\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.149482\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.117231\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9515/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.048746\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.065783\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.056629\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.131726\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.077530\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9544/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.016801\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.047444\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.022257\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.096726\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.038727\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 9587/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.012962\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.025609\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.029075\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.043052\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.016519\n",
            "\n",
            "Test set: Average loss: 0.0019, Accuracy: 9653/10000 (97%)\n",
            "\n",
            "CPU times: user 1min 21s, sys: 558 ms, total: 1min 22s\n",
            "Wall time: 1min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYgR1Q1ZnUGk",
        "colab_type": "code",
        "outputId": "549c6d20-ffd7-4eb0-b91a-4e2a28755538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "%%time\n",
        "# ---------------------------------------------- 10 ----------------------------------------------------\n",
        "#  50\n",
        "\n",
        "b_size = len(train_dataset)//2\n",
        "ass_2_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=b_size, shuffle=False)\n",
        "\n",
        "model10 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(5, 10))\n",
        "\n",
        "optimizer10 = optim.SGD(model10.parameters(), lr=0.1)\n",
        "\n",
        "for param in model10.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)\n",
        "\n",
        "print(len(list(model10.parameters())))\n",
        "\n",
        "for epoch in range(0, 5):\n",
        "      train(model10, ass_2_train_loader, optimizer10, loss_function, epoch)\n",
        "      ass_test(model10, test_loader, loss_function)\n",
        "\n",
        "# --> The test accuracy is barely significant\n",
        "# --> The model doesn't have enough data to train on hence the test accuracy\n",
        "# --> This model barely learns anything"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.287766\n",
            "\n",
            "Test set: Average loss: 0.0356, Accuracy: 1631/10000 (16%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.271450\n",
            "\n",
            "Test set: Average loss: 0.0353, Accuracy: 1998/10000 (20%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.251193\n",
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 2322/10000 (23%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.224027\n",
            "\n",
            "Test set: Average loss: 0.0343, Accuracy: 2665/10000 (27%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.188049\n",
            "\n",
            "Test set: Average loss: 0.0335, Accuracy: 3070/10000 (31%)\n",
            "\n",
            "CPU times: user 1min 16s, sys: 444 ms, total: 1min 17s\n",
            "Wall time: 1min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg8_r8eqp5N2",
        "colab_type": "code",
        "outputId": "d5306a93-9880-4a1a-88c5-a3a1b995a1a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "%%time\n",
        "# 30%\n",
        "\n",
        "b_size = int(round((3 * len(train_dataset))//10))\n",
        "\n",
        "ass_3_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=b_size, shuffle=False)\n",
        "\n",
        "model11 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(5, 64))\n",
        "\n",
        "optimizer11 = optim.SGD(model11.parameters(), lr=0.1)\n",
        "\n",
        "for param in model11.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)\n",
        "\n",
        "print(len(list(model11.parameters())))\n",
        "\n",
        "for epoch in range(0, 5):\n",
        "      train(model11, ass_3_train_loader, optimizer11, loss_function, epoch)\n",
        "      ass_test(model11, test_loader, loss_function)\n",
        "\n",
        "# --> The test accuracy is barely significant\n",
        "# --> The model doesn't have enough data to train on hence the test accuracy\n",
        "# --> This model barely learns anything"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 4.173932\n",
            "\n",
            "Test set: Average loss: 0.0645, Accuracy: 867/10000 (9%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 4.109099\n",
            "\n",
            "Test set: Average loss: 0.0635, Accuracy: 1649/10000 (16%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 4.041963\n",
            "\n",
            "Test set: Average loss: 0.0597, Accuracy: 2007/10000 (20%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 3.803080\n",
            "\n",
            "Test set: Average loss: 0.0446, Accuracy: 1804/10000 (18%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.850003\n",
            "\n",
            "Test set: Average loss: 0.0329, Accuracy: 3408/10000 (34%)\n",
            "\n",
            "CPU times: user 1min 15s, sys: 165 ms, total: 1min 15s\n",
            "Wall time: 1min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or-URC6MrcVr",
        "colab_type": "code",
        "outputId": "7e27983a-3ff6-4f43-c89b-a592d9a93233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "%%time\n",
        "# 10%\n",
        "\n",
        "b_size = int(round((1 * len(train_dataset))//10))\n",
        "\n",
        "ass_4_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=b_size, shuffle=False)\n",
        "\n",
        "model12 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(5, 64))\n",
        "\n",
        "optimizer12 = optim.SGD(model12.parameters(), lr=0.1)\n",
        "\n",
        "for param in model12.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)\n",
        "\n",
        "print(len(list(model12.parameters())))\n",
        "\n",
        "for epoch in range(0, 5):\n",
        "      train(model12, ass_4_train_loader, optimizer12, loss_function, epoch)\n",
        "      ass_test(model12, test_loader, loss_function)\n",
        "\n",
        "# --> The test accuracy is barely significant\n",
        "# --> The model doesn't have enough data to train on hence the test accuracy\n",
        "# --> This model is a joke "
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 4.212206\n",
            "\n",
            "Test set: Average loss: 0.0625, Accuracy: 1000/10000 (10%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 3.981749\n",
            "\n",
            "Test set: Average loss: 0.0380, Accuracy: 2544/10000 (25%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.425915\n",
            "\n",
            "Test set: Average loss: 0.0304, Accuracy: 3944/10000 (39%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.936317\n",
            "\n",
            "Test set: Average loss: 0.0255, Accuracy: 4898/10000 (49%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.622102\n",
            "\n",
            "Test set: Average loss: 0.0214, Accuracy: 4995/10000 (50%)\n",
            "\n",
            "CPU times: user 1min 14s, sys: 90.6 ms, total: 1min 14s\n",
            "Wall time: 1min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx878231wz4N",
        "colab_type": "text"
      },
      "source": [
        "**Important!** This task is not too hard, but it is pretty time-consuming. Total computation time is about 4 hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm1Jm5bCpkbd",
        "colab_type": "text"
      },
      "source": [
        "1. Find out how many epochs are needed for our network to stop improving on test dataset (let's stop on 5 epochs without accuracy improvement on the test set). How long does it take? [1]\n",
        "2. Find some problematic examples and show them with `example()` function we defined in class.[1]\n",
        "3. Draw a confusion matrix for your model on test dataset. It is a 10x10 matrix, and in the cell `(i,j)` there is a number of digits `i` classified as digit `j`.[1]\n",
        "4. By default weight of linear layer is initialized with `kaiming_uniform` function and bias is unitialized with `uniform` function (see reset parameters method of Linear class https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py). Initialize all weights as `uniform(-0.1,0.1)` and test. How does this modification affect training process? Is it faster/slower? Is the end result better/worse? Same question form `uniform(-1, 1)`. Same question for `constant(0)` initialization. Don't forget to recreate optimizer for your new model (otherwise you'll optimize parameters of the old model using values from the new one, which does not work).[1]\n",
        "5. Try replacing `Tanh` activation by `Sigmoid` test, how does this modification affect training process? These and further questions assumes that you are changing the initial model (i.e. all modification from previous step are undone). [1]\n",
        "6. Try changing output dimension of the first linear layer  (and input of the second) to `256`, to `1024`. How does this modification affect training process? How does the number of model parameters changes? [1]\n",
        "7. Our model has 2 hidden layers of sizes `512` and `64`. Let's use 3 hidden layers of sizes `512`, `256` and `64`.  How does this modification affect training process? How does the number of model parameters changes? Same question for 3 layers of sizes `512`, `5` and `64`(don't forget to add activation function between linear layers). [1]\n",
        "8. Try adding dropout after first/second layer. How does this modification affect training process? [1]\n",
        "9. Try disabling shuffle in the train dataloader (leave it unchanged in the test dataloader, otherwise testing will not be fair). How does this modification affect training process? Do not forget to reset training weights of the model. [1]\n",
        "10. Try training, using half of the training dataset. 30%. 10%. How does this affect training process? Do not forget to reset training weights of the model. [1] \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89MVN5spyr3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}