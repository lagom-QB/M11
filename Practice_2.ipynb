{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lagom-QB/M11/blob/master/Practice_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY2P_K6PbR4U",
        "colab_type": "text"
      },
      "source": [
        "# Keywords: modules, optimizers, dense layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UwJ0fPUb24R",
        "colab_type": "text"
      },
      "source": [
        "# High level concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A339bun3b6LD",
        "colab_type": "text"
      },
      "source": [
        "## Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrNck7Vsb-gK",
        "colab_type": "text"
      },
      "source": [
        "Modules helps organizing and composing functions and inputs (weihgts) together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHh0RNT6bQa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from torch.nn.modules import loss\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6xmxvkJcTRA",
        "colab_type": "text"
      },
      "source": [
        "Some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbIVrzkecL3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear = nn.Linear(10, 10)\n",
        "linear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqASjjZQckL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear(torch.tensor([1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,0.0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJcHLHt6cXAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "relu = nn.ReLU()\n",
        "relu\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzrQBmD6cfr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([-1.0])\n",
        "relu(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4CehSLxcjyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tanh = nn.Tanh()\n",
        "tanh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfNrJGRnc1po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout = nn.Dropout(0.5)\n",
        "dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RFklgV1c3Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequential = nn.Sequential(nn.Linear(10, 100), nn.Tanh(), nn.Linear(100,100), nn.Tanh(), nn.Linear(100,10))\n",
        "sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH30QbbVc41R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lin1 = nn.Linear(10,100)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.lin2 = nn.Linear(100,100)\n",
        "        self.lin3 = nn.Linear(100,100)\n",
        "        self.lin4 = nn.Linear(100,10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin3(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin4(x)\n",
        "        return x\n",
        "net = Net()\n",
        "net\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hJXnvzvc677",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = loss.CrossEntropyLoss()\n",
        "cross_entropy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PakWOAlNHa8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import Module"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZaSSef3Hc7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import Parameter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhScgmbhF-rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Power(Module):\n",
        "\n",
        "    __constants__ = ['power']\n",
        "\n",
        "    def __init__(self, exponent=3):\n",
        "        super().__init__()\n",
        "        self.exponent = exponent\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.pow(input, self.exponent)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return f'exponent={self.exponent}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1uAg4zzGrWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WPower(Module):    \n",
        "    def __init__(self, ):\n",
        "        super().__init__()\n",
        "        self.exponent = Parameter(torch.Tensor(1))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init.uniform_(self.exponent, a=math.sqrt(5))\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.pow(input, self.exponent)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YemfgVcdIFB",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeszfvqidJ_o",
        "colab_type": "text"
      },
      "source": [
        "Some models are not just functions, but they also have internal parameters (weights/graph inputs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbYduaVOdDID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(linear.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmgsM_OedbPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear.weight\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5f0Q3GCdeHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear.bias\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoSzZUpfdgDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(tanh.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-sapuItdiYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(dropout.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aet5UQbydkp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout.p "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsdfce82dtQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(cross_entropy.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQT6wYz8dpPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(map(lambda x: x.shape, list(sequential.parameters())))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtxKoxdfdmsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(map(lambda x: x.shape, list(net.parameters())))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3SN19HOdrow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(map(lambda x: x.requires_grad, list(net.parameters())))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8zULEKKd37v",
        "colab_type": "text"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqPenEPGd7U5",
        "colab_type": "text"
      },
      "source": [
        "Each module can be in either `eval` or `train` state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFPY0TRNd6Kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout.train()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPk0cHNqdw51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout(torch.ones(10))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1JnLrcLeFYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout.eval()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT0hgQ5PeG_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newseq = nn.Sequential(nn.Dropout(), nn.Dropout())\n",
        "newseq(torch.ones(10))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kETqU1poeKMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newseq.eval()\n",
        "newseq(torch.ones(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxeKQ3r0eP9a",
        "colab_type": "text"
      },
      "source": [
        "**Important**! Train / eval mode has nothing to do with weight training. It just changes behaviour of some modules (i.e. `dropout`, `batchnorm`). For composite modules `.eval()`/`.train()` sets corresponding mode for each of its components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7rIS3A3etBO",
        "colab_type": "text"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyKkp9pcewGR",
        "colab_type": "text"
      },
      "source": [
        "Most of module have default way of parameter initialization, but sometimes we might want to init them explicitly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKX8XpoPer3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear.weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8LyFiCweOYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init.xavier_uniform_(linear.weight)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og6vAbZvfHRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init.constant_(linear.weight, 1.0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6X6oRr2fJ6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(linear.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NcEej-6fL5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in linear.parameters():\n",
        "    init.uniform_(param, -12, 12)\n",
        "list(linear.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bczsQJD_fXJF",
        "colab_type": "text"
      },
      "source": [
        "You can find more initialization functions here: https://pytorch.org/docs/master/nn.html#torch-nn-init."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-HlBUMMfooa",
        "colab_type": "text"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QcAvjRJfvsT",
        "colab_type": "text"
      },
      "source": [
        "Torch has a reach collection of optimizers built-in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D4SLAamfONk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_zpzWMggMHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([1.0], requires_grad = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfWQxhE3gOC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = optim.SGD([x], lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80K1tz4ugP_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x * 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS49qBGzgTEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0nHcNqVgWRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuVGUuqPgYTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr-tEtKEgaIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0dKVjoYgb_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.grad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HkkGT9igdst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd.zero_grad()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8eRwxRQgfNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.grad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bbVM2MHgiWQ",
        "colab_type": "text"
      },
      "source": [
        "# First Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIFr-KUjgmR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKSiYasbgrQ3",
        "colab_type": "text"
      },
      "source": [
        "Let's downlad MNIST --- dataset of handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CaQGiyMgrnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = datasets.MNIST('/data', train=True, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                ]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3h5RcNngxnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = datasets.MNIST('../data', train=False, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VreNjs_ghAEI",
        "colab_type": "text"
      },
      "source": [
        "Dataloaders are responsible for data loading. They help us to split dataset in batches and shuffles the dataset(otherwise each buch will have only variants of a single digit). We will look inside them later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isUaEilOg79-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JwLAUASg-3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "toPIL = transforms.ToPILImage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNt3vzcWheef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def example(i):\n",
        "    print(train_dataset[i][1])\n",
        "    return toPIL(train_dataset[i][0]).resize((256, 256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT3VcfTNhg9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example(10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukAEeDcShinq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader.__iter__().__next__()[1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2xbqs4CiAxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader.__iter__().__next__()[0].shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBOrXp1ZiDQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toPIL(train_loader.__iter__().__next__()[0][0]).resize((256,256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU728eD_iVwF",
        "colab_type": "text"
      },
      "source": [
        "Let's write a simple helper module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drFE7ng0iaY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        return x.view(batch_size, -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyfJfxlYiGY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "for param in model.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8q6alogikey",
        "colab_type": "text"
      },
      "source": [
        "Why do we need `Flatten` module?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1ioiHwWiriu",
        "colab_type": "text"
      },
      "source": [
        "Setup an optimizer:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_ZaRtLhiQpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuGF-VaJixR-",
        "colab_type": "text"
      },
      "source": [
        "Choose a loss function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97rK7imziwi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = loss.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY1JXkwsi4B7",
        "colab_type": "text"
      },
      "source": [
        "And start training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTGlEEUsi21g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, optimizer, loss_function, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_function(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 200 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJZcV3I1it47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, test_loader, loss_function):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            test_loss += loss_function(output, target).sum().item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMHY4BfdjJFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " %%time\n",
        " for epoch in range(1, 100):\n",
        "        train(model, train_loader, optimizer, loss_function, epoch)\n",
        "        test(model, test_loader, loss_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v18YmlwUoxY8",
        "colab_type": "text"
      },
      "source": [
        "# Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W20EUe7AxioK",
        "colab_type": "text"
      },
      "source": [
        "## Due to 10AM, 20.05.2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO6zst4UpcMR",
        "colab_type": "text"
      },
      "source": [
        "## 1. MNIST playground [10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx878231wz4N",
        "colab_type": "text"
      },
      "source": [
        "**Important!** This task is not too hard, but it is pretty time-consuming. Total computation time is about 4 hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm1Jm5bCpkbd",
        "colab_type": "text"
      },
      "source": [
        "1. Find out how many epochs are needed for our network to stop improving on test dataset (let's stop on 5 epochs without accuracy improvement on the test set). How long does it take? [1]\n",
        "2. Find some problematic examples and show them with `example()` function we defined in class.[1]\n",
        "3. Draw a confusion matrix for your model on test dataset. It is a 10x10 matrix, and in the cell `(i,j)` there is a number of digits `i` classified as digit `j`.[1]\n",
        "4. By default weight of linear layer is initialized with `kaiming_uniform` function and bias is unitialized with `uniform` function (see reset parameters method of Linear class https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py). Initialize all weights as `uniform(-0.1,0.1)` and test. How does this modification affect training process? Is it faster/slower? Is the end result better/worse? Same question form `uniform(-1, 1)`. Same question for `constant(0)` initialization. Don't forget to recreate optimizer for your new model (otherwise you'll optimize parameters of the old model using values from the new one, which does not work).[1]\n",
        "5. Try replacing `Tanh` activation by `Sigmoid` test, how does this modification affect training process? These and further questions assumes that you are changing the initial model (i.e. all modification from previous step are undone). [1]\n",
        "6. Try changing output dimension of the first linear layer  (and input of the second) to `256`, to `1024`. How does this modification affect training process? How does the number of model parameters changes? [1]\n",
        "7. Our model has 2 hidden layers of sizes `512` and `64`. Let's use 3 hidden layers of sizes `512`, `256` and `64`.  How does this modification affect training process? How does the number of model parameters changes? Same question for 3 layers of sizes `512`, `5` and `64`(don't forget to add activation function between linear layers). [1]\n",
        "8. Try adding dropout after first/second layer. How does this modification affect training process? [1]\n",
        "9. Try disabling shuffle in the train dataloader (leave it unchanged in the test dataloader, otherwise testing will not be fair). How does this modification affect training process? Do not forget to reset training weights of the model. [1]\n",
        "10. Try training, using half of the training dataset. 30%. 10%. How does this affect training process? Do not forget to reset training weights of the model. [1] \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89MVN5spyr3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}