{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lagom-QB/M11/blob/master/Practice_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY2P_K6PbR4U",
        "colab_type": "text"
      },
      "source": [
        "# Keywords: modules, optimizers, dense layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UwJ0fPUb24R",
        "colab_type": "text"
      },
      "source": [
        "# High level concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A339bun3b6LD",
        "colab_type": "text"
      },
      "source": [
        "## Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrNck7Vsb-gK",
        "colab_type": "text"
      },
      "source": [
        "Modules helps organizing and composing functions and inputs (weights) together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHh0RNT6bQa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from torch.nn.modules import loss\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6xmxvkJcTRA",
        "colab_type": "text"
      },
      "source": [
        "Some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbIVrzkecL3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e14c4684-bfa0-4767-e7de-5841ebe213a3"
      },
      "source": [
        "linear = nn.Linear(10, 10)\n",
        "linear"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=10, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqASjjZQckL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e3bf5151-b8b4-450e-94dc-cbcae507f51b"
      },
      "source": [
        "linear(torch.tensor([1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,0.0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.6963,  1.5029, -0.8684,  3.1083,  4.5538, -0.9848, -0.6275, -1.8187,\n",
              "         5.8677,  2.1064], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJcHLHt6cXAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd7ca0ce-1e24-46ad-a48b-82ec1228acb2"
      },
      "source": [
        "relu = nn.ReLU()\n",
        "relu\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ReLU()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzrQBmD6cfr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b90004f-4ec6-4c59-dadb-0eaa24d75fab"
      },
      "source": [
        "x = torch.tensor([-1.0])\n",
        "relu(x)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4CehSLxcjyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "045b46c3-95e2-4bfe-c7fe-0d75dcf78d1c"
      },
      "source": [
        "tanh = nn.Tanh()\n",
        "tanh"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tanh()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfNrJGRnc1po",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fcda7bf-85fc-428f-9974-f63b1a2fec65"
      },
      "source": [
        "dropout = nn.Dropout(0.45, inplace=True)\n",
        "dropout"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dropout(p=0.45, inplace=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RFklgV1c3Lp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "f434c7b6-dd4c-4c40-b017-1d0f7dfd9267"
      },
      "source": [
        "sequential = nn.Sequential(nn.Linear(10, 100), nn.Tanh(), nn.Linear(100,100), nn.Dropout(0.4, inplace = True), nn.Linear(100,10))\n",
        "sequential"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=100, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (3): Dropout(p=0.4, inplace=True)\n",
              "  (4): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH30QbbVc41R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "655286b4-fc81-4982-81c2-40440396e0c1"
      },
      "source": [
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lin1 = nn.Linear(10,100)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.lin2 = nn.Linear(100,100)\n",
        "        self.lin3 = nn.Linear(100,100)\n",
        "        self.lin4 = nn.Linear(100,10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin3(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin4(x)\n",
        "        return x\n",
        "net = Net()\n",
        "net\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (lin1): Linear(in_features=10, out_features=100, bias=True)\n",
              "  (act1): Tanh()\n",
              "  (lin2): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (lin3): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (lin4): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hJXnvzvc677",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ed01191-2f74-4510-d2e7-2811b493baf1"
      },
      "source": [
        "cross_entropy = loss.CrossEntropyLoss()\n",
        "cross_entropy\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PakWOAlNHa8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import Module"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZaSSef3Hc7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import Parameter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhScgmbhF-rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Power(Module):\n",
        "\n",
        "    __constants__ = ['exponent']\n",
        "\n",
        "    def __init__(self, exponent=3):\n",
        "        super().__init__()\n",
        "        self.exponent = exponent\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.pow(input, self.exponent)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return f'exponent={self.exponent}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z_jvFGhOt18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0bc3a08-a0b5-4533-ba62-7b136dc8c1e9"
      },
      "source": [
        "Power(exponent = 4)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Power(exponent=4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1uAg4zzGrWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WPower(Module):    \n",
        "    def __init__(self, ):\n",
        "        super().__init__()\n",
        "        self.exponent = Parameter(torch.Tensor(1))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init.uniform_(self.exponent, a=math.sqrt(5))\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.pow(input, self.exponent)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YemfgVcdIFB",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeszfvqidJ_o",
        "colab_type": "text"
      },
      "source": [
        "Some models are not just functions, but they also have internal parameters (weights/graph inputs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbYduaVOdDID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "abd00d70-84a1-480d-abef-e4a6cee28ed3"
      },
      "source": [
        "list(linear.parameters())\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0027, -0.2211, -0.2735, -0.0491,  0.2319, -0.2681, -0.2732,  0.2109,\n",
              "           0.0271, -0.2290],\n",
              "         [ 0.2957, -0.1693, -0.0366, -0.2077,  0.2994,  0.0644,  0.0490, -0.3114,\n",
              "           0.2942, -0.2810],\n",
              "         [ 0.1992, -0.2892,  0.0674,  0.0507,  0.1135, -0.2438,  0.0013,  0.2407,\n",
              "          -0.2101,  0.1690],\n",
              "         [ 0.0726, -0.1074,  0.2681, -0.1294,  0.1598,  0.2365,  0.2077,  0.2524,\n",
              "          -0.2919,  0.0020],\n",
              "         [-0.2195,  0.1777,  0.2155, -0.1588,  0.0353,  0.3071,  0.1882,  0.2432,\n",
              "          -0.0661,  0.0005],\n",
              "         [ 0.0677,  0.0386, -0.1665,  0.3045, -0.1042,  0.1134,  0.0949, -0.1904,\n",
              "          -0.1467, -0.2724],\n",
              "         [-0.2064,  0.2832,  0.0202,  0.1638, -0.2312,  0.0429, -0.0152,  0.0761,\n",
              "          -0.1280, -0.2837],\n",
              "         [ 0.1916,  0.1903,  0.2784,  0.1428,  0.0864,  0.1358, -0.1625, -0.3057,\n",
              "          -0.1806,  0.1590],\n",
              "         [ 0.0733,  0.1437, -0.1913, -0.2587, -0.0312,  0.1236,  0.2719,  0.2633,\n",
              "           0.2628, -0.1769],\n",
              "         [ 0.0918,  0.1295, -0.0928,  0.0852, -0.1370,  0.2644, -0.0311,  0.0739,\n",
              "           0.0751,  0.2892]], requires_grad=True), Parameter containing:\n",
              " tensor([ 0.1966,  0.1032, -0.0421, -0.1005, -0.2809,  0.1715, -0.1555,  0.1645,\n",
              "          0.1554, -0.2582], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmgsM_OedbPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "454d299d-081c-41bf-e165-e4f8bd266193"
      },
      "source": [
        "linear.weight\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0027, -0.2211, -0.2735, -0.0491,  0.2319, -0.2681, -0.2732,  0.2109,\n",
              "          0.0271, -0.2290],\n",
              "        [ 0.2957, -0.1693, -0.0366, -0.2077,  0.2994,  0.0644,  0.0490, -0.3114,\n",
              "          0.2942, -0.2810],\n",
              "        [ 0.1992, -0.2892,  0.0674,  0.0507,  0.1135, -0.2438,  0.0013,  0.2407,\n",
              "         -0.2101,  0.1690],\n",
              "        [ 0.0726, -0.1074,  0.2681, -0.1294,  0.1598,  0.2365,  0.2077,  0.2524,\n",
              "         -0.2919,  0.0020],\n",
              "        [-0.2195,  0.1777,  0.2155, -0.1588,  0.0353,  0.3071,  0.1882,  0.2432,\n",
              "         -0.0661,  0.0005],\n",
              "        [ 0.0677,  0.0386, -0.1665,  0.3045, -0.1042,  0.1134,  0.0949, -0.1904,\n",
              "         -0.1467, -0.2724],\n",
              "        [-0.2064,  0.2832,  0.0202,  0.1638, -0.2312,  0.0429, -0.0152,  0.0761,\n",
              "         -0.1280, -0.2837],\n",
              "        [ 0.1916,  0.1903,  0.2784,  0.1428,  0.0864,  0.1358, -0.1625, -0.3057,\n",
              "         -0.1806,  0.1590],\n",
              "        [ 0.0733,  0.1437, -0.1913, -0.2587, -0.0312,  0.1236,  0.2719,  0.2633,\n",
              "          0.2628, -0.1769],\n",
              "        [ 0.0918,  0.1295, -0.0928,  0.0852, -0.1370,  0.2644, -0.0311,  0.0739,\n",
              "          0.0751,  0.2892]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5f0Q3GCdeHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "bc6c81ba-5529-42bf-e6b2-eb0602abee26"
      },
      "source": [
        "linear.bias\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([ 0.1966,  0.1032, -0.0421, -0.1005, -0.2809,  0.1715, -0.1555,  0.1645,\n",
              "         0.1554, -0.2582], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoSzZUpfdgDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56bc9aff-a0d4-43ff-a112-e62d9ef8940d"
      },
      "source": [
        "list(tanh.parameters())\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-sapuItdiYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b137c898-a504-419f-d00c-f3e073355229"
      },
      "source": [
        "list(dropout.parameters())\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aet5UQbydkp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d42b8aa0-712d-461c-f7bd-8c9a380056b9"
      },
      "source": [
        "dropout.p "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsdfce82dtQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b949522-051b-4ad0-b6c7-141dec78da20"
      },
      "source": [
        "list(cross_entropy.parameters())\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQT6wYz8dpPH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "8cf20527-25e4-4da8-c65a-654a7ef565e9"
      },
      "source": [
        "list(map(lambda x: x.shape, list(sequential.parameters())))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([100, 10]),\n",
              " torch.Size([100]),\n",
              " torch.Size([100, 100]),\n",
              " torch.Size([100]),\n",
              " torch.Size([10, 100]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtxKoxdfdmsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "61044257-bbcb-4db6-e45f-7caa5f3a1c95"
      },
      "source": [
        "list(map(lambda x: x.shape, list(net.parameters())))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([100, 10]),\n",
              " torch.Size([100]),\n",
              " torch.Size([100, 100]),\n",
              " torch.Size([100]),\n",
              " torch.Size([100, 100]),\n",
              " torch.Size([100]),\n",
              " torch.Size([10, 100]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3SN19HOdrow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da9ebe05-dad9-4a40-c5be-98e7ca638474"
      },
      "source": [
        "list(map(lambda x: x.requires_grad, list(net.parameters())))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True, True, True, True, True, True, True, True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8zULEKKd37v",
        "colab_type": "text"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqPenEPGd7U5",
        "colab_type": "text"
      },
      "source": [
        "Each module can be in either `eval` or `train` state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFPY0TRNd6Kn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f82e44b-740c-4715-f7b2-022a1830100f"
      },
      "source": [
        "dropout.train()\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dropout(p=0.45, inplace=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPk0cHNqdw51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8b9289fb-d25a-483b-b2c6-58d9e46feaee"
      },
      "source": [
        "dropout(torch.ones(10))\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 0.0000, 1.8182, 0.0000, 1.8182, 0.0000, 1.8182,\n",
              "        1.8182])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1JnLrcLeFYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f26707ad-fe29-4b9a-c5e1-9fc952c6bf85"
      },
      "source": [
        "dropout.eval()\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dropout(p=0.45, inplace=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT0hgQ5PeG_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8df10e4-e88a-4ddd-e113-a43a81798d2b"
      },
      "source": [
        "newseq = nn.Sequential(nn.Dropout(), nn.Dropout())\n",
        "newseq(torch.ones(10))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 4., 0., 0., 4., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kETqU1poeKMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0c7a289-9dc4-42cb-d5c7-0225738b6432"
      },
      "source": [
        "newseq.eval()\n",
        "newseq(torch.ones(10))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxeKQ3r0eP9a",
        "colab_type": "text"
      },
      "source": [
        "**Important**! Train / eval mode has nothing to do with weight training. It just changes behaviour of some modules (i.e. `dropout`, `batchnorm`). For composite modules `.eval()`/`.train()` sets corresponding mode for each of its components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7rIS3A3etBO",
        "colab_type": "text"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyKkp9pcewGR",
        "colab_type": "text"
      },
      "source": [
        "Most of module have default way of parameter initialization, but sometimes we might want to init them explicitly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKX8XpoPer3N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "f3c71ef8-e65f-45bc-8db0-270627b61cad"
      },
      "source": [
        "linear.weight"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0027, -0.2211, -0.2735, -0.0491,  0.2319, -0.2681, -0.2732,  0.2109,\n",
              "          0.0271, -0.2290],\n",
              "        [ 0.2957, -0.1693, -0.0366, -0.2077,  0.2994,  0.0644,  0.0490, -0.3114,\n",
              "          0.2942, -0.2810],\n",
              "        [ 0.1992, -0.2892,  0.0674,  0.0507,  0.1135, -0.2438,  0.0013,  0.2407,\n",
              "         -0.2101,  0.1690],\n",
              "        [ 0.0726, -0.1074,  0.2681, -0.1294,  0.1598,  0.2365,  0.2077,  0.2524,\n",
              "         -0.2919,  0.0020],\n",
              "        [-0.2195,  0.1777,  0.2155, -0.1588,  0.0353,  0.3071,  0.1882,  0.2432,\n",
              "         -0.0661,  0.0005],\n",
              "        [ 0.0677,  0.0386, -0.1665,  0.3045, -0.1042,  0.1134,  0.0949, -0.1904,\n",
              "         -0.1467, -0.2724],\n",
              "        [-0.2064,  0.2832,  0.0202,  0.1638, -0.2312,  0.0429, -0.0152,  0.0761,\n",
              "         -0.1280, -0.2837],\n",
              "        [ 0.1916,  0.1903,  0.2784,  0.1428,  0.0864,  0.1358, -0.1625, -0.3057,\n",
              "         -0.1806,  0.1590],\n",
              "        [ 0.0733,  0.1437, -0.1913, -0.2587, -0.0312,  0.1236,  0.2719,  0.2633,\n",
              "          0.2628, -0.1769],\n",
              "        [ 0.0918,  0.1295, -0.0928,  0.0852, -0.1370,  0.2644, -0.0311,  0.0739,\n",
              "          0.0751,  0.2892]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8LyFiCweOYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "39fc62ab-14bb-4453-9f6e-0f1584813e14"
      },
      "source": [
        "init.xavier_uniform_(linear.weight)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.4791,  0.3153, -0.2981,  0.4577,  0.0855, -0.4668, -0.3250,  0.2268,\n",
              "          0.0335, -0.1580],\n",
              "        [ 0.3158, -0.5197,  0.2526, -0.0163, -0.1385, -0.5269, -0.1296, -0.2408,\n",
              "         -0.0605,  0.4791],\n",
              "        [ 0.1861,  0.3523,  0.3250,  0.0771, -0.2959,  0.4437, -0.3315, -0.0956,\n",
              "         -0.1429, -0.4993],\n",
              "        [-0.0592, -0.0019,  0.3306, -0.0563, -0.4209,  0.3499,  0.5453, -0.1047,\n",
              "         -0.5163,  0.2789],\n",
              "        [ 0.1696,  0.3643,  0.4865, -0.4270, -0.2468,  0.2677,  0.2060,  0.3171,\n",
              "          0.1841, -0.1748],\n",
              "        [-0.4786, -0.2658, -0.4344,  0.5344, -0.1596, -0.2098,  0.4759,  0.5139,\n",
              "          0.5280, -0.1852],\n",
              "        [ 0.3429,  0.1368, -0.1375,  0.0058,  0.4810,  0.2855,  0.1015, -0.3473,\n",
              "         -0.2691,  0.0286],\n",
              "        [ 0.0411, -0.5433,  0.0348,  0.2818,  0.4250, -0.4068,  0.0112, -0.2955,\n",
              "          0.1399, -0.0260],\n",
              "        [-0.3189,  0.4794,  0.2225, -0.5079, -0.2746, -0.4354, -0.4586,  0.4850,\n",
              "          0.2630,  0.4807],\n",
              "        [-0.1260, -0.1152, -0.2383, -0.1679,  0.3399, -0.0370, -0.3758, -0.4072,\n",
              "         -0.2920,  0.1636]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og6vAbZvfHRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "c4924ea3-9afb-4d82-fcda-0b5cb6cae76c"
      },
      "source": [
        "init.constant_(linear.weight, 1.0)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6X6oRr2fJ6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "5e17da65-2244-44ad-e8db-89603ace90ba"
      },
      "source": [
        "list(linear.parameters())\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.1966,  0.1032, -0.0421, -0.1005, -0.2809,  0.1715, -0.1555,  0.1645,\n",
              "          0.1554, -0.2582], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NcEej-6fL5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "12b606ac-828b-4a54-f2ee-5385c8c43f7b"
      },
      "source": [
        "for param in linear.parameters():\n",
        "    init.uniform_(param, -12, 12)\n",
        "list(linear.parameters())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ -0.0693,   4.0672,  -9.7008,   5.6510, -11.4066,  -6.3090, -11.0726,\n",
              "            3.8310, -10.2759,   6.3835],\n",
              "         [  5.1474,   2.8737,  -6.2926,   0.0378,   2.2584, -10.2943,   6.6297,\n",
              "            7.7498,  -5.3114,  11.5358],\n",
              "         [ -6.4542,  -4.9942,  -9.8922,  -3.3351,   2.9393,   9.9581,  -4.6675,\n",
              "           -4.8261,  -4.7029,   1.0023],\n",
              "         [  3.5115,  -7.2074,   4.1617,   9.1712,  -0.9573,  -6.2061,   4.7461,\n",
              "            3.1043,  -2.0520,  -3.8580],\n",
              "         [-11.4583,  -7.8245,   1.5411,  -8.5157,  10.7574,  -1.1466,  -3.6018,\n",
              "           -4.6622,   7.4345,  10.9662],\n",
              "         [  8.6711,  -0.4452,  -6.0770,  -3.1184,  -6.7547,   2.2255,   6.0005,\n",
              "            2.5647,   7.9769,  -3.1634],\n",
              "         [  4.3004,  11.5693,  -1.2766,   0.2349,   0.9411,  -1.6166,   6.6567,\n",
              "           -7.2181,   8.3802,   0.2843],\n",
              "         [ -3.1749,   8.8571,  -7.3255,  -8.5279,   2.8075,  11.5442,  -7.8383,\n",
              "            6.0542,   2.0503,  10.3908],\n",
              "         [  9.6133,   9.2564,   2.9407,  -7.9668,   9.6855,   8.5666,  -7.0240,\n",
              "            0.6091,   1.3934,  -7.8484],\n",
              "         [  0.2101,  -7.7976,   0.9041,  -3.2202,  -4.3870, -10.6646,  -4.1874,\n",
              "           -2.8395,   0.9629,   1.0201]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-10.4344,  -7.6326,   2.6546, -11.8482,   0.2135,  -3.9957,  -3.3783,\n",
              "          -7.9953,  -9.3471,  -4.9607], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bczsQJD_fXJF",
        "colab_type": "text"
      },
      "source": [
        "You can find more initialization functions here: https://pytorch.org/docs/master/nn.html#torch-nn-init."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-HlBUMMfooa",
        "colab_type": "text"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QcAvjRJfvsT",
        "colab_type": "text"
      },
      "source": [
        "Torch has a reach collection of optimizers built-in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D4SLAamfONk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_zpzWMggMHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([1.0], requires_grad = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfWQxhE3gOC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = optim.SGD([x], lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80K1tz4ugP_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x * 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS49qBGzgTEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0nHcNqVgWRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02866348-4ebd-47a1-d22a-9f46a9f08d3d"
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuVGUuqPgYTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr-tEtKEgaIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "470535c2-4bb2-4bf4-994b-4c91e7a325e9"
      },
      "source": [
        "x"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.8000], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0dKVjoYgb_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d11d2690-c3f2-4f95-b2e9-9094633d9fe6"
      },
      "source": [
        "x.grad\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HkkGT9igdst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd.zero_grad()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8eRwxRQgfNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7578fdfa-a5a4-4363-cee5-676a8628c91f"
      },
      "source": [
        "x.grad\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bbVM2MHgiWQ",
        "colab_type": "text"
      },
      "source": [
        "# First Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIFr-KUjgmR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKSiYasbgrQ3",
        "colab_type": "text"
      },
      "source": [
        "Let's downlad MNIST --- dataset of handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CaQGiyMgrnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = datasets.MNIST('/data', train=True, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                ]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3h5RcNngxnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = datasets.MNIST('../data', train=False, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VreNjs_ghAEI",
        "colab_type": "text"
      },
      "source": [
        "Dataloaders are responsible for data loading. They help us to split dataset in batches and shuffles the dataset(otherwise each buch will have only variants of a single digit). We will look inside them later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isUaEilOg79-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JwLAUASg-3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "toPIL = transforms.ToPILImage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNt3vzcWheef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def example(i):\n",
        "    print(train_dataset[i][1])\n",
        "    return toPIL(train_dataset[i][0]).resize((256, 256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS0IXIAOk_8K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "c00f0f16-f292-4bbc-9355-aee5bacf6320"
      },
      "source": [
        "example(9)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F67B78164E0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT3VcfTNhg9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "f99c3ea5-9107-456e-8c0a-9878643a9975"
      },
      "source": [
        "example(10)\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F67B8056710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukAEeDcShinq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "80f2de55-ae84-426a-a08e-29d19041198b"
      },
      "source": [
        "train_loader.__iter__().__next__()[1]\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 9, 6, 9, 0, 5, 3, 6, 9, 1, 3, 8, 0, 6, 8, 9, 3, 3, 4, 5, 6, 5, 5, 7,\n",
              "        8, 2, 6, 0, 8, 9, 3, 4, 0, 0, 9, 4, 6, 0, 8, 7, 3, 6, 2, 7, 9, 7, 5, 3,\n",
              "        6, 1, 4, 3, 8, 8, 2, 1, 1, 3, 8, 0, 1, 3, 8, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2xbqs4CiAxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbe093c4-78c1-4d06-8adf-92f98fdc068a"
      },
      "source": [
        "train_loader.__iter__().__next__()[0].shape\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBOrXp1ZiDQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "8390bf71-cd93-4bd6-8b5b-92f60305297a"
      },
      "source": [
        "toPIL(train_loader.__iter__().__next__()[0][0]).resize((256,256))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F67BAEFAE10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU728eD_iVwF",
        "colab_type": "text"
      },
      "source": [
        "Let's write a simple helper module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drFE7ng0iaY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        return x.view(batch_size, -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyfJfxlYiGY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "for param in model.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8q6alogikey",
        "colab_type": "text"
      },
      "source": [
        "Why do we need `Flatten` module?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1ioiHwWiriu",
        "colab_type": "text"
      },
      "source": [
        "Setup an optimizer:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_ZaRtLhiQpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuGF-VaJixR-",
        "colab_type": "text"
      },
      "source": [
        "Choose a loss function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97rK7imziwi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = loss.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY1JXkwsi4B7",
        "colab_type": "text"
      },
      "source": [
        "And start training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTGlEEUsi21g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, optimizer, loss_function, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_function(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 200 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJZcV3I1it47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, test_loader, loss_function):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            test_loss += loss_function(output, target).sum().item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMHY4BfdjJFr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94f74b4c-476b-45d7-8e49-ad4896d15b7f"
      },
      "source": [
        " %%time\n",
        " for epoch in range(1, 100):\n",
        "        train(model, train_loader, optimizer, loss_function, epoch)\n",
        "        test(model, test_loader, loss_function)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000208\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.000162\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.000132\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.000218\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.000085\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.000158\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.000074\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.000075\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.000118\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.000139\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.000123\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.000091\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.000121\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.000175\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000051\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.000028\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.000129\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.000072\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.000083\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.000140\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.000090\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000117\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.000052\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.000179\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.000189\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.000063\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000124\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.000062\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.000054\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000047\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000143\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.000083\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000096\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.000077\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.000073\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000136\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000179\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000086\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000125\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000080\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000039\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000125\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000129\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000083\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000073\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000102\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.000213\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.000054\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.000039\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000125\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.000098\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.000096\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.000082\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.000179\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.000114\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000059\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.000077\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.000071\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.000106\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.000169\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.000076\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.000111\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.000064\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.000102\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.000091\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.000125\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.000078\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.000119\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.000087\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.000105\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.000073\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.000070\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.000053\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.000118\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.000188\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000073\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.000102\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.000127\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.000124\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.000135\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.000084\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.000129\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.000126\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.000163\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.000063\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000055\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.000101\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.000103\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.000135\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.000065\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.000108\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.000161\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.000047\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.000160\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.000063\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.000083\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.000018\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.000073\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.000066\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.000081\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.000070\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.000034\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.000132\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.000063\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.000188\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.000053\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.000069\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.000142\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.000051\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.000064\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000071\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.000099\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.000104\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.000058\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.000068\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000117\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.000047\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.000119\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.000093\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.000078\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.000074\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.000086\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.000061\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.000064\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.000101\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.000082\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.000167\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.000057\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.000082\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000119\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000084\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.000099\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.000039\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.000128\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.000056\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.000101\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.000091\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.000071\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.000076\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.000041\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000084\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.000037\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.000039\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.000110\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.000033\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.000119\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.000077\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.000084\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.000047\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.000088\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.000084\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.000150\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.000025\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.000043\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.000128\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.000057\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.000058\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.000041\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.000049\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.000095\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000070\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.000043\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.000122\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.000057\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.000064\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.000028\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.000121\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.000058\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.000203\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000128\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.000123\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.000134\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.000063\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.000102\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.000094\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000086\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.000097\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.000031\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.000085\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.000066\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000065\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.000052\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.000090\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.000062\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.000085\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.000067\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.000081\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.000113\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.000105\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.000090\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.000100\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.000105\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.000172\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.000123\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.000080\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000164\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.000062\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.000071\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.000073\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.000043\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.000053\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.000095\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.000057\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.000053\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.000073\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000034\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.000101\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.000054\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.000138\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.000050\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.000097\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.000129\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.000029\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.000118\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.000028\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.000052\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.000040\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.000031\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.000105\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.000048\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000170\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.000085\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.000044\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.000037\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000157\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000257\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.000043\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.000032\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.000112\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.000073\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000085\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.000171\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.000120\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.000034\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.000080\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000036\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.000065\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.000065\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.000053\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.000041\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000080\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.000158\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.000076\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.000100\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.000180\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.000088\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.000061\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.000037\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.000079\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.000023\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.000051\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.000078\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.000044\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.000026\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.000088\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.000049\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.000040\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.000053\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.000029\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.000066\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.000070\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.000045\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.000060\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.000068\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.000029\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.000065\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.000101\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.000103\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.000097\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.000048\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.000082\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.000062\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.000134\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.000054\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.000075\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.000065\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.000059\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.000080\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.000042\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.000034\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000077\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.000042\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.000059\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.000091\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.000079\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.000039\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.000080\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.000057\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.000053\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.000044\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.000139\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.000088\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.000059\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.000061\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.000110\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.000059\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.000040\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.000090\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.000118\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.000073\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.000032\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.000082\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.000046\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.000067\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.000043\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.000080\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.000055\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.000061\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.000100\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.000068\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.000065\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.000040\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.000079\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.000052\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.000081\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.000030\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.000128\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.000032\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.000028\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.000047\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.000061\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.000086\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.000064\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.000058\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.000045\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.000043\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.000081\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.000043\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.000171\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.000042\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.000041\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.000080\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.000095\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.000032\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.000154\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.000056\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.000041\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.000042\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.000071\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.000034\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.000042\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.000050\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.000043\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.000055\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.000031\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.000089\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.000052\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.000044\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.000060\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.000120\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.000093\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 0.000042\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.000070\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.000063\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.000049\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000039\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.000187\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.000055\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.000059\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.000024\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.000050\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.000060\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.000046\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.000071\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.000042\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.000052\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.000084\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.000064\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.000042\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.000076\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.000054\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.000018\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.000057\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.000142\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.000036\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.000066\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.000070\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.000024\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.000052\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.000048\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.000059\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.000063\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.000061\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 0.000041\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.000037\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.000043\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.000079\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.000045\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.000027\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.000042\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.000049\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.000113\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.000104\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.000061\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.000083\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.000037\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.000029\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.000041\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.000034\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.000073\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.000052\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.000118\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.000060\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.000121\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.000040\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.000140\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.000015\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.000033\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.000068\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.000090\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.000111\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.000067\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.000058\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.000046\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.000081\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.000029\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.000049\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.000071\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.000038\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.000035\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000027\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.000017\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.000026\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.000052\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.000059\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.000085\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.000093\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.000027\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.000073\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.000060\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.000075\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.000034\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.000056\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.000018\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.000075\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.000055\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.000071\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.000058\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.000089\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.000006\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000041\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.000095\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.000068\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.000072\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.000076\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.000005\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.000028\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.000042\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.000078\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.000088\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.000009\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.000030\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.000043\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.000028\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.000084\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000040\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.000056\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.000038\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.000032\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.000088\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.000050\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.000032\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.000061\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.000037\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.000072\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.000024\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.000079\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.000048\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.000040\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.000021\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.000024\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.000059\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.000021\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.000021\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.000024\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000053\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.000075\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.000106\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.000042\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.000085\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.000077\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.000062\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.000020\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.000050\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.000062\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.000045\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.000025\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.000040\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.000065\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.000060\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.000092\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.000045\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.000048\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.000024\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.000084\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "CPU times: user 28min 49s, sys: 6.85 s, total: 28min 56s\n",
            "Wall time: 29min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v18YmlwUoxY8",
        "colab_type": "text"
      },
      "source": [
        "# Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W20EUe7AxioK",
        "colab_type": "text"
      },
      "source": [
        "## Due to 10AM, 20.05.2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO6zst4UpcMR",
        "colab_type": "text"
      },
      "source": [
        "## 1. MNIST playground [10]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtSB7TYDiWJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "64ce48df-b182-46be-c080-7e2677dfe897"
      },
      "source": [
        "#2 \n",
        "# example(4321) #The 0 looks like a 6 to me\n",
        "# example(600) #The nine looks like a 1 to me\n",
        "# example(4542) #Is that a 2?\n",
        "# example(56742) #This 9 is a joke"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F67B79F83C8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjSuqqK1jN9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx878231wz4N",
        "colab_type": "text"
      },
      "source": [
        "**Important!** This task is not too hard, but it is pretty time-consuming. Total computation time is about 4 hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm1Jm5bCpkbd",
        "colab_type": "text"
      },
      "source": [
        "1. Find out how many epochs are needed for our network to stop improving on test dataset (let's stop on 5 epochs without accuracy improvement on the test set). How long does it take? [1]\n",
        "2. Find some problematic examples and show them with `example()` function we defined in class.[1]\n",
        "3. Draw a confusion matrix for your model on test dataset. It is a 10x10 matrix, and in the cell `(i,j)` there is a number of digits `i` classified as digit `j`.[1]\n",
        "4. By default weight of linear layer is initialized with `kaiming_uniform` function and bias is unitialized with `uniform` function (see reset parameters method of Linear class https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py). Initialize all weights as `uniform(-0.1,0.1)` and test. How does this modification affect training process? Is it faster/slower? Is the end result better/worse? Same question form `uniform(-1, 1)`. Same question for `constant(0)` initialization. Don't forget to recreate optimizer for your new model (otherwise you'll optimize parameters of the old model using values from the new one, which does not work).[1]\n",
        "5. Try replacing `Tanh` activation by `Sigmoid` test, how does this modification affect training process? These and further questions assumes that you are changing the initial model (i.e. all modification from previous step are undone). [1]\n",
        "6. Try changing output dimension of the first linear layer  (and input of the second) to `256`, to `1024`. How does this modification affect training process? How does the number of model parameters changes? [1]\n",
        "7. Our model has 2 hidden layers of sizes `512` and `64`. Let's use 3 hidden layers of sizes `512`, `256` and `64`.  How does this modification affect training process? How does the number of model parameters changes? Same question for 3 layers of sizes `512`, `5` and `64`(don't forget to add activation function between linear layers). [1]\n",
        "8. Try adding dropout after first/second layer. How does this modification affect training process? [1]\n",
        "9. Try disabling shuffle in the train dataloader (leave it unchanged in the test dataloader, otherwise testing will not be fair). How does this modification affect training process? Do not forget to reset training weights of the model. [1]\n",
        "10. Try training, using half of the training dataset. 30%. 10%. How does this affect training process? Do not forget to reset training weights of the model. [1] \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89MVN5spyr3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}