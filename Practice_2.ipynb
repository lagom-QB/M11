{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lagom-QB/M11/blob/master/Practice_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY2P_K6PbR4U",
        "colab_type": "text"
      },
      "source": [
        "# Keywords: modules, optimizers, dense layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UwJ0fPUb24R",
        "colab_type": "text"
      },
      "source": [
        "# High level concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A339bun3b6LD",
        "colab_type": "text"
      },
      "source": [
        "## Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrNck7Vsb-gK",
        "colab_type": "text"
      },
      "source": [
        "Modules helps organizing and composing functions and inputs (weights) together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHh0RNT6bQa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from torch.nn.modules import loss\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6xmxvkJcTRA",
        "colab_type": "text"
      },
      "source": [
        "Some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbIVrzkecL3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear = nn.Linear(10, 10)\n",
        "linear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqASjjZQckL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear(torch.tensor([1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,0.0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJcHLHt6cXAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "relu = nn.ReLU()\n",
        "relu\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzrQBmD6cfr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([-1.0])\n",
        "relu(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4CehSLxcjyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tanh = nn.Tanh()\n",
        "tanh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfNrJGRnc1po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout = nn.Dropout(0.45, inplace=True)\n",
        "dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RFklgV1c3Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequential = nn.Sequential(nn.Linear(10, 100), nn.Tanh(), nn.Linear(100,100), nn.Dropout(0.4, inplace = True), nn.Linear(100,10))\n",
        "sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH30QbbVc41R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lin1 = nn.Linear(10,100)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.lin2 = nn.Linear(100,100)\n",
        "        self.lin3 = nn.Linear(100,100)\n",
        "        self.lin4 = nn.Linear(100,10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin3(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin4(x)\n",
        "        return x\n",
        "net = Net()\n",
        "net\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hJXnvzvc677",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = loss.CrossEntropyLoss()\n",
        "cross_entropy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PakWOAlNHa8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import Module"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZaSSef3Hc7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import Parameter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhScgmbhF-rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Power(Module):\n",
        "\n",
        "    __constants__ = ['exponent']\n",
        "\n",
        "    def __init__(self, exponent=3):\n",
        "        super().__init__()\n",
        "        self.exponent = exponent\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.pow(input, self.exponent)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return f'exponent={self.exponent}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z_jvFGhOt18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Power(exponent = 4)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1uAg4zzGrWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WPower(Module):    \n",
        "    def __init__(self, ):\n",
        "        super().__init__()\n",
        "        self.exponent = Parameter(torch.Tensor(1))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init.uniform_(self.exponent, a=math.sqrt(5))\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.pow(input, self.exponent)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YemfgVcdIFB",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeszfvqidJ_o",
        "colab_type": "text"
      },
      "source": [
        "Some models are not just functions, but they also have internal parameters (weights/graph inputs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbYduaVOdDID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(linear.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmgsM_OedbPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear.weight\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5f0Q3GCdeHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear.bias\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoSzZUpfdgDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(tanh.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-sapuItdiYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(dropout.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aet5UQbydkp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout.p "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsdfce82dtQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1613d487-f635-4e82-a50c-0f095e3f618f"
      },
      "source": [
        "list(cross_entropy.parameters())\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQT6wYz8dpPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(map(lambda x: x.shape, list(sequential.parameters())))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtxKoxdfdmsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(map(lambda x: x.shape, list(net.parameters())))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3SN19HOdrow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(map(lambda x: x.requires_grad, list(net.parameters())))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8zULEKKd37v",
        "colab_type": "text"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqPenEPGd7U5",
        "colab_type": "text"
      },
      "source": [
        "Each module can be in either `eval` or `train` state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFPY0TRNd6Kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout.train()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPk0cHNqdw51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout(torch.ones(10))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1JnLrcLeFYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout.eval()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT0hgQ5PeG_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newseq = nn.Sequential(nn.Dropout(), nn.Dropout())\n",
        "newseq(torch.ones(10))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kETqU1poeKMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newseq.eval()\n",
        "newseq(torch.ones(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxeKQ3r0eP9a",
        "colab_type": "text"
      },
      "source": [
        "**Important**! Train / eval mode has nothing to do with weight training. It just changes behaviour of some modules (i.e. `dropout`, `batchnorm`). For composite modules `.eval()`/`.train()` sets corresponding mode for each of its components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7rIS3A3etBO",
        "colab_type": "text"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyKkp9pcewGR",
        "colab_type": "text"
      },
      "source": [
        "Most of module have default way of parameter initialization, but sometimes we might want to init them explicitly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKX8XpoPer3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear.weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8LyFiCweOYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init.xavier_uniform_(linear.weight)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og6vAbZvfHRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init.constant_(linear.weight, 1.0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6X6oRr2fJ6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(linear.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NcEej-6fL5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in linear.parameters():\n",
        "    init.uniform_(param, -12, 12)\n",
        "list(linear.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bczsQJD_fXJF",
        "colab_type": "text"
      },
      "source": [
        "You can find more initialization functions here: https://pytorch.org/docs/master/nn.html#torch-nn-init."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-HlBUMMfooa",
        "colab_type": "text"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QcAvjRJfvsT",
        "colab_type": "text"
      },
      "source": [
        "Torch has a reach collection of optimizers built-in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D4SLAamfONk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_zpzWMggMHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([1.0], requires_grad = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfWQxhE3gOC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = optim.SGD([x], lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80K1tz4ugP_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x * 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS49qBGzgTEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0nHcNqVgWRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuVGUuqPgYTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr-tEtKEgaIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0dKVjoYgb_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.grad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HkkGT9igdst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd.zero_grad()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8eRwxRQgfNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.grad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bbVM2MHgiWQ",
        "colab_type": "text"
      },
      "source": [
        "# First Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIFr-KUjgmR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKSiYasbgrQ3",
        "colab_type": "text"
      },
      "source": [
        "Let's downlad MNIST --- dataset of handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CaQGiyMgrnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = datasets.MNIST('/data', train=True, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                ]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3h5RcNngxnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = datasets.MNIST('../data', train=False, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VreNjs_ghAEI",
        "colab_type": "text"
      },
      "source": [
        "Dataloaders are responsible for data loading. They help us to split dataset in batches and shuffles the dataset(otherwise each buch will have only variants of a single digit). We will look inside them later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isUaEilOg79-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JwLAUASg-3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "toPIL = transforms.ToPILImage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNt3vzcWheef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def example(i):\n",
        "    print(train_dataset[i][1])\n",
        "    return toPIL(train_dataset[i][0]).resize((256, 256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS0IXIAOk_8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example(9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT3VcfTNhg9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example(10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukAEeDcShinq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader.__iter__().__next__()[1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2xbqs4CiAxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader.__iter__().__next__()[0].shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBOrXp1ZiDQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toPIL(train_loader.__iter__().__next__()[0][0]).resize((256,256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU728eD_iVwF",
        "colab_type": "text"
      },
      "source": [
        "Let's write a simple helper module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drFE7ng0iaY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        return x.view(batch_size, -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyfJfxlYiGY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "for param in model.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar9AwM6aFVxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8q6alogikey",
        "colab_type": "text"
      },
      "source": [
        "Why do we need `Flatten` module?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1ioiHwWiriu",
        "colab_type": "text"
      },
      "source": [
        "Setup an optimizer:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_ZaRtLhiQpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuGF-VaJixR-",
        "colab_type": "text"
      },
      "source": [
        "Choose a loss function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97rK7imziwi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = loss.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY1JXkwsi4B7",
        "colab_type": "text"
      },
      "source": [
        "And start training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTGlEEUsi21g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, optimizer, loss_function, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_function(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 200 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJZcV3I1it47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, test_loader, loss_function):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "\n",
        "    y_prediction = []\n",
        "    \n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            test_loss += loss_function(output, target).sum().item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            y_prediction.append(output)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    #     test_loss, correct, len(test_loader.dataset),\n",
        "    #     100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    flat_list = [item for sublist in y_prediction for item in sublist]\n",
        "\n",
        "    print(len(flat_list))\n",
        "    return flat_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMHY4BfdjJFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " %%time\n",
        "\n",
        "#  for epoch in range(1, 10):\n",
        "#         train(model, train_loader, optimizer, loss_function, epoch)\n",
        "#         test(model, test_loader, loss_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v18YmlwUoxY8",
        "colab_type": "text"
      },
      "source": [
        "# Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W20EUe7AxioK",
        "colab_type": "text"
      },
      "source": [
        "## Due to 10AM, 20.05.2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO6zst4UpcMR",
        "colab_type": "text"
      },
      "source": [
        "## 1. MNIST playground [10]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et-qYR-M9PIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------------- 1. ----------------------------------- \n",
        "# For the test set; it has a constant percentage loss of 98% from the get go, \n",
        "#     Lying between Accuracy: 9821/10000 and Accuracy: 9819/10000\n",
        "#     So i'll say the test accuracy is somewhat comstant\n",
        "\n",
        "# -------------------- 2. ----------------------------------- \n",
        "# example(4321) #The 0 looks like a 6 to me\n",
        "# example(600) #The nine looks like a 1 to me\n",
        "# example(4542) #Is that a 2?\n",
        "# example(56742) #This 9 is a joke"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLi6gyxB9V1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ass_test(model, test_loader, loss_function):\n",
        "    y_predictions = []\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            \n",
        "            output = model(data)\n",
        "            \n",
        "            test_loss += loss_function(output, target).sum().item()\n",
        "            \n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            \n",
        "            y_predictions.append(pred)\n",
        "            \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    return [item for sublist in y_predictions for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjSuqqK1jN9j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "736a6a6a-a157-411b-c1ae-e9cc26a36489"
      },
      "source": [
        "#---------------------------------------------3 ----------------------------------------------\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels = test_dataset.targets\n",
        "y_pred = ass_test(model, test_loader, loss_function)\n",
        "\n",
        "confusion_matrix(labels, y_pred)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[164, 114,  10, 352,  15,  66, 149,  36,  17,  57],\n",
              "       [177, 124,  17, 411,  19,  67, 193,  37,  21,  69],\n",
              "       [186, 122,  13, 379,  23,  69, 144,  23,  17,  56],\n",
              "       [177, 127,   7, 375,  19,  59, 145,  31,  22,  48],\n",
              "       [167,  98,  10, 363,  15,  87, 123,  35,  21,  63],\n",
              "       [155,  86,  12, 321,  16,  50, 143,  30,  10,  69],\n",
              "       [163,  97,  14, 366,   9,  76, 144,  22,  18,  49],\n",
              "       [190, 118,  10, 364,  21,  67, 151,  29,  10,  68],\n",
              "       [172, 103,  10, 351,  12,  73, 155,  30,  12,  56],\n",
              "       [183, 103,  14, 353,  15,  76, 167,  26,  23,  49]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4lJfekJBvv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "634311ec-2b3a-41eb-d0f1-4997dd69e15f"
      },
      "source": [
        "%%time\n",
        "#  -----------------------------------------4 -----------------------------------------------\n",
        "model1 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer1 = optim.SGD(model1.parameters(), lr=0.1)\n",
        "for param in model1.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)\n",
        "for epoch in range(0, 5):\n",
        "      train(model1, train_loader, optimizer1, loss_function, epoch)\n",
        "      ass_test(model1, test_loader, loss_function)\n",
        "\n",
        "# This takes about 2mins (probably bc i did just 5 iterations) and has test accuracy of 95%-97%"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.409482\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.245392\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.240422\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.248784\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.169147\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9542/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.107290\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.179685\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.090589\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.089025\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.095167\n",
            "\n",
            "Test set: Average loss: 0.0018, Accuracy: 9656/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.043507\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.169896\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.018526\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.029023\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.120653\n",
            "\n",
            "Test set: Average loss: 0.0015, Accuracy: 9721/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.044140\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.022646\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.027298\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.010352\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.047379\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9728/10000 (97%)\n",
            "\n",
            "CPU times: user 1min 12s, sys: 260 ms, total: 1min 12s\n",
            "Wall time: 1min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT4ISfEWHRNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "13a64847-1bee-4b06-8993-8e1505dab5aa"
      },
      "source": [
        "%%time\n",
        "model2 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer2 = optim.SGD(model2.parameters(), lr=0.1)\n",
        "for param in model2.parameters():\n",
        "    init.uniform_(param, -1, 1)\n",
        "for epoch in range(0, 5):\n",
        "      train(model2, train_loader, optimizer2, loss_function, epoch)\n",
        "      ass_test(model2, test_loader, loss_function)\n",
        "\n",
        "#  --> Gives a test accuracy of 83% - 87%.\n",
        "#  --> Takes approximately 2 minutes ; almost same time as the previous one"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 8.049155\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.254858\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.251435\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.331955\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.636467\n",
            "\n",
            "Test set: Average loss: 0.0086, Accuracy: 8255/10000 (83%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.633537\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.479071\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.369918\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.351569\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.300271\n",
            "\n",
            "Test set: Average loss: 0.0068, Accuracy: 8676/10000 (87%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.331682\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.311977\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.326685\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.195453\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.250011\n",
            "\n",
            "Test set: Average loss: 0.0062, Accuracy: 8780/10000 (88%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.391217\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.648983\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.116849\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.126457\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.143782\n",
            "\n",
            "Test set: Average loss: 0.0058, Accuracy: 8851/10000 (89%)\n",
            "\n",
            "CPU times: user 1min 13s, sys: 262 ms, total: 1min 14s\n",
            "Wall time: 1min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gbto4UPJlh9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "ccc7a33d-f55c-489f-aff8-27d5422076cf"
      },
      "source": [
        "%%time\n",
        "model3 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer3 = optim.SGD(model3.parameters(), lr=0.1)\n",
        "for param in model3.parameters():\n",
        "    init.uniform_(param, 0)\n",
        "for epoch in range(1, 5):\n",
        "      train(model3, train_loader, optimizer3, loss_function, epoch)\n",
        "      ass_test(model3, test_loader, loss_function)\n",
        "\n",
        "#  --> Poorest model with a Test Accuracy of 11%\n",
        "#  --> Takes the same amount of time as the previous 2"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302583\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.307203\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.307371\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.299948\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.307300\n",
            "\n",
            "Test set: Average loss: 0.0361, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.307154\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.311776\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.295553\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.299408\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.300027\n",
            "\n",
            "Test set: Average loss: 0.0361, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.298128\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.314942\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.311247\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.306334\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.297529\n",
            "\n",
            "Test set: Average loss: 0.0361, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.301251\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.303141\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 2.313977\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 2.303316\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.301124\n",
            "\n",
            "Test set: Average loss: 0.0361, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "CPU times: user 1min 12s, sys: 265 ms, total: 1min 13s\n",
            "Wall time: 1min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVgzcmOQNN-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "f8c928ab-4fff-4260-d9ef-529023a67768"
      },
      "source": [
        "%%time\n",
        "#  ----------------------------------------------- 5 --------------------------------------------------\n",
        "model4 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Sigmoid(),\n",
        "                      nn.Linear(512, 64), \n",
        "                      nn.Sigmoid(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer4 = optim.SGD(model4.parameters(), lr=0.1)\n",
        "for epoch in range(1, 5):\n",
        "      train(model4, train_loader, optimizer4, loss_function, epoch)\n",
        "      ass_test(model4, test_loader, loss_function)\n",
        "\n",
        "#  --> This runs for about 2 minutes and has a test accuracy in the range 88% - 94% "
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.325993\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.784569\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.823898\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.467822\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.457327\n",
            "\n",
            "Test set: Average loss: 0.0065, Accuracy: 8849/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.483803\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.325358\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.274338\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.372460\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.297992\n",
            "\n",
            "Test set: Average loss: 0.0047, Accuracy: 9139/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.366866\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.218086\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.268061\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.211224\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.315009\n",
            "\n",
            "Test set: Average loss: 0.0039, Accuracy: 9274/10000 (93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.234791\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.193683\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.298786\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.278898\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.149227\n",
            "\n",
            "Test set: Average loss: 0.0035, Accuracy: 9354/10000 (94%)\n",
            "\n",
            "CPU times: user 1min 14s, sys: 288 ms, total: 1min 14s\n",
            "Wall time: 1min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loiRdOBhPiyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "4aa97444-e83a-4202-a153-b6bf5ab54ae4"
      },
      "source": [
        "%%time\n",
        "# ------------------------------------------------ 6 -------------------------------------------------------------\n",
        "\n",
        "model5 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 256), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(256, 1024), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(1024, 10))\n",
        "optimizer5 = optim.SGD(model5.parameters(), lr=0.1)\n",
        "\n",
        "print(len(list(model5.parameters())))\n",
        "\n",
        "for epoch in range(0, 5):\n",
        "      train(model5, train_loader, optimizer5, loss_function, epoch)\n",
        "      ass_test(model5, test_loader, loss_function)\n",
        "\n",
        "# --> This cell takes about 2minutes and has a range accuracy of 94% - 98%\n",
        "# --> Here we have 6 parameters\n",
        "# --> Because we are building 1024 ouputs from 256inputs, we should have more weights \n",
        "#       to enable those transformations from few inputs to so many"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.278835\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.338060\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.144467\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.133026\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.226442\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9551/10000 (96%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.115169\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.091748\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.067802\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.104047\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.067872\n",
            "\n",
            "Test set: Average loss: 0.0018, Accuracy: 9618/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.165790\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.051647\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.140376\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.032812\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.069637\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9698/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.038885\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.014545\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.020218\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.053591\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.057139\n",
            "\n",
            "Test set: Average loss: 0.0012, Accuracy: 9756/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.023787\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.005286\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.036670\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.022537\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.147898\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 9748/10000 (97%)\n",
            "\n",
            "CPU times: user 1min 39s, sys: 392 ms, total: 1min 39s\n",
            "Wall time: 1min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1feGFZR28_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "8900da89-4ac0-4cb7-ff96-4c97fd5e065c"
      },
      "source": [
        "%%time\n",
        "# ------------------------------------------------ 7 -------------------------------------------------------------\n",
        "model6 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 256), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(256, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer6 = optim.SGD(model6.parameters(), lr=0.1)\n",
        "for epoch in range(0, 5):\n",
        "      train(model6, train_loader, optimizer6, loss_function, epoch)\n",
        "      # ass_test(model6, test_loader, loss_function)\n",
        "\n",
        "print(len(list(model6.parameters())))\n",
        "\n",
        "# --> Test accuracy lies bwtween 95% and 97%. \n",
        "# --> Because there is a layer more than the previous cells, it should take more time to complete and have more parameters\n",
        "# --> This cell has 8 parameters"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.307865\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.207812\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.247935\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.164265\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.216250\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.241294\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.143290\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.198603\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.143752\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.020959\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.095096\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.019771\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.145385\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.059978\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.036191\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.408859\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.166354\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.137785\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.027203\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.047179\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.066580\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.009640\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.023412\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.055565\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.135877\n",
            "8\n",
            "CPU times: user 1min 26s, sys: 347 ms, total: 1min 26s\n",
            "Wall time: 1min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dvuMbGFV_34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "53a1f8ab-7f61-4acb-ca67-d57482971a98"
      },
      "source": [
        "%%time\n",
        "model7 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(5, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "optimizer7 = optim.SGD(model7.parameters(), lr=0.1)\n",
        "for epoch in range(0, 5):\n",
        "      train(model7, train_loader, optimizer7, loss_function, epoch)\n",
        "      ass_test(model7, test_loader, loss_function)\n",
        "\n",
        "print(len(list(model7.parameters())))\n",
        "\n",
        "# --> It takes a few seconds more to complete compared to the q4 and q5 because of the extra layer\n",
        "# --> It should have 8 layers like in the other cell\n",
        "# --> The accuracy should pumelt because we are extracting 64 features from 5 \n",
        "#     features after loosing over half of our features from 512"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.351526\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.594746\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.418340\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.472391\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.433677\n",
            "\n",
            "Test set: Average loss: 0.0041, Accuracy: 9314/10000 (93%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.169153\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.321724\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.203700\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.216825\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.125539\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 8659/10000 (87%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.468025\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.087342\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.144907\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.074739\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.136765\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 9577/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.111384\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.039813\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.084118\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.154492\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.053544\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9516/10000 (95%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.026218\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.023803\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.131719\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.132903\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.048237\n",
            "\n",
            "Test set: Average loss: 0.0031, Accuracy: 9460/10000 (95%)\n",
            "\n",
            "8\n",
            "CPU times: user 1min 34s, sys: 370 ms, total: 1min 34s\n",
            "Wall time: 1min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ0Ia-O5ZSSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "f8119917-ed80-4389-d03b-c922a77798d8"
      },
      "source": [
        "%%time\n",
        "# ------------------------------------------- 8 -----------------------------------------------------\n",
        "model8 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5),\n",
        "                      nn.Dropout(0.35, inplace=True),\n",
        "                      nn.Linear(5, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "print(len(list(model8.parameters())))\n",
        "\n",
        "optimizer8 = optim.SGD(model8.parameters(), lr=0.1)\n",
        "for epoch in range(0, 5):\n",
        "      train(model8, train_loader, optimizer8, loss_function, epoch)\n",
        "      ass_test(model8, test_loader, loss_function)\n",
        "\n",
        "# --> Training using dropout ensures that some features aren't considered more important than others by randomly deselecting \n",
        "#     some nodes during the training process. I think a model which uses dropuout is barely biased on the training."
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.285109\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.007937\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.791132\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.675152\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.745005\n",
            "\n",
            "Test set: Average loss: 0.0053, Accuracy: 9033/10000 (90%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.774634\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.660407\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.542673\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.342067\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.362171\n",
            "\n",
            "Test set: Average loss: 0.0034, Accuracy: 9403/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.686689\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.378557\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.454226\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.422405\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.467761\n",
            "\n",
            "Test set: Average loss: 0.0054, Accuracy: 8923/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.835129\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.321122\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.452889\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.285238\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.319383\n",
            "\n",
            "Test set: Average loss: 0.0035, Accuracy: 9372/10000 (94%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.388442\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.317762\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.224559\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.298483\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.565701\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 9655/10000 (97%)\n",
            "\n",
            "CPU times: user 1min 33s, sys: 337 ms, total: 1min 33s\n",
            "Wall time: 1min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTE5DGkygbT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "62e3d748-209d-4ec3-919e-c563e948f098"
      },
      "source": [
        "%%time\n",
        "# ----------------------------------------------- 9 ---------------------------------------------------------------------\n",
        "\n",
        "ass_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "model9 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(5, 64), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "optimizer9 = optim.SGD(model9.parameters(), lr=0.1)\n",
        "\n",
        "for param in model9.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)\n",
        "    \n",
        "print(len(list(model9.parameters())))\n",
        "\n",
        "for epoch in range(0, 5):\n",
        "      train(model9, ass_train_loader, optimizer9, loss_function, epoch)\n",
        "      ass_test(model9, test_loader, loss_function)\n",
        "\n",
        "# --> When training, the loss reduces faster than in the shuffled model because the data is probably correlated"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.289038\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.626103\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.373072\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.378959\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.221681\n",
            "\n",
            "Test set: Average loss: 0.0034, Accuracy: 9364/10000 (94%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.189761\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.122652\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.103976\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.159315\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.162575\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9536/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.052364\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.075839\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.030565\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.059556\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.122196\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 9611/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.029132\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.076242\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.012028\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.034993\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.094793\n",
            "\n",
            "Test set: Average loss: 0.0019, Accuracy: 9666/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.014968\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.081040\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.011977\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.034745\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.080182\n",
            "\n",
            "Test set: Average loss: 0.0019, Accuracy: 9682/10000 (97%)\n",
            "\n",
            "CPU times: user 1min 31s, sys: 353 ms, total: 1min 32s\n",
            "Wall time: 1min 32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYgR1Q1ZnUGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "3207d0e8-7411-4cad-d13c-ae1583b46e9a"
      },
      "source": [
        "%%time\n",
        "# ---------------------------------------------- 10 ----------------------------------------------------\n",
        "#  50\n",
        "\n",
        "b_size = len(train_dataset)//2\n",
        "ass_2_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=b_size, shuffle=False)\n",
        "\n",
        "model10 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(5, 10))\n",
        "\n",
        "optimizer10 = optim.SGD(model10.parameters(), lr=0.1)\n",
        "\n",
        "for param in model10.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)\n",
        "\n",
        "print(len(list(model10.parameters())))\n",
        "\n",
        "for epoch in range(0, 5):\n",
        "      train(model10, ass_2_train_loader, optimizer10, loss_function, epoch)\n",
        "      ass_test(model10, test_loader, loss_function)\n",
        "\n",
        "# --> The test accuracy is barely significant\n",
        "# --> The model doesn't have enough data to train on hence the test accuracy\n",
        "# --> This model barely learns anything"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.311400\n",
            "\n",
            "Test set: Average loss: 0.0360, Accuracy: 1076/10000 (11%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.294225\n",
            "\n",
            "Test set: Average loss: 0.0357, Accuracy: 1140/10000 (11%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.276594\n",
            "\n",
            "Test set: Average loss: 0.0353, Accuracy: 1460/10000 (15%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.254478\n",
            "\n",
            "Test set: Average loss: 0.0349, Accuracy: 2097/10000 (21%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.224661\n",
            "\n",
            "Test set: Average loss: 0.0342, Accuracy: 2617/10000 (26%)\n",
            "\n",
            "CPU times: user 1min 25s, sys: 236 ms, total: 1min 25s\n",
            "Wall time: 1min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg8_r8eqp5N2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "26bd98ca-9093-40c5-9df9-5a0cf8c102dd"
      },
      "source": [
        "%%time\n",
        "# 30%\n",
        "\n",
        "b_size = int(round((3 * len(train_dataset))//10))\n",
        "\n",
        "ass_3_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=b_size, shuffle=False)\n",
        "\n",
        "model11 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(5, 64))\n",
        "\n",
        "optimizer11 = optim.SGD(model11.parameters(), lr=0.1)\n",
        "\n",
        "for param in model11.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)\n",
        "\n",
        "print(len(list(model11.parameters())))\n",
        "\n",
        "for epoch in range(0, 5):\n",
        "      train(model11, ass_3_train_loader, optimizer11, loss_function, epoch)\n",
        "      ass_test(model11, test_loader, loss_function)\n",
        "\n",
        "# --> The test accuracy is barely significant\n",
        "# --> The model doesn't have enough data to train on hence the test accuracy\n",
        "# --> This model barely learns anything"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 4.135107\n",
            "\n",
            "Test set: Average loss: 0.0615, Accuracy: 1385/10000 (14%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 3.918769\n",
            "\n",
            "Test set: Average loss: 0.0462, Accuracy: 1268/10000 (13%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.955041\n",
            "\n",
            "Test set: Average loss: 0.0338, Accuracy: 3198/10000 (32%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.165608\n",
            "\n",
            "Test set: Average loss: 0.0294, Accuracy: 4029/10000 (40%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.888728\n",
            "\n",
            "Test set: Average loss: 0.0263, Accuracy: 4493/10000 (45%)\n",
            "\n",
            "CPU times: user 1min 25s, sys: 174 ms, total: 1min 25s\n",
            "Wall time: 1min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or-URC6MrcVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4e032320-317c-436f-effd-62a1bdbadf28"
      },
      "source": [
        "%%time\n",
        "# 10%\n",
        "\n",
        "b_size = int(round((1 * len(train_dataset))//10))\n",
        "\n",
        "ass_4_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=b_size, shuffle=False)\n",
        "\n",
        "model12 = nn.Sequential(Flatten(), \n",
        "                      nn.Linear(784, 512), \n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 5),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(5, 64))\n",
        "\n",
        "optimizer12 = optim.SGD(model12.parameters(), lr=0.1)\n",
        "\n",
        "for param in model12.parameters():\n",
        "    init.uniform_(param, -0.1, 0.1)\n",
        "\n",
        "print(len(list(model12.parameters())))\n",
        "\n",
        "for epoch in range(0, 5):\n",
        "      train(model12, ass_4_train_loader, optimizer12, loss_function, epoch)\n",
        "      ass_test(model12, test_loader, loss_function)\n",
        "\n",
        "# --> The test accuracy is barely significant\n",
        "# --> The model doesn't have enough data to train on hence the test accuracy\n",
        "# --> This model is a joke "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 4.180956\n",
            "\n",
            "Test set: Average loss: 0.0501, Accuracy: 2666/10000 (27%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 3.185317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx878231wz4N",
        "colab_type": "text"
      },
      "source": [
        "**Important!** This task is not too hard, but it is pretty time-consuming. Total computation time is about 4 hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm1Jm5bCpkbd",
        "colab_type": "text"
      },
      "source": [
        "1. Find out how many epochs are needed for our network to stop improving on test dataset (let's stop on 5 epochs without accuracy improvement on the test set). How long does it take? [1]\n",
        "2. Find some problematic examples and show them with `example()` function we defined in class.[1]\n",
        "3. Draw a confusion matrix for your model on test dataset. It is a 10x10 matrix, and in the cell `(i,j)` there is a number of digits `i` classified as digit `j`.[1]\n",
        "4. By default weight of linear layer is initialized with `kaiming_uniform` function and bias is unitialized with `uniform` function (see reset parameters method of Linear class https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py). Initialize all weights as `uniform(-0.1,0.1)` and test. How does this modification affect training process? Is it faster/slower? Is the end result better/worse? Same question form `uniform(-1, 1)`. Same question for `constant(0)` initialization. Don't forget to recreate optimizer for your new model (otherwise you'll optimize parameters of the old model using values from the new one, which does not work).[1]\n",
        "5. Try replacing `Tanh` activation by `Sigmoid` test, how does this modification affect training process? These and further questions assumes that you are changing the initial model (i.e. all modification from previous step are undone). [1]\n",
        "6. Try changing output dimension of the first linear layer  (and input of the second) to `256`, to `1024`. How does this modification affect training process? How does the number of model parameters changes? [1]\n",
        "7. Our model has 2 hidden layers of sizes `512` and `64`. Let's use 3 hidden layers of sizes `512`, `256` and `64`.  How does this modification affect training process? How does the number of model parameters changes? Same question for 3 layers of sizes `512`, `5` and `64`(don't forget to add activation function between linear layers). [1]\n",
        "8. Try adding dropout after first/second layer. How does this modification affect training process? [1]\n",
        "9. Try disabling shuffle in the train dataloader (leave it unchanged in the test dataloader, otherwise testing will not be fair). How does this modification affect training process? Do not forget to reset training weights of the model. [1]\n",
        "10. Try training, using half of the training dataset. 30%. 10%. How does this affect training process? Do not forget to reset training weights of the model. [1] \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89MVN5spyr3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}