{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 6.",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lagom-QB/M11/blob/master/Practice_6_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jux4XsCoOWko",
        "colab_type": "text"
      },
      "source": [
        "# Modern convolutional architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45MLGi18OeoC",
        "colab_type": "text"
      },
      "source": [
        "# keywords: resnet, inception trick, batchnorm, image normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjSjLOaxFDm5",
        "colab_type": "text"
      },
      "source": [
        "Here is a resnet implementation (see also https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWq2apxvEk17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNZi8RWHD7L1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=True)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "  def forward(self, x):\n",
        "    batch_size = x.shape[0]\n",
        "    return x.view(batch_size, -1)\n",
        "    \n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=True)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=True)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=True)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class FBResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 16\n",
        "        # Special attributs\n",
        "        self.input_space = None\n",
        "        self.input_size = (299, 299, 3)\n",
        "        self.mean = None\n",
        "        self.std = None\n",
        "        super(FBResNet, self).__init__()\n",
        "        # Modules\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                                bias=True)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = Flatten()\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=True),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def features(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = self.flatten(x)\n",
        "        return x\n",
        "\n",
        "    def logits(self, features):\n",
        "        return self.last_linear(features)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.features(input)\n",
        "        x = self.logits(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvt-8ZvYEnfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fbresnet18(num_classes=1000):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = FBResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "def fbresnet34(num_classes=1000):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = FBResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "def fbresnet50(num_classes=1000):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = FBResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "def fbresnet101(num_classes=1000):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = FBResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HX58Kc7Vtdb",
        "colab_type": "text"
      },
      "source": [
        "Note: there is no dropout layers here. Usually dropouts and batchnorms does not work well together. You may use dropouts in the dense classifier in the end, but using dropout before the batchnorm is usually a bad idea."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKhl1adSE1O1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18 = fbresnet18()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxCF6hHqa5tL",
        "colab_type": "text"
      },
      "source": [
        "Let's count the number of the parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgtnuQ8davhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0786f93-12be-44ed-ee5d-09486cc49109"
      },
      "source": [
        "sum(p.numel() for p in resnet18.parameters() if p.requires_grad)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3271496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl9pSnnWE6Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMLxerLPE893",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_batch = torch.ones((4, 3, 224, 224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMl0KrNKGN7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18(test_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnBUvsfaKYUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez2-11cBKxhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHsaDcEAFkds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKn0JVldFuSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88WcqXduFzW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter(log_dir=\"logs/resnet18_graph\")\n",
        "writer.add_graph(resnet18, test_batch)\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DjoMWWzVa12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18.par"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_DLmoOvOpMW",
        "colab_type": "text"
      },
      "source": [
        "# Image normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UW9lzXfMIsz",
        "colab_type": "text"
      },
      "source": [
        "As there is batchnorm after every layer, it's easier to train the network (lr is similar for all layers). Except the first one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-Ngu6goPTQ1",
        "colab_type": "text"
      },
      "source": [
        "To fix this we add normalization to test/train transform.\n",
        "Below is the usual transform for imagenet dataset (it's better to use it if you use pretrained network)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmKIx5eYOwP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "transforms.Normalize(mean, std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICTPKrJQPm9b",
        "colab_type": "text"
      },
      "source": [
        "If you train from scratch it's better to compute mean and dispersion for the dataset you are training on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjKga3mDPy0p",
        "colab_type": "text"
      },
      "source": [
        "# Updates for cifar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo2jccXAP6MJ",
        "colab_type": "text"
      },
      "source": [
        "Perception field of `7` is not needed for `32`x`32` images, also we do not want to decrease our resolution in half, so let's set `stride=1`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7HKQJ7ARESY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTTTdU1rRVHW",
        "colab_type": "text"
      },
      "source": [
        "resnet18 has way too many parameters for the cifar. There is `64` channels after the first convolution. Let's decrease this number to `16`.\n",
        "Also there are two blocks with `64` channels, two blocks with `128` , with `256` and with `512` channels.\n",
        "For cifar `16`, `32`, `64`, `128` will be enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws1JCxP-S1p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "self.layer4 = self._make_layer(block, 512, layers[3], stride=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEYHQTwlTKmP",
        "colab_type": "text"
      },
      "source": [
        "=>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhejRZNCTIEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "self.layer4 = self._make_layer(block, 128, layers[3], stride=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51zaDr8ATbQh",
        "colab_type": "text"
      },
      "source": [
        "Also, we are dividing dimensions of the image by `2` three times.\n",
        "This means that in the last group of blocks we are working with `4`x`4` images, i.e. our network is almost dense.\n",
        "It's benefitial to skip `self.layer4` altogether.\n",
        "To keep network deep enough, let's create `3` blocks in each other layer, instead of `2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hdkeVy5UJcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fbresnet20(num_classes=1000):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = FBResNetCifar(BasicBlock, [3, 3, 3], num_classes=num_classes)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdelyfflW0pC",
        "colab_type": "text"
      },
      "source": [
        "# Assignment[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SEIe6E5YT8G",
        "colab_type": "text"
      },
      "source": [
        "1. Shape arithmetic [2]:\n",
        "\n",
        "a) How will the layer shape change after apllying `Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=True)`?\n",
        "\n",
        "b) What padding should we use, so that `Conv2d(3, 64, kernel_size=17, stride=2, padding=?, bias=True)` transforms a tensor with shape `[64, 3, 2x, 2x]` to the tensor with shape `[64, 64, x, x]`?\n",
        "\n",
        "c) What will be dimensions of the tensor `[64, 3, 4, 4]` after we `Flatten` it?\n",
        "\n",
        "d) In resnet blocks of different layer work with tensors of different shape. How does the number of parameters per block changes between layers1, layers2, layers3, layers4?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzXFWWMBXDoC",
        "colab_type": "text"
      },
      "source": [
        "2. Implement the changes we discussed in practice in FBResNetCifar and create a resnet20 model. Compute the number of its parameters.[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX0EOnI-XLlo",
        "colab_type": "text"
      },
      "source": [
        "3. Compute mean and standard deviation for each channel for cifar10 train dataset. [2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf8-bt8KXfH0",
        "colab_type": "text"
      },
      "source": [
        "4. Train resnet20 network on cifar dataset for at least 80% accuracy. Normalize input according to values computed in (3). [2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04d7MkOnXtTx",
        "colab_type": "text"
      },
      "source": [
        "5. Replace 3x3 convolutions in resnet20 by 3x1 and 1x3 convolution, using inception trick. Compute the number of its parameters. Train this model on cifar dataset for the same number of epochs with the same optimizer. Normalize the input. [2]"
      ]
    }
  ]
}