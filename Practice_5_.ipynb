{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 5.",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lagom-QB/M11/blob/master/Practice_5_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noa9c7UrIiUs",
        "colab_type": "text"
      },
      "source": [
        "#Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6X55s0NJkhg",
        "colab_type": "text"
      },
      "source": [
        "# keywords: convolution, batchnorm, vgg, inception, cifar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzuThefpL-ak",
        "colab_type": "text"
      },
      "source": [
        "# Goodle Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyqQq3dwKmGS",
        "colab_type": "text"
      },
      "source": [
        "One of the big disadvantages of colab is the absence of persistent drive. \n",
        "\n",
        "We can solve this problem, by mounting google drive to colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8nfm_13JkO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULey3w9bIfNS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "92bb7267-3658-4cb4-bd34-aaf7d28f4fc1"
      },
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EJf2t8YK-v0",
        "colab_type": "text"
      },
      "source": [
        "This command will ask you for authorization code. You can get it by following the URL printed (you will ask to allow colab to access your gdrive data). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmFYGm_hJ-Zt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "158b6c0c-f2e0-4988-ccb8-c57b63ef15fc"
      },
      "source": [
        "!ls /content/drive/My\\ Drive/Colab\\ Notebooks/DS411"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/drive/My Drive/Colab Notebooks/DS411': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbTJ1KGGLZIC",
        "colab_type": "text"
      },
      "source": [
        "No your drive (and drives shared with you) can be accessed from the notebook. Data stored in your drive can be accessed from later sessions.\n",
        "Beware that all changes are permanent. Do not delete data you may need later from your google drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTCMORviMZ47",
        "colab_type": "text"
      },
      "source": [
        "# VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH59jSiQMiUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "import torch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCZzCv9wNH-R",
        "colab_type": "text"
      },
      "source": [
        "Convolution layer are already implemented in pytorch module library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmCEq7vTMfIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv = nn.Conv2d(3, 3, kernel_size=5, padding=2)\n",
        "conv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mec4wOfM1c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(conv.named_parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Sl948uMdix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WxLMR1_NdUb",
        "colab_type": "text"
      },
      "source": [
        "torchvision module has many models and helper functions, usefull for cv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7mLu3jNNbV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16 = models.vgg16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV0QMu_KOQf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHTkxgDSOvzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHmsOqfxOxwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks_eSwHBPSAP",
        "colab_type": "text"
      },
      "source": [
        "Let's create a fake input bath of 32x32 rgb images (first dimension in pytorch is always a batchsize)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epZubPvhO0fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_batch = torch.ones((64, 3, 32, 32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDBSdOiLPBoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter(log_dir=\"logs/vgg16_graph\")\n",
        "writer.add_graph(vgg16, input_batch)\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCSXeTk2PnqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9e-pD0DRT0f",
        "colab_type": "text"
      },
      "source": [
        "Most of the models can also be downloaded with weights pretrained on imagenet (it's an image dataset with 1000 classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMTKdtcUQZdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_pretrained = models.vgg16(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8njnRt9bRpfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "toPIL = transforms.ToPILImage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BTE6FzWRqSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toPIL(list(vgg16_pretrained.features[28].parameters())[0][67].cpu()).resize((256, 256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5rwOGgUSi4s",
        "colab_type": "text"
      },
      "source": [
        "# CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUed5sNHRu4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVGlRqk9SmNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def example(dataset, i):\n",
        "    print(classes[dataset[i][1]])\n",
        "    return toPIL(dataset[i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYnVAkxUSpbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example(train_dataset, 13).resize((256, 256))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVwhGVMISwhD",
        "colab_type": "text"
      },
      "source": [
        "# Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1V-AEWfS0Fe",
        "colab_type": "text"
      },
      "source": [
        "In matine learning applications, you always want to get as much diverse data as you can."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8LBUj9sS7w0",
        "colab_type": "text"
      },
      "source": [
        "Augmentations is a way to get some \"new\" data for free.\n",
        "There are plenty of augmentations in `torchvision` library, but `albumentations` is one of the best framework-independent augmentation library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2FWRx-5SraZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import albumentations as alb\n",
        "import albumentations.augmentations.transforms as aat\n",
        "import numpy as np\n",
        "from PIL import Image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjppFFSHTSEm",
        "colab_type": "text"
      },
      "source": [
        "Let's write a simple adapter between albumentation and pytorch transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL9CESjrSuc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlbuWrapper:  # typing: ignore\n",
        "    def __init__(self, atrans: alb.BasicTransform):\n",
        "        self.atrans = atrans\n",
        "\n",
        "    def __call__(self, img: Image.Image) -> Image.Image:\n",
        "        return self.atrans(image=np.array(img))[\"image\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odJGqd7OTRJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1C3JHioTasf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alb_transforms = alb.Compose(\n",
        "        [\n",
        "            alb.OneOf([alb.IAAAdditiveGaussianNoise(), alb.GaussNoise()], p=0.2),\n",
        "            alb.OneOf(\n",
        "                [alb.MotionBlur(p=0.2), alb.MedianBlur(blur_limit=3, p=0.1), alb.Blur(blur_limit=3, p=0.1)], p=0.2\n",
        "            ),\n",
        "            alb.OneOf([alb.OpticalDistortion(p=0.3), alb.GridDistortion(p=0.1), alb.IAAPiecewiseAffine(p=0.3)], p=0.2),\n",
        "            alb.OneOf([aat.CLAHE(clip_limit=2), alb.IAASharpen(), alb.IAAEmboss()], p=0.3),\n",
        "            aat.HueSaturationValue(p=0.3),\n",
        "            aat.HorizontalFlip(),\n",
        "            aat.RGBShift(),\n",
        "            aat.RandomBrightnessContrast(),\n",
        "            aat.RandomGamma(),\n",
        "            aat.Cutout(2, 10, 10)\n",
        "        ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaxsCnIVTgdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_transforms = transform\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWv08pFkTj_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms.Compose(\n",
        "[AlbuWrapper(alb_transforms), transform])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOPbejkSTloS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=258,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transforms)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=258,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4p4i9FMTxCc",
        "colab_type": "text"
      },
      "source": [
        "Let's have a look at transformed bird:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeYaXla0ToAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example(train_dataset, 13).resize((256, 256))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xhjJe1uT5KO",
        "colab_type": "text"
      },
      "source": [
        "# Replace classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd6SmK1JT9gp",
        "colab_type": "text"
      },
      "source": [
        "VGG model we loaded is designed for imagenent. Imagenet has 1000 classes and the pictures there are larger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3Ea-ovKUg-p",
        "colab_type": "text"
      },
      "source": [
        "We can use feature extractor as-is without any changes (CNN).\n",
        "But we will need a new dense classifier (we have only 10 classes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj6wtRsZTqC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = nn.Sequential(nn.Linear(25088, 4096), nn.ReLU(), nn.Linear(4096, 4096), nn.ReLU(), nn.Linear(4096,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suoJfj3bVJOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5czKD-CVT9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter(log_dir=\"logs/vgg16_graph_new_classifier\")\n",
        "writer.add_graph(vgg16, input_batch)\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BK19SAIWAna",
        "colab_type": "text"
      },
      "source": [
        "### What problems do you see in this model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCi7GriaXZxp",
        "colab_type": "text"
      },
      "source": [
        "Dense classiffier is 49 times larger than needed..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo_7ZIxLVbNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4FL4dv_Y_Ik",
        "colab_type": "text"
      },
      "source": [
        "Now we have 512 dimensional feature vector. Probably there is no need in 2 hidden layers, so we can simplify classifier a bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65_hw7BdXxPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = nn.Sequential(nn.Linear(512, 512), nn.ReLU(), nn.Linear(512,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rd-IxBRdaw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmywdai-cXde",
        "colab_type": "text"
      },
      "source": [
        "# Pretrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO9bqPoicegQ",
        "colab_type": "text"
      },
      "source": [
        "We have a VGG16 network pretrained on imagenet. Even though this dataset is pretty different from CIFAR, the first few layers of feature extractor usually are pretty generic and we can reuse them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J5bcnQoYAAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_pretrained.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT1j7nFAdVpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_pretrained.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RecU2s69dt0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_pretrained"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP1uN1cidjfv",
        "colab_type": "text"
      },
      "source": [
        "Let's **freeze** the first 19 layers of feature extractor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omzM3i8tdgHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in vgg16_pretrained.features[0:19]:\n",
        "  for p in layer.parameters():\n",
        "    p.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM55aepvewt5",
        "colab_type": "text"
      },
      "source": [
        "Now when we optimize the model, the weights of the first 19 layers will not be updated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF9rqQjhe_7a",
        "colab_type": "text"
      },
      "source": [
        "Once we trained models with the frozen layers it may be benefitial to \"unfreeze\" frozen layers and train the whole model. Usually you will use SGD optimizer with a really small learning rate for the last part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a01nZCkqevea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in vgg16_pretrained.features[0:19]:\n",
        "  for p in layer.parameters():\n",
        "    p.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6qefbF4gjjX",
        "colab_type": "text"
      },
      "source": [
        "# GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGl97YOzgqY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa_xf2OegkfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([1,2,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEBkl7w_gohm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = torch.tensor([1,2,3], device=torch.device(\"cuda\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6ySz8Hug5SE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCWP0-9ohAtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyWEl1OPhBC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB6OqWYxhBuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.to(torch.device(\"cuda\")) + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oGUG4yZijQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x + y.to(torch.device(\"cpu\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKF-hExYhdgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywk5_lx7hQ1Y",
        "colab_type": "text"
      },
      "source": [
        "Remember that your model also have weights. So, if you want to train on GPU, you need to move both, model weights, data and labels to GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvX7mqAmhO8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "label = label.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23Rpqkxmh5N4",
        "colab_type": "text"
      },
      "source": [
        "# Assignment [10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_puqE0y0iZ0g",
        "colab_type": "text"
      },
      "source": [
        "1. Update your `train` and `test` procedures, so they can accept additional argument `device` and can be used for both cpu and gpu training. [1]\n",
        "2. Try taining an epoch on cifar on cpu (do not use augmentations for now) and on gpu. Compare the training speed. [1]\n",
        "3. Try taining an epoch on cifar on gpu (do not use augmentations for now) with old and updated classifier part. Compare the training speed. [1]\n",
        "4. Train vgg16 cifar classifier on gpu with updated classifier and no augmentations.[1]\n",
        "5. Train vgg16 cifar classifier on gpu with updated classifier and augmentations.[1]\n",
        "6. Train vgg16 cifar classifier initialized with pretrained weights (do not freeze layers).[2]\n",
        "7. Train vgg16 cifar classifier initialized with pretrained weights with first 19 layers frozen, then unfreeze those layers and continue training with a small learning rate and SGD classifier. [3]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8DuZ-w5hplo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}